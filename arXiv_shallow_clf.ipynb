{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer #, HashingVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.linear_model import RidgeClassifier\n",
    "#from sklearn.linear_model import SGDlassifier(loss = ...)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* Build and test a simple preprocessing pipe that handles *LaTeX* formulas prepended to count-vectorization and TFIDF transformation.\n",
    "* Test a handful of shallow multiclass classifiers with *macro-F1* as the objective (in a noninteractive fashion)\n",
    "* Plot the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the measure of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available scores\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = \"f1_macro\"\n",
    "average = \"macro\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the two-column data frame (text + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"data\", \"bare_all.csv\")\n",
    "\n",
    "data = pd.read_csv(file, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 20k records to play with\n",
    "small_num = 20000\n",
    "sample = data[:small_num]\n",
    "\n",
    "text = sample.text\n",
    "label = sample.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No all records in memory: 837'000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power sum decompositions of defining equations of reflection arrangements.  We determine the Waring rank of the fund...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Spectroscopic Survey of Massive Stars in M31 and M33.  We describe our spectroscopic follow-up to the Local Group ...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hamiltonian Thermodynamics of Black Holes in Generic 2-D Dilaton Gravity.  We consider the Hamiltonian mechanics and...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      text  \\\n",
       "0  Power sum decompositions of defining equations of reflection arrangements.  We determine the Waring rank of the fund...   \n",
       "1  A Spectroscopic Survey of Massive Stars in M31 and M33.  We describe our spectroscopic follow-up to the Local Group ...   \n",
       "2  Hamiltonian Thermodynamics of Black Holes in Generic 2-D Dilaton Gravity.  We consider the Hamiltonian mechanics and...   \n",
       "\n",
       "  label  \n",
       "0  math  \n",
       "1  phys  \n",
       "2  phys  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"No all records in memory: {round(len(data)/1000)}'000\")\n",
    "with pd.option_context('display.max_colwidth', 120):\n",
    "    display(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts of scientific papers tend to be written in a formal style, to not contain typos, nor direct citations, little references, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Modular Formalization of Reversibility for Concurrent Models and Languages.  Causal-consistent reversibility is the reference notion of reversibility for concurrency. We introduce a modular framework for defining causal-consistent reversible extensions of concurrent models and languages. We show how our framework can be used to define reversible extensions of formalisms as different as CCS and concurrent X-machines. The generality of the approach allows for the reuse of theories and techniques in different settings. \n",
      "---\n",
      "Modular circle quotients and PL limit sets.  We say that a collection Gamma of geodesics in the hyperbolic plane H^2 is a modular pattern if Gamma is invariant under the modular group PSL_2(Z), if there are only finitely many PSL_2(Z)-equivalence classes of geodesics in Gamma, and if each geodesic in Gamma is stabilized by an infinite order subgroup of PSL_2(Z). For instance, any finite union of closed geodesics on the modular orbifold H^2/PSL_2(Z) lifts to a modular pattern. Let S^1 be the ideal boundary of H^2. Given two points p,q in S^1 we write pq if p and q are the endpoints of a geodesic in Gamma. (In particular pp.) We show that is an equivalence relation. We let Q_Gamma=S^1/ be the quotient space. We call Q_Gamma a modular circle quotient. In this paper we will give a sense of what modular circle quotients `look like' by realizing them as limit sets of piecewise-linear group actions \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(text.iloc[random.choice(range(len(text)))])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One messy but informative kind of writing they have are LaTeX formulas (*\\$...\\$*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distribution of the roots of the equations $Z(t)=0$, $Z\\'(t)=0$ in the theory of the Riemann zeta-function.  Let the symbols $\\\\{\\\\gamma\\\\},\\\\ \\\\{t_0\\\\};\\\\ t_0\\\\not=\\\\gamma$ denote the sequences of the roots of the equations $$Z(t)=0,\\\\quad \\\\text{and}\\\\qquad Z\\'(t)=0,$$ respectively, and $$m(t_0)=\\\\min\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad Q(t_0)=\\\\max\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad \\\\gamma\\'<t_0<\\\\gamma\",$$ where $\\\\gamma\\',\\\\gamma\"$ are the neighboring zeroes. We have proved the following in this paper: on the Riemann hypothesis we have $$\\\\frac{Q(t_0)}{m(t_0)}<t_0\\\\ln^2t_0\\\\ln_2t_0\\\\ln_3t_0,\\\\quad t_0\\\\to\\\\infty.$$ This paper is the English version of the paper of ref. \\\\cite{5}. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose to either mask them with * \\_latex\\_ * or flag them by appending * \\_latex\\_ * in front of each such expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask or flag LaTeX expression with a word ' _LATEX_ '\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DeLaTeX(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Replace r\"(\\${1,2}[...]*?\\${1,2})\" with ' _latex_ ' or 'latex \\1'\n",
    "    \"\"\"\n",
    "    # why does it differ from  r'(\\$.+?\\$)' ?\n",
    "    \n",
    "    def __init__(self, behave = 'flag'):\n",
    "        self.pattern = r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\"\n",
    "        if behave:\n",
    "            self.repl = ' _LATEX_ ' if behave == 'mask' else  r' _LATEX_ \\1'\n",
    "        else:\n",
    "            self.repl = r'\\1' # do nothing with extra steps\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.str.replace(self.pattern, self.repl)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distribution of the roots of the equations $Z(t)=0$, $Z\\'(t)=0$ in the theory of the Riemann zeta-function.  Let the symbols $\\\\{\\\\gamma\\\\},\\\\ \\\\{t_0\\\\};\\\\ t_0\\\\not=\\\\gamma$ denote the sequences of the roots of the equations $$Z(t)=0,\\\\quad \\\\text{and}\\\\qquad Z\\'(t)=0,$$ respectively, and $$m(t_0)=\\\\min\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad Q(t_0)=\\\\max\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad \\\\gamma\\'<t_0<\\\\gamma\",$$ where $\\\\gamma\\',\\\\gamma\"$ are the neighboring zeroes. We have proved the following in this paper: on the Riemann hypothesis we have $$\\\\frac{Q(t_0)}{m(t_0)}<t_0\\\\ln^2t_0\\\\ln_2t_0\\\\ln_3t_0,\\\\quad t_0\\\\to\\\\infty.$$ This paper is the English version of the paper of ref. \\\\cite{5}. '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = None)\n",
    "delatex.transform(text[9:10])[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distribution of the roots of the equations  _LATEX_ ,  _LATEX_  in the theory of the Riemann zeta-function.  Let the symbols  _LATEX_  denote the sequences of the roots of the equations  _LATEX_  respectively, and  _LATEX_  where  _LATEX_  are the neighboring zeroes. We have proved the following in this paper: on the Riemann hypothesis we have  _LATEX_  This paper is the English version of the paper of ref. \\\\cite{5}. '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'mask')\n",
    "delatex.transform(text[9:10])[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distribution of the roots of the equations  _LATEX_ $Z(t)=0$,  _LATEX_ $Z\\'(t)=0$ in the theory of the Riemann zeta-function.  Let the symbols  _LATEX_ $\\\\{\\\\gamma\\\\},\\\\ \\\\{t_0\\\\};\\\\ t_0\\\\not=\\\\gamma$ denote the sequences of the roots of the equations  _LATEX_ $$Z(t)=0,\\\\quad \\\\text{and}\\\\qquad Z\\'(t)=0,$$ respectively, and  _LATEX_ $$m(t_0)=\\\\min\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad Q(t_0)=\\\\max\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad \\\\gamma\\'<t_0<\\\\gamma\",$$ where  _LATEX_ $\\\\gamma\\',\\\\gamma\"$ are the neighboring zeroes. We have proved the following in this paper: on the Riemann hypothesis we have  _LATEX_ $$\\\\frac{Q(t_0)}{m(t_0)}<t_0\\\\ln^2t_0\\\\ln_2t_0\\\\ln_3t_0,\\\\quad t_0\\\\to\\\\infty.$$ This paper is the English version of the paper of ref. \\\\cite{5}. '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "delatex.transform(text[9:10])[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs', 'math', 'phys', 'q-bio', 'q-fin', 'stat']\n"
     ]
    }
   ],
   "source": [
    "# 'cs' -> 0, ..., 'stat' -> 5\n",
    "\n",
    "label_e = LabelEncoder()\n",
    "y_train = label_e.fit_transform(label)\n",
    "\n",
    "print(list(label_e.classes_))\n",
    "\n",
    "#label_e.inverse_transform([0]) # array(['cs'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optionally, have a look at the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "count_v = CountVectorizer(strip_accents='unicode')\n",
    "word_counts_train = count_v.fit_transform(delatex.fit_transform(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(213000, 'the'),\n",
       " (135000, 'of'),\n",
       " (75000, 'and'),\n",
       " (67000, 'in'),\n",
       " (56000, 'to'),\n",
       " (43000, 'we'),\n",
       " (40000, 'is'),\n",
       " (36000, 'for'),\n",
       " (36000, '_latex_'),\n",
       " (29000, 'that')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_word_counts_train = word_counts_train.sum(axis=0)\n",
    "sorted([(round(sum_word_counts_train[0, i],-3), word) for word, i in count_v.vocabulary_.items()],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go step by step through an arbitrary pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX()\n",
    "tex_text_train = delatex.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(use_idf=True, min_df = 2, max_df=0.8, strip_accents='unicode')\n",
    "tfidf_scores_train = tfidf_v.fit_transform(tex_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1, class_weight='balanced')\n",
    "lsvc.fit(tfidf_scores_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's just have some fun first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_abstracts = pd.Series([\"\"\"\n",
    "The Lack of A Priori Distinctions Between Learning Algorithms. This is the first of\n",
    "two papers that use off-training set (OTS) error to investigate the assumption-free\n",
    "relationship between learning algorithms. This first paper discusses the senses in\n",
    "which there are no a priori distinctions between learning algorithms. (The second\n",
    "paper discusses the senses in which there are such distinctions.) In this first paper\n",
    "it is shown, loosely speaking, that for any two algorithms A and B, there are \"as many\"\n",
    "targets (or priors over targets) for which A has lower expected OTS error than B as\n",
    "vice versa, for loss functions like zero-one loss. In particular, this is true if A\n",
    "is cross-validation and B is \"anti-cross-validation'' (choose the learning algorithm\n",
    "with largest cross-validation error). This paper ends with a discussion of the\n",
    "implications of these results for computational learning theory. It is shown that one\n",
    "cannot say: if empirical misclassification rate is low, the Vapnik-Chervonenkis\n",
    "dimension of your generalizer is small, and the training set is large, then with high\n",
    "probability your OTS error is small. Other implications for \"membership queries\"\n",
    "algorithms and \"punting\" algorithms are also discussed.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "X-rays quarks lepton scattering experiment field\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "genes DNA RNA sequencing protein species fenotype \n",
    "\"\"\",\n",
    "\"\"\"\n",
    "computer algorithm graph sorting depth first interface\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "novel intuitive proof of $\\limit_{x\\to 0} x = 0$ convergence fomula,\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "inflation resources market stock bonds derivatives\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "distribution Bayesian p value marginalization Monte Carlo\n",
    "\"\"\"\n",
    "])\n",
    "\n",
    "label_e.inverse_transform(lsvc.predict(tfidf_v.transform(delatex.transform(random_abstracts ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks promising :)\n",
    "Here's the actual score on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = data[small_num:2*small_num].text\n",
    "y_test = label_e.transform(data[small_num:2*small_num].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = lsvc.predict(tfidf_v.transform(delatex.transform(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.749729642271259\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.82      0.87      0.84      2656\n",
      "        math       0.85      0.88      0.87      4465\n",
      "        phys       0.97      0.95      0.96     12194\n",
      "       q-bio       0.59      0.52      0.55       231\n",
      "       q-fin       0.81      0.69      0.75       110\n",
      "        stat       0.54      0.51      0.53       344\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     20000\n",
      "   macro avg       0.76      0.74      0.75     20000\n",
      "weighted avg       0.91      0.91      0.91     20000\n",
      "\n",
      "[[ 2301   231    60    13     6    45]\n",
      " [  211  3944   225    13     7    65]\n",
      " [  166   353 11602    48     3    22]\n",
      " [   35    17    45   120     0    14]\n",
      " [    9    14     8     0    76     3]\n",
      " [   86    55    15     9     2   177]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro F1:\", f1_score(y_test, predicted_y_test, average=\"macro\"))\n",
    "print(classification_report(y_test, predicted_y_test, target_names=label_e.classes_))\n",
    "print(confusion_matrix(y_test, predicted_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"By definition a confusion matrix $C$ is such that $C_{ij}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\" https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained on 20k records with an untuned Linear SVM, we have reached 0.75 macro-F1 (out of sample) pulled down by poor performomance on classification wrt rarer classes. E.g. many *cs* and *math* are confused with *stat* (and vice versa), and similarly for *q-bio* and *physics*. This is actually sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search with CV by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = []\n",
    "pipe.append(( 'delatex', DeLaTeX(behave='mask') ))\n",
    "pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=False, strip_accents='unicode', min_df = 2, max_df = 0.8)  ))\n",
    "pipe.append(( 'LinearSVC', LinearSVC(C=1, penalty='l2', class_weight='balanced')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delatex__behave': ['mask', None],\n",
       " 'tfidf_v__ngram_range': [(1, 1), (1, 2)],\n",
       " 'tfidf_v__use_idf': [False, True],\n",
       " 'tfidf_v__max_df': [0.7, 0.9],\n",
       " 'LinearSVC__C': [0.1, 1]}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'delatex__behave': ['mask', None],\n",
    "    'tfidf_v__ngram_range': [(1, 1),(1,2)],\n",
    "    'tfidf_v__use_idf': [False, True],\n",
    "    'tfidf_v__max_df': [0.7, 0.9],\n",
    "}\n",
    "params['LinearSVC' + '__' + 'C'] = [0.1, 1]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave=None)), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2'...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=False, n_jobs=1,\n",
       "       param_grid={'delatex__behave': ['mask', None], 'tfidf_v__ngram_range': [(1, 1), (1, 2)], 'tfidf_v__use_idf': [False, True], 'tfidf_v__max_df': [0.7, 0.9], 'LinearSVC__C': [0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LONG WAIT\n",
    "\n",
    "# there's some bug with njobs different than 1 because of the delatex in the pipe\n",
    "\n",
    "grid_s = GridSearchCV(Pipeline(pipe), params, cv=5, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False)\n",
    "grid_s.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC__C': 0.1,\n",
       " 'delatex__behave': 'mask',\n",
       " 'tfidf_v__max_df': 0.7,\n",
       " 'tfidf_v__ngram_range': (1, 1),\n",
       " 'tfidf_v__use_idf': True}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.762059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.762059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.760856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.760856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.748585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.748585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.746615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.746615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.734054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.734054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.732154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.732154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave param_tfidf_v__ngram_range param_tfidf_v__use_idf  \\\n",
       "17                  mask                     (1, 1)                   True   \n",
       "25                  None                     (1, 1)                   True   \n",
       "21                  mask                     (1, 1)                   True   \n",
       "29                  None                     (1, 1)                   True   \n",
       "20                  mask                     (1, 1)                  False   \n",
       "28                  None                     (1, 1)                  False   \n",
       "16                  mask                     (1, 1)                  False   \n",
       "24                  None                     (1, 1)                  False   \n",
       "19                  mask                     (1, 2)                   True   \n",
       "27                  None                     (1, 2)                   True   \n",
       "23                  mask                     (1, 2)                   True   \n",
       "31                  None                     (1, 2)                   True   \n",
       "22                  mask                     (1, 2)                  False   \n",
       "30                  None                     (1, 2)                  False   \n",
       "18                  mask                     (1, 2)                  False   \n",
       "26                  None                     (1, 2)                  False   \n",
       "1                   mask                     (1, 1)                   True   \n",
       "9                   None                     (1, 1)                   True   \n",
       "5                   mask                     (1, 1)                   True   \n",
       "13                  None                     (1, 1)                   True   \n",
       "7                   mask                     (1, 2)                   True   \n",
       "15                  None                     (1, 2)                   True   \n",
       "3                   mask                     (1, 2)                   True   \n",
       "11                  None                     (1, 2)                   True   \n",
       "0                   mask                     (1, 1)                  False   \n",
       "8                   None                     (1, 1)                  False   \n",
       "4                   mask                     (1, 1)                  False   \n",
       "12                  None                     (1, 1)                  False   \n",
       "6                   mask                     (1, 2)                  False   \n",
       "14                  None                     (1, 2)                  False   \n",
       "2                   mask                     (1, 2)                  False   \n",
       "10                  None                     (1, 2)                  False   \n",
       "\n",
       "   param_tfidf_v__max_df param_LinearSVC__C  mean_test_score  \n",
       "17                   0.7                  1         0.753318  \n",
       "25                   0.7                  1         0.753318  \n",
       "21                   0.9                  1         0.751887  \n",
       "29                   0.9                  1         0.751887  \n",
       "20                   0.9                  1         0.744601  \n",
       "28                   0.9                  1         0.744601  \n",
       "16                   0.7                  1         0.737964  \n",
       "24                   0.7                  1         0.737964  \n",
       "19                   0.7                  1         0.736053  \n",
       "27                   0.7                  1         0.736053  \n",
       "23                   0.9                  1         0.734947  \n",
       "31                   0.9                  1         0.734947  \n",
       "22                   0.9                  1         0.723301  \n",
       "30                   0.9                  1         0.723301  \n",
       "18                   0.7                  1         0.722968  \n",
       "26                   0.7                  1         0.722968  \n",
       "1                    0.7                0.1         0.762059  \n",
       "9                    0.7                0.1         0.762059  \n",
       "5                    0.9                0.1         0.760856  \n",
       "13                   0.9                0.1         0.760856  \n",
       "7                    0.9                0.1         0.748585  \n",
       "15                   0.9                0.1         0.748585  \n",
       "3                    0.7                0.1         0.746615  \n",
       "11                   0.7                0.1         0.746615  \n",
       "0                    0.7                0.1         0.744710  \n",
       "8                    0.7                0.1         0.744710  \n",
       "4                    0.9                0.1         0.744347  \n",
       "12                   0.9                0.1         0.744347  \n",
       "6                    0.9                0.1         0.734054  \n",
       "14                   0.9                0.1         0.734054  \n",
       "2                    0.7                0.1         0.732154  \n",
       "10                   0.7                0.1         0.732154  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_s.cv_results_)\n",
    "cols = ['param_' + param for param in params.keys()] + ['mean_test_score']\n",
    "\n",
    "results[cols].sort_values(by=['param_LinearSVC__C','mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regards to our preprocessing steps:\n",
    "    * our DeLaTeX does not help at all\n",
    "    * it is better to use IDF\n",
    "    * max_df=0.7 is slightly better than 0.9\n",
    "    * using 1-grams alone in the count-vectorizer proved to be no visibly better than adding *2grams*\n",
    "   \n",
    "### We will stick to those settings in tuning the classifiers' hyperparameters below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated GridSearchCV for multiple classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(name, model):\n",
    "    pipe = []\n",
    "    #pipe.append(( 'delatex', DeLaTeX(behave='flag') ))\n",
    "    pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=True, strip_accents='unicode', min_df = 2, max_df = 0.7)  ))\n",
    "    pipe.append(( name, model  ))\n",
    "    \n",
    "    return Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe_params(name, model_params):\n",
    "    params = {\n",
    "        #'delatex__behave': [None],\n",
    "        'tfidf_v__ngram_range': [(1, 1)],\n",
    "        'tfidf_v__use_idf': [True],\n",
    "        'tfidf_v__max_df': [0.7],\n",
    "    }\n",
    "    for (param_name, range_) in model_params:\n",
    "        params[name + '__' + param_name] = range_\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify models with grid of parametrs and run the GridSearchCV, cv=5 (stratified by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearSVC': [LinearSVC(class_weight='balanced'),\n",
    "                  [( 'C', [1] )]\n",
    "                 ],\n",
    "    'LogisticR': [LogisticRegression(class_weight='balanced', solver='lbfgs', multi_class='ovr'),\n",
    "                  [( 'C', [1] )]\n",
    "                 ],\n",
    "    'RandomFC': [RandomForestClassifier(class_weight='balanced', n_estimators=100, ),\n",
    "                 [('max_depth', [20]) , ('min_samples_leaf', [10])]\n",
    "                ],\n",
    "    'MulinomNB': [MultinomialNB(),\n",
    "                [('alpha', [1]), ('fit_prior', [True])]\n",
    "               ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "0.7533176359424341 \n",
      "\n",
      "LogisticR\n",
      "0.7461565618083735 \n",
      "\n",
      "RandomFC\n",
      "0.6563406624672407 \n",
      "\n",
      "MulinomNB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olspa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\olspa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\olspa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\olspa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\olspa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4254312712328293 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GRID-SEARCH\n",
    "\n",
    "# collect the best_params for the models\n",
    "results = {}\n",
    "\n",
    "for name, (model, model_params) in models.items():\n",
    "    \n",
    "    print(name)\n",
    "    pipe = build_clf(name, model)\n",
    "    params = build_pipe_params(name, model_params)\n",
    "    \n",
    "    grid_s = GridSearchCV(pipe, params, cv=5, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False)\n",
    "    grid_s.fit(text_train, y_train)\n",
    "    \n",
    "    print(grid_s.best_score_, \"\\n\")\n",
    "    results[name] = [grid_s.best_params_, grid_s.best_score_, grid_s.cv_results_]\n",
    "\n",
    "    \n",
    "# store the best_params in the models dict\n",
    "for name, result in results.items():\n",
    "    \n",
    "    best_params = result[0]    \n",
    "    print(name, best_params)\n",
    "    models[name][1] = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the whole train data to the tuned classifiers. Record final scores on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_num = 30_000\n",
    "train_vol = int(large_num*4/5)\n",
    "\n",
    "final_train = data[:train_vol]\n",
    "final_test = data[train_vol:large_num]\n",
    "\n",
    "\n",
    "final_text_train = final_train.text\n",
    "final_y_train = label_e.transform(final_train.label)\n",
    "\n",
    "final_text_test = final_test.text\n",
    "final_y_test = label_e.transform(final_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olspa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "final_scores = {}\n",
    "\n",
    "for name, (model, pipe_best_params) in models.items():\n",
    "    \n",
    "    clf = build_clf(name, model)\n",
    "    clf.set_params(**pipe_best_params)\n",
    "    clf.fit(final_text_train, final_y_train)\n",
    "    \n",
    "    final_scores[name] = f1_score(final_y_test, clf.predict(final_text_test), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC': 0.7499445806947218,\n",
       " 'LogisticR': 0.7695364539630752,\n",
       " 'RandomFC': 0.6634326117503377,\n",
       " 'MulinomNB': 0.4250664956892689}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = range(len(final_scores))\n",
    "plt.bar(count, list(final_scores.values()))\n",
    "plt.xticks(count, list(final_scores.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
