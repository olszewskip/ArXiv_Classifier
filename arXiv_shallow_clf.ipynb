{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import SCORERS, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer #, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "#from sklearn.linear_model import SGDlassifier(loss = ...) # loss='hinge'/'log'\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "### Bag od words with SVMs, Log-Regression, Random-Forest etc. on top \n",
    "\n",
    "* Build and test a preprocessing pipe:\n",
    "    * Handle *LaTeX* formulas before count-vectorizatation and TFIDF transformation.\n",
    "    * Test a handful of preprocessing parameters (inc. 2-grams, idf switched on/off, maximal document frequency) with a single untuned classifier.\n",
    "* Test a handful of shallow multiclass classifiers with *macro-F1* as the objective, this time without broadly changing the preprocessing parameters:\n",
    "* The grid-search in both step is (likely) performed on a fraction of the train data.\n",
    "* Fit the tuned classifiers to the whole of train data.\n",
    "* Collect the *macro-f1* scores obtained on the test data.\n",
    "* ... Save the best fitted model to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the measure of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available scikit-learn's scorers\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my choice\n",
    "scoring = \"f1_macro\"\n",
    "average = \"macro\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the two-column data frame (text + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"data\", \"bare_all.csv\")\n",
    "\n",
    "data = pd.read_csv(file, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample of records to play with\n",
    "small_num = 200_000\n",
    "sample = data[:small_num]\n",
    "\n",
    "text = sample.text\n",
    "label = sample.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. all records in memory: 836551\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The\\r\\n  Serpens YSO Population As Observed With ...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On-line Viterbi Algorithm and Its Relationship to Random Walks   In this paper, we introduce the on-line Viterbi alg...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dynamical Objects for Cohomologically Expanding Maps   The goal of this paper is to construct invariant dynamical ob...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      text  \\\n",
       "0  The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The\\r\\n  Serpens YSO Population As Observed With ...   \n",
       "1  On-line Viterbi Algorithm and Its Relationship to Random Walks   In this paper, we introduce the on-line Viterbi alg...   \n",
       "2  Dynamical Objects for Cohomologically Expanding Maps   The goal of this paper is to construct invariant dynamical ob...   \n",
       "\n",
       "  label  \n",
       "0  phys  \n",
       "1    cs  \n",
       "2  math  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"No. all records in memory: {len(data)}\")\n",
    "with pd.option_context('display.max_colwidth', 120):\n",
    "    display(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts of scientific papers tend to be written in a formal style, to not contain typos, nor direct citations, little references, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing a quantum game on polarization vortices   The quantum mechanical approach to the well known prisoners dilemma, one of\r",
      "\r\n",
      "the basic examples to illustrate the concepts of Game Theory, is implemented\r",
      "\r\n",
      "with a classical optical resource, nonquantum entanglement between spin and\r",
      "\r\n",
      "orbital degrees of freedom of laser modes. The concept of entanglement is\r",
      "\r\n",
      "crucial in the quantum version of the game, which brings novel features with a\r",
      "\r\n",
      "richer universe of strategies. As we show, this richness can be achieved in a\r",
      "\r\n",
      "quite unexpected context, namely that of paraxial spin-orbit modes in classical\r",
      "\r\n",
      "optics.\r",
      "\r\n",
      "\n",
      "---\n",
      "Ten Years of Precision Electroweak Physics   We review a number of theoretical developments in Precision Electroweak\r",
      "\r\n",
      "Physics that are closely connected with the interpretation of experiments. The\r",
      "\r\n",
      "emphasis is on the test of the Standard Model at the level of its quantum\r",
      "\r\n",
      "corrections, the search for the Higgs boson, and constraints on new physics.\r",
      "\r\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(text.iloc[random.choice(range(len(text)))])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One messy but informative kind of writing they have are LaTeX formulas (*\\$...\\$*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Refuting the Pseudo Attack on the REESSE1+ Cryptosystem   We illustrate through example 1 and 2 that the condition at theorem 1 in [8]\\r\\ndissatisfies necessity, and the converse proposition of fact 1.1 in [8] does\\r\\nnot hold, namely the condition Z/M - L/Ak < 1/(2 Ak^2) is not sufficient for\\r\\nf(i) + f(j) = f(k). Illuminate through an analysis and ex.3 that there is a\\r\\nlogic error during deduction of'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[6][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose to either mask them with * \\_latex\\_ * or flag them by appending * \\_latex\\_ * in front of each such expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask or flag LaTeX expression with a word ' _LATEX_ '\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "    # self.pattern = r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\"\n",
    "    # why does it differ from  r'(\\$.+?\\$)' ?\n",
    "    \n",
    "class DeLaTeX(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, behave=None, pattern=r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\", repl = ' _LATEX_ '):\n",
    "        self.repl = ' _LATEX_ '\n",
    "        self.pattern = pattern\n",
    "        self.behave = behave\n",
    "        \n",
    "        if self.behave == 'mask':\n",
    "            self.repl = ' _LATEX_ '\n",
    "        elif self.behave == 'flag':\n",
    "            self.repl = r' _LATEX_ \\1'\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.core.series.Series):\n",
    "            raise TypeError(\"The data must be a pandas Series of strings\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.behave:\n",
    "            return X.str.replace(self.pattern, self.repl)\n",
    "        return X\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.estimator_checks import check_estimator\n",
    "# check_estimator(DeLaTeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group $\\\\Gamma$ on a single element $\\\\psi$ of a given Hilbert space $\\\\mathcal{H}$. As $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the $L^1$-space associated to the group von Neumann algebra of $\\\\Gamma$. Our result generalizes recent work for LCA groups. In many cases, the b'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = None)\n",
    "delatex.transform(text[6:7]).iloc[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_  on a single element  _LATEX_  of a given Hilbert space  _LATEX_ . As  _LATEX_  might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ -space associated to the group von Neumann algebra of  _LATEX_ . Our result generalizes recent work for LCA groups. In many cases,'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'mask')\n",
    "delatex.transform(text[6:7]).iloc[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_ $\\\\Gamma$ on a single element  _LATEX_ $\\\\psi$ of a given Hilbert space  _LATEX_ $\\\\mathcal{H}$. As  _LATEX_ $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ $L^1$-space associated to the group von Neumann algebra of  _LATEX_ $\\\\Gamma$. Our result genera'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "delatex.transform(text[6:7]).iloc[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs', 'math', 'phys', 'q-bio', 'q-fin', 'stat']\n"
     ]
    }
   ],
   "source": [
    "# 'cs' -> 0, ..., 'stat' -> 5\n",
    "\n",
    "label_e = LabelEncoder()\n",
    "y_train = label_e.fit_transform(label)\n",
    "\n",
    "print(list(label_e.classes_))\n",
    "\n",
    "#label_e.inverse_transform([0]) # array(['cs'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the most frequent words. Choose winners as the stop-words.\n",
    "Take note of the rank of our '\\_latex\\_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 122807)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "count_v = CountVectorizer(strip_accents='unicode')\n",
    "word_counts_train = count_v.fit_transform(delatex.fit_transform(text))\n",
    "word_counts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1057000, 'the'),\n",
       " (670000, 'of'),\n",
       " (370000, 'and'),\n",
       " (332000, 'in'),\n",
       " (277000, 'to'),\n",
       " (213000, 'we'),\n",
       " (195000, 'is'),\n",
       " (181000, 'for'),\n",
       " (180000, '_latex_'),\n",
       " (142000, 'that')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_word_counts_train = word_counts_train.sum(axis=0)\n",
    "sorted([(round(sum_word_counts_train[0, i],-3), word) for word, i in count_v.vocabulary_.items()],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['the', 'of', 'and', 'in','to','we','is'] # 'for' seems already mathematical/computer-sciency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go step by step through an arbitrary pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train = text\n",
    "text_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX(behave='mask')\n",
    "tex_text_train = delatex.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(use_idf=True, stop_words=stopwords, min_df = 2, max_df=0.8, strip_accents='unicode')\n",
    "tfidf_scores_train = tfidf_v.fit_transform(tex_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1, class_weight='balanced')\n",
    "lsvc.fit(tfidf_scores_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's just have some fun first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_abstracts = pd.Series([\"\"\"\n",
    "The Lack of A Priori Distinctions Between Learning Algorithms. This is the first of\n",
    "two papers that use off-training set (OTS) error to investigate the assumption-free\n",
    "relationship between learning algorithms. This first paper discusses the senses in\n",
    "which there are no a priori distinctions between learning algorithms. (The second\n",
    "paper discusses the senses in which there are such distinctions.) In this first paper\n",
    "it is shown, loosely speaking, that for any two algorithms A and B, there are \"as many\"\n",
    "targets (or priors over targets) for which A has lower expected OTS error than B as\n",
    "vice versa, for loss functions like zero-one loss. In particular, this is true if A\n",
    "is cross-validation and B is \"anti-cross-validation'' (choose the learning algorithm\n",
    "with largest cross-validation error). This paper ends with a discussion of the\n",
    "implications of these results for computational learning theory. It is shown that one\n",
    "cannot say: if empirical misclassification rate is low, the Vapnik-Chervonenkis\n",
    "dimension of your generalizer is small, and the training set is large, then with high\n",
    "probability your OTS error is small. Other implications for \"membership queries\"\n",
    "algorithms and \"punting\" algorithms are also discussed.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "X-rays quarks lepton scattering experiment field\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "genes DNA RNA sequencing protein species fenotype \n",
    "\"\"\",\n",
    "\"\"\"\n",
    "computer algorithm graph sorting depth first interface\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "novel intuitive proof of $\\limit_{x\\to 0} x = 0$ convergence fomula,\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "inflation resources market stock bonds derivatives\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "distribution Bayesian p value marginalization Monte Carlo\n",
    "\"\"\"\n",
    "])\n",
    "\n",
    "label_e.inverse_transform(lsvc.predict(tfidf_v.transform(delatex.transform(random_abstracts ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks promising :)\n",
    "Here's the actual score on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = data[small_num:2*small_num].text\n",
    "y_test = label_e.transform(data[small_num:2*small_num].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = lsvc.predict(tfidf_v.transform(delatex.transform(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.7882150751626531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.83      0.87      0.85     25755\n",
      "        math       0.90      0.91      0.90     47881\n",
      "        phys       0.98      0.96      0.97    118753\n",
      "       q-bio       0.66      0.69      0.67      3040\n",
      "       q-fin       0.75      0.82      0.78      1231\n",
      "        stat       0.54      0.57      0.55      3340\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    200000\n",
      "   macro avg       0.78      0.80      0.79    200000\n",
      "weighted avg       0.93      0.92      0.93    200000\n",
      "\n",
      "[[ 22535   1701    679    220     58    562]\n",
      " [  1973  43453   1453    190    137    675]\n",
      " [  1395   2591 113869    589     87    222]\n",
      " [   274    119    398   2090      7    152]\n",
      " [    57     87     52      4   1004     27]\n",
      " [   810    364    142     85     46   1893]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro F1:\", f1_score(y_test, predicted_y_test, average=\"macro\"))\n",
    "print(classification_report(y_test, predicted_y_test, target_names=label_e.classes_))\n",
    "nofuss_conf_mtrx = confusion_matrix(y_test, predicted_y_test)\n",
    "print(nofuss_conf_mtrx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"By definition a confusion matrix $C$ is such that $C_{ij}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\" https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained on a fraction of all records with an untuned Linear SVM, we have reached ~0.78 macro-F1 (out of sample) pulled down by poor performomance on classification wrt rarer classes. E.g. many *cs* and *math* are confused with *stat* (and vice versa), and similarly for *q-bio* and *physics*. This is actually sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid searching by hand through preprocessing params with Linear SVM Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = []\n",
    "pipe.append(( 'delatex', DeLaTeX(behave='mask') ))\n",
    "pipe.append(( 'tfidf_v', TfidfVectorizer(analyzer = 'word', strip_accents='unicode', min_df = 2)  ))\n",
    "pipe.append(( 'LinearSVC', LinearSVC(C=1, penalty='l2', class_weight='balanced')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delatex__behave': ['mask', None],\n",
       " 'tfidf_v__stop_words': [['the', 'of', 'and', 'in', 'to', 'we', 'is'], None],\n",
       " 'tfidf_v__ngram_range': [(1, 1), (1, 2)],\n",
       " 'tfidf_v__use_idf': [True, False],\n",
       " 'tfidf_v__max_df': [0.6, 0.75, 0.9],\n",
       " 'LinearSVC__C': [0.2, 2]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'delatex__behave': ['mask', None],\n",
    "    'tfidf_v__stop_words': [stopwords, None],\n",
    "    'tfidf_v__ngram_range': [(1, 1), (1,2)],\n",
    "    'tfidf_v__use_idf': [True, False],\n",
    "    'tfidf_v__max_df': [0.6, 0.75, 0.9],\n",
    "}\n",
    "params['LinearSVC' + '__' + 'C'] = [0.2, 2]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 96 candidates, totalling 384 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 384 out of 384 | elapsed: 258.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave='mask',\n",
       "    pattern='(\\\\${1,2}[\\\\s\\\\w\\\\d\\\\\\\\,\\\\.=\\\\(\\\\)*{}/\\\\[\\\\]^;:\\'`<>|%&@\\\\\"!\\\\?~#+-]*?\\\\${1,2})',\n",
       "    repl=' _LATEX_ ')), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=False, n_jobs=1,\n",
       "       param_grid={'delatex__behave': ['mask', None], 'tfidf_v__stop_words': [['the', 'of', 'and', 'in', 'to', 'we', 'is'], None], 'tfidf_v__ngram_range': [(1, 1), (1, 2)], 'tfidf_v__use_idf': [True, False], 'tfidf_v__max_df': [0.6, 0.75, 0.9], 'LinearSVC__C': [0.2, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LONG WAIT\n",
    "\n",
    "# there's some bug with njobs different than 1 because of the delatex in the pipe\n",
    "# may be related to the fact that check_estimator(DeLaTeX) raises an error due to DeLaTeX using the pandas' vectorized str method \n",
    "\n",
    "grid_s = GridSearchCV(Pipeline(pipe), params, cv=4, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False, verbose=1)\n",
    "grid_s.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7912419492069807"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC__C': 0.2,\n",
       " 'delatex__behave': 'mask',\n",
       " 'tfidf_v__max_df': 0.6,\n",
       " 'tfidf_v__ngram_range': (1, 2),\n",
       " 'tfidf_v__stop_words': None,\n",
       " 'tfidf_v__use_idf': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_results = pd.DataFrame(grid_s.cv_results_)\n",
    "cols = ['param_' + param for param in params.keys()] + ['mean_test_score']\n",
    "results_df = grid_cv_results[cols].sort_values(by=['mean_test_score','param_delatex__behave','param_tfidf_v__max_df'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.791242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.791209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.790569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.790383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.790162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.789770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "6                   mask                            None   \n",
       "30                  None                            None   \n",
       "38                  None                            None   \n",
       "46                  None                            None   \n",
       "14                  mask                            None   \n",
       "22                  mask                            None   \n",
       "28                  None  [the, of, and, in, to, we, is]   \n",
       "4                   mask  [the, of, and, in, to, we, is]   \n",
       "44                  None  [the, of, and, in, to, we, is]   \n",
       "36                  None  [the, of, and, in, to, we, is]   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "6                      (1, 2)                   True                   0.6   \n",
       "30                     (1, 2)                   True                   0.6   \n",
       "38                     (1, 2)                   True                  0.75   \n",
       "46                     (1, 2)                   True                   0.9   \n",
       "14                     (1, 2)                   True                  0.75   \n",
       "22                     (1, 2)                   True                   0.9   \n",
       "28                     (1, 2)                   True                   0.6   \n",
       "4                      (1, 2)                   True                   0.6   \n",
       "44                     (1, 2)                   True                   0.9   \n",
       "36                     (1, 2)                   True                  0.75   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "6                 0.2         0.791242  \n",
       "30                0.2         0.791209  \n",
       "38                0.2         0.790569  \n",
       "46                0.2         0.790383  \n",
       "14                0.2         0.790162  \n",
       "22                0.2         0.789770  \n",
       "28                0.2         0.788460  \n",
       "4                 0.2         0.788429  \n",
       "44                0.2         0.788314  \n",
       "36                0.2         0.788314  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 0.2) & (results_df.param_tfidf_v__ngram_range==(1,2))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.780536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.780056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.780056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.778934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.778753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "29                  None  [the, of, and, in, to, we, is]   \n",
       "21                  mask  [the, of, and, in, to, we, is]   \n",
       "13                  mask  [the, of, and, in, to, we, is]   \n",
       "7                   mask                            None   \n",
       "47                  None                            None   \n",
       "45                  None  [the, of, and, in, to, we, is]   \n",
       "37                  None  [the, of, and, in, to, we, is]   \n",
       "23                  mask                            None   \n",
       "15                  mask                            None   \n",
       "39                  None                            None   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "29                     (1, 2)                  False                   0.6   \n",
       "21                     (1, 2)                  False                   0.9   \n",
       "13                     (1, 2)                  False                  0.75   \n",
       "7                      (1, 2)                  False                   0.6   \n",
       "47                     (1, 2)                  False                   0.9   \n",
       "45                     (1, 2)                  False                   0.9   \n",
       "37                     (1, 2)                  False                  0.75   \n",
       "23                     (1, 2)                  False                   0.9   \n",
       "15                     (1, 2)                  False                  0.75   \n",
       "39                     (1, 2)                  False                  0.75   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "29                0.2         0.780536  \n",
       "21                0.2         0.780056  \n",
       "13                0.2         0.780056  \n",
       "7                 0.2         0.779726  \n",
       "47                0.2         0.779349  \n",
       "45                0.2         0.779298  \n",
       "37                0.2         0.779298  \n",
       "23                0.2         0.779035  \n",
       "15                0.2         0.778934  \n",
       "39                0.2         0.778753  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 0.2) & (results_df.param_tfidf_v__ngram_range==(1,2))][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.783177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.783177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.783177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "40                  None  [the, of, and, in, to, we, is]   \n",
       "32                  None  [the, of, and, in, to, we, is]   \n",
       "34                  None                            None   \n",
       "42                  None                            None   \n",
       "24                  None  [the, of, and, in, to, we, is]   \n",
       "26                  None                            None   \n",
       "16                  mask  [the, of, and, in, to, we, is]   \n",
       "8                   mask  [the, of, and, in, to, we, is]   \n",
       "10                  mask                            None   \n",
       "0                   mask  [the, of, and, in, to, we, is]   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "40                     (1, 1)                   True                   0.9   \n",
       "32                     (1, 1)                   True                  0.75   \n",
       "34                     (1, 1)                   True                  0.75   \n",
       "42                     (1, 1)                   True                   0.9   \n",
       "24                     (1, 1)                   True                   0.6   \n",
       "26                     (1, 1)                   True                   0.6   \n",
       "16                     (1, 1)                   True                   0.9   \n",
       "8                      (1, 1)                   True                  0.75   \n",
       "10                     (1, 1)                   True                  0.75   \n",
       "0                      (1, 1)                   True                   0.6   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "40                0.2         0.783177  \n",
       "32                0.2         0.783177  \n",
       "34                0.2         0.783177  \n",
       "42                0.2         0.782992  \n",
       "24                0.2         0.782940  \n",
       "26                0.2         0.782940  \n",
       "16                0.2         0.782872  \n",
       "8                 0.2         0.782872  \n",
       "10                0.2         0.782872  \n",
       "0                 0.2         0.782364  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 0.2) & (results_df.param_tfidf_v__ngram_range==(1,1))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.784678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.784561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "54                  mask                            None   \n",
       "70                  mask                            None   \n",
       "62                  mask                            None   \n",
       "94                  None                            None   \n",
       "86                  None                            None   \n",
       "78                  None                            None   \n",
       "92                  None  [the, of, and, in, to, we, is]   \n",
       "84                  None  [the, of, and, in, to, we, is]   \n",
       "68                  mask  [the, of, and, in, to, we, is]   \n",
       "60                  mask  [the, of, and, in, to, we, is]   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "54                     (1, 2)                   True                   0.6   \n",
       "70                     (1, 2)                   True                   0.9   \n",
       "62                     (1, 2)                   True                  0.75   \n",
       "94                     (1, 2)                   True                   0.9   \n",
       "86                     (1, 2)                   True                  0.75   \n",
       "78                     (1, 2)                   True                   0.6   \n",
       "92                     (1, 2)                   True                   0.9   \n",
       "84                     (1, 2)                   True                  0.75   \n",
       "68                     (1, 2)                   True                   0.9   \n",
       "60                     (1, 2)                   True                  0.75   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "54                  2         0.784678  \n",
       "70                  2         0.784561  \n",
       "62                  2         0.783827  \n",
       "94                  2         0.783620  \n",
       "86                  2         0.783560  \n",
       "78                  2         0.783283  \n",
       "92                  2         0.783071  \n",
       "84                  2         0.783071  \n",
       "68                  2         0.783070  \n",
       "60                  2         0.783070  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 2) & (results_df.param_tfidf_v__ngram_range==(1,2))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "83                  None                            None   \n",
       "64                  mask  [the, of, and, in, to, we, is]   \n",
       "56                  mask  [the, of, and, in, to, we, is]   \n",
       "58                  mask                            None   \n",
       "72                  None  [the, of, and, in, to, we, is]   \n",
       "74                  None                            None   \n",
       "48                  mask  [the, of, and, in, to, we, is]   \n",
       "50                  mask                            None   \n",
       "73                  None  [the, of, and, in, to, we, is]   \n",
       "75                  None                            None   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "83                     (1, 1)                  False                  0.75   \n",
       "64                     (1, 1)                   True                   0.9   \n",
       "56                     (1, 1)                   True                  0.75   \n",
       "58                     (1, 1)                   True                  0.75   \n",
       "72                     (1, 1)                   True                   0.6   \n",
       "74                     (1, 1)                   True                   0.6   \n",
       "48                     (1, 1)                   True                   0.6   \n",
       "50                     (1, 1)                   True                   0.6   \n",
       "73                     (1, 1)                  False                   0.6   \n",
       "75                     (1, 1)                  False                   0.6   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "83                  2         0.768993  \n",
       "64                  2         0.768403  \n",
       "56                  2         0.768403  \n",
       "58                  2         0.768403  \n",
       "72                  2         0.768203  \n",
       "74                  2         0.768203  \n",
       "48                  2         0.767866  \n",
       "50                  2         0.767866  \n",
       "73                  2         0.767772  \n",
       "75                  2         0.767772  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 2) & (results_df.param_tfidf_v__ngram_range==(1,1))][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regards to our preprocessing steps:\n",
    "    * By and large the search was performed over unimportant parameters.\n",
    "    * The most important ones (at the level of gaining 0.8 percentage points), aside from the model's *C*, were: using (1,2)-word-grams rather than 1-word-grams and using IDFs over not using it.\n",
    "    * The influence of max_df is small and not very consistent.\n",
    "    * Our DeLaTeX behavior and stopwords have no significant effect.\n",
    "   \n",
    "In light of the above we will stick to:\n",
    "    * no DeLaTeX\n",
    "    * no stop-words\n",
    "    * (1,2)-grams\n",
    "    * using IDFs\n",
    "    * no max_df limit (meaning the default =1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated GridSearchCV for multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train = text\n",
    "text_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(name, model):\n",
    "    pipe = []\n",
    "    #pipe.append(( 'delatex', DeLaTeX(behave='flag') ))\n",
    "    pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=True, strip_accents='unicode', min_df = 2, ngram_range=(1,2))  ))\n",
    "    pipe.append(( name, model  ))\n",
    "    \n",
    "    return Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe_params(name, model_params):\n",
    "    params = {\n",
    "        #'delatex__behave': [None],  # (bug) switch off in order to use n_jobs in GridSearchCV\n",
    "        #'tfidf_v__ngram_range': [(1, 1), (1,2)],\n",
    "        #'tfidf_v__use_idf': [True, False],\n",
    "        #'tfidf_v__max_df': [0.8, 1.0],\n",
    "    }\n",
    "    for (param_name, range_) in model_params:\n",
    "        params[name + '__' + param_name] = range_\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify models with grid of parametrs and run the GridSearchCV, cv=4 (stratified by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \n",
    "#     'rbfSVC': [SVC(class_weight='balanced', gamma='scale'),\n",
    "#             [( 'C', [0.04, 0.2, 1, 5] )]\n",
    "#            ],\n",
    "    'LogReg': [LogisticRegression(class_weight='balanced', solver='lbfgs', multi_class='multinomial', max_iter=500),\n",
    "                  [( 'C', [0.04, 0.2, 1, 5] ), ('multi_class', ['multinomial','ovr'])]\n",
    "                 ],\n",
    "    'RndFClf': [RandomForestClassifier(class_weight='balanced', n_estimators=300),\n",
    "                 [('max_depth', [10, 20, 30]) , ('min_samples_leaf', [ 1E-4, 1E-3, 1E-2])]\n",
    "                ],\n",
    "    'LinSVC': [LinearSVC(class_weight='balanced'),\n",
    "                  [( 'C', [0.04, 0.2, 1, 5] )]\n",
    "                 ],\n",
    "    'NearCen': [NearestCentroid(),\n",
    "                [('metric', ['euclidean','manhattan'])]\n",
    "               ],\n",
    "    'MultNB': [MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None),\n",
    "                [('alpha', [0.01, 0.1, 1])]\n",
    "               ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=3)]: Done  32 out of  32 | elapsed: 231.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7987186309082982 \n",
      "\n",
      "RndFClf\n",
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=3)]: Done  36 out of  36 | elapsed: 103.3min finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6681091393505779 \n",
      "\n",
      "LinSVC\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=3)]: Done  16 out of  16 | elapsed: 23.5min finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8029163408055535 \n",
      "\n",
      "NearCen\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   8 out of   8 | elapsed: 138.5min finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6922020578147665 \n",
      "\n",
      "MultNB\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "0.7769708804092343 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  12 out of  12 | elapsed: 13.9min finished\n"
     ]
    }
   ],
   "source": [
    "# GRID-SEARCH\n",
    "\n",
    "# collect the best_params for the models\n",
    "results = {}\n",
    "\n",
    "for name, (model, model_params) in models.items():\n",
    "    \n",
    "    print(name)\n",
    "    pipe = build_clf(name, model)\n",
    "    params = build_pipe_params(name, model_params)\n",
    "    \n",
    "    grid_s = GridSearchCV(pipe, params, cv=4, scoring=scoring, iid=False, return_train_score=True, n_jobs=3, refit=False, verbose=1)\n",
    "    grid_s.fit(text_train, y_train)\n",
    "    \n",
    "    print(grid_s.best_score_, \"\\n\")\n",
    "    results[name] = [grid_s.best_params_, grid_s.best_score_, grid_s.cv_results_]\n",
    "\n",
    "    \n",
    "# store the best_params in the models dict\n",
    "for name, result in results.items():\n",
    "    \n",
    "    best_params = result[0]    \n",
    "    models[name].append(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=None, max_features='auto',\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=300, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " [('max_depth', [10, 20, 30]), ('min_samples_leaf', [0.0001, 0.001, 0.01])],\n",
       " {'RndFClf__max_depth': 30, 'RndFClf__min_samples_leaf': 0.0001}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the obtaind best_params of Random Forest for example\n",
    "models[\"RndFClf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the whole train data to the tuned classifiers. Record final scores on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_num = 500_000 # len(data)\n",
    "train_vol = int(large_num*3/4)\n",
    "\n",
    "final_train = data[:train_vol]\n",
    "final_test = data[train_vol:large_num]\n",
    "\n",
    "\n",
    "final_text_train = final_train.text\n",
    "final_y_train = label_e.transform(final_train.label)\n",
    "\n",
    "final_text_test = final_test.text\n",
    "final_y_test = label_e.transform(final_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted LogReg.\n",
      "Fitted RndFClf.\n",
      "Fitted LinSVC.\n",
      "Fitted NearCen.\n",
      "Fitted MultNB.\n"
     ]
    }
   ],
   "source": [
    "final_scores = {}\n",
    "\n",
    "for name, (model, grid, pipe_best_params) in models.items():\n",
    "    \n",
    "    clf = build_clf(name, model)\n",
    "    clf.set_params(**pipe_best_params)\n",
    "    clf.fit(final_text_train, final_y_train)\n",
    "    models[name].append(clf)\n",
    "    print(f\"Fitted {name}.\")\n",
    "    \n",
    "    final_scores[name] = f1_score(final_y_test, clf.predict(final_text_test), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinSVC': 0.8001433350980055,\n",
       " 'LogReg': 0.7920095263091622,\n",
       " 'MultNB': 0.7612820516262264,\n",
       " 'NearCen': 0.6338241231661168,\n",
       " 'RndFClf': 0.6055674922626612}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the dict with final F1 scores\n",
    "# save the name of the winner\n",
    "\n",
    "final_scores_list =sorted(final_scores.items(), key=lambda x: x[1], reverse = True)\n",
    "winner = final_scores_list[0][0]\n",
    "final_scores_sorted = {name: score for (name, score) in final_scores_list}\n",
    "final_scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = range(len(final_scores))\n",
    "plt.ylim(0.5, 1)\n",
    "plt.bar(count, list(final_scores_sorted.values()))\n",
    "plt.xticks(count, list(final_scores_sorted.keys()))\n",
    "plt.title(\"Macro F1 scores on unseen quarter of the data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_clf = models[winner][-1]\n",
    "predicted_final_y_test = winner_clf.predict(final_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.82      0.89      0.85      4945\n",
      "        math       0.83      0.90      0.86      8899\n",
      "        phys       0.99      0.98      0.99    109158\n",
      "       q-bio       0.68      0.72      0.70      1002\n",
      "       q-fin       0.78      0.85      0.81       306\n",
      "        stat       0.60      0.57      0.58       690\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    125000\n",
      "   macro avg       0.78      0.82      0.80    125000\n",
      "weighted avg       0.97      0.97      0.97    125000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  4398,    313,    133,     28,     11,     62],\n",
       "       [   291,   7976,    482,     28,     21,    101],\n",
       "       [   432,   1221, 107127,    263,     35,     80],\n",
       "       [    40,     13,    211,    721,      0,     17],\n",
       "       [     6,     13,     24,      0,    260,      3],\n",
       "       [   194,     56,     24,     17,      6,    393]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(final_y_test, predicted_final_y_test, target_names=label_e.classes_))\n",
    "conf_mtrx = confusion_matrix(final_y_test, predicted_final_y_test)\n",
    "conf_mtrx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Statistics* class appears to be escpecially ambigous "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how the articles have flown between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_nofuss = nofuss_conf_mtrx * (large_num-train_vol)/small_num\n",
    "(conf_mtrx - rescaled_nofuss).sum() # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9700.,   -800.,   -300.,   -100.,     -0.,   -300.],\n",
       "       [  -900., -19200.,   -400.,   -100.,   -100.,   -300.],\n",
       "       [  -400.,   -400.,  36000.,   -100.,     -0.,   -100.],\n",
       "       [  -100.,   -100.,     -0.,   -600.,     -0.,   -100.],\n",
       "       [    -0.,     -0.,     -0.,     -0.,   -400.,     -0.],\n",
       "       [  -300.,   -200.,   -100.,     -0.,     -0.,   -800.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(conf_mtrx - rescaled_nofuss, -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The *physics* class simply got inflated a bit and have swallowed more misclassified records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the best model in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinSVC'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LinSVC_arXiv.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib / pickle\n",
    "dump(models[winner], winner+'_arXiv.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       " [('C', [0.04, 0.2, 1, 5])],\n",
       " {'LinSVC__C': 1},\n",
       " Pipeline(memory=None,\n",
       "      steps=[('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "         ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=Tru...ax_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0))])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_model = load(winner+'_arXiv.joblib')\n",
    "some_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_clf = some_model[-1]\n",
    "label_e.inverse_transform(some_clf.predict(random_abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
