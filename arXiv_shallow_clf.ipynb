{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer #, HashingVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "#from sklearn.linear_model import SGDlassifier(loss = ...)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* Build and test a preprocessing pipe:\n",
    "    * Handle *LaTeX* formulas before count-vectorizatation and TFIDF transformation.\n",
    "    * Test a handful of preprocessing parameters (inc. 2-grams, idf switched on/off, maximal document frequency) with a single untuned classifier.\n",
    "* Test a handful of shallow multiclass classifiers with *macro-F1* as the objective, this time without changing the preprocessing parameters:\n",
    "* The grid-search in both step is (likely) performed on a fraction of the train data.\n",
    "* Fit the tuned classifiers to the whole of train data.\n",
    "* Collect the *macro-f1* scores obtained on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the measure of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available scores\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my choice\n",
    "scoring = \"f1_macro\"\n",
    "average = \"macro\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the two-column data frame (text + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"data\", \"bare_all.csv\")\n",
    "\n",
    "data = pd.read_csv(file, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 20k records to play with\n",
    "small_num = 20000\n",
    "sample = data[:small_num]\n",
    "\n",
    "text = sample.text\n",
    "label = sample.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No all records in memory: 837'000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The\\r\\n  Serpens YSO Population As Observed With ...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On-line Viterbi Algorithm and Its Relationship to Random Walks   In this paper, we introduce the on-line Viterbi alg...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dynamical Objects for Cohomologically Expanding Maps   The goal of this paper is to construct invariant dynamical ob...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      text  \\\n",
       "0  The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The\\r\\n  Serpens YSO Population As Observed With ...   \n",
       "1  On-line Viterbi Algorithm and Its Relationship to Random Walks   In this paper, we introduce the on-line Viterbi alg...   \n",
       "2  Dynamical Objects for Cohomologically Expanding Maps   The goal of this paper is to construct invariant dynamical ob...   \n",
       "\n",
       "  label  \n",
       "0  phys  \n",
       "1    cs  \n",
       "2  math  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"No all records in memory: {round(len(data)/1000)}'000\")\n",
    "with pd.option_context('display.max_colwidth', 120):\n",
    "    display(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts of scientific papers tend to be written in a formal style, to not contain typos, nor direct citations, little references, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple Havel-Hakimi type algorithm to realize graphical degree\r\n",
      "  sequences of directed graphs   One of the simplest ways to decide whether a given finite sequence of\r\n",
      "positive integers can arise as the degree sequence of a simple graph is the\r\n",
      "greedy algorithm of Havel and Hakimi. This note extends their approach to\r\n",
      "directed graphs. It also studies cases of some simple forbidden edge-sets.\r\n",
      "Finally, it proves a result which is useful to design an MCMC algorithm to find\r\n",
      "random realizations of prescribed directed degree sequences.\r\n",
      "\n",
      "---\n",
      "Hooke's law correlation in two-electron systems   We study the properties of the Hooke's law correlation energy ($\\Ec$),\r\n",
      "defined as the correlation energy when two electrons interact {\\em via} a\r\n",
      "harmonic potential in a $D$-dimensional space. More precisely, we investigate\r\n",
      "the $^1S$ ground state properties of two model systems: the Moshinsky atom (in\r\n",
      "which the electrons move in a quadratic potential) and the spherium model (in\r\n",
      "which they move on the surface of a sphere). A comparison with their Coulombic\r\n",
      "counterparts is made, which highlights the main differences of the $\\Ec$ in\r\n",
      "both the weakly and strongly correlated limits. Moreover, we show that the\r\n",
      "Schr\\\"odinger equation of the spherium model is exactly solvable for two values\r\n",
      "of the dimension ($D = 1 \\text{and} 3$), and that the exact wave function is\r\n",
      "based on Mathieu functions.\r\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(text.iloc[random.choice(range(len(text)))])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One messy but informative kind of writing they have are LaTeX formulas (*\\$...\\$*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Decomposition numbers for finite Coxeter groups and generalised\\r\\n  non-crossing partitions   Given a finite irreducible Coxeter group $W$, a positive integer $d$, and\\r\\ntypes $T_1,T_2,...,T_d$ (in the sense of the classification of finite Coxeter\\r\\ngroups), we compute the number of decompositions $c=\\\\si_1\\\\si_2 cdots\\\\si_d$ of a\\r\\nCoxeter element $c$ of $W$, such that $\\\\si_i$ is a Coxeter element in a\\r'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[3][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose to either mask them with * \\_latex\\_ * or flag them by appending * \\_latex\\_ * in front of each such expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask or flag LaTeX expression with a word ' _LATEX_ '\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DeLaTeX(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Replace r\"(\\${1,2}[...]*?\\${1,2})\" with ' _latex_ ' or 'latex \\1'\n",
    "    \"\"\"\n",
    "    # why does it differ from  r'(\\$.+?\\$)' ?\n",
    "    \n",
    "    def __init__(self, behave = 'flag'):\n",
    "        self.pattern = r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\"\n",
    "        if behave:\n",
    "            self.repl = ' _LATEX_ ' if behave == 'mask' else  r' _LATEX_ \\1'\n",
    "        else:\n",
    "            self.repl = r'\\1' # do nothing with extra steps\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.str.replace(self.pattern, self.repl)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Decomposition numbers for finite Coxeter groups and generalised\\r\\n  non-crossing partitions   Given a finite irreducible Coxeter group $W$, a positive integer $d$, and\\r\\ntypes $T_1,T_2,...,T_d$ (in the sense of the classification of finite Coxeter\\r\\ngroups), we compute the number of decompositions $c=\\\\si_1\\\\si_2 cdots\\\\si_d$ of a\\r\\nCoxeter element $c$ of $W$, such that $\\\\si_i$ is a Coxeter element in a\\r'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = None)\n",
    "delatex.transform(text[3:4])[3][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Decomposition numbers for finite Coxeter groups and generalised\\r\\n  non-crossing partitions   Given a finite irreducible Coxeter group  _LATEX_ , a positive integer  _LATEX_ , and\\r\\ntypes  _LATEX_  (in the sense of the classification of finite Coxeter\\r\\ngroups), we compute the number of decompositions  _LATEX_  of a\\r\\nCoxeter element  _LATEX_  of  _LATEX_ , such that  _LATEX_  is a Coxeter element in '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'mask')\n",
    "delatex.transform(text[3:4])[3][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Decomposition numbers for finite Coxeter groups and generalised\\r\\n  non-crossing partitions   Given a finite irreducible Coxeter group  _LATEX_ $W$, a positive integer  _LATEX_ $d$, and\\r\\ntypes  _LATEX_ $T_1,T_2,...,T_d$ (in the sense of the classification of finite Coxeter\\r\\ngroups), we compute the number of decompositions  _LATEX_ $c=\\\\si_1\\\\si_2 cdots\\\\si_d$ of a\\r\\nCoxeter element  _LATEX_ $c$ of  _LA'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "delatex.transform(text[3:4])[3][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs', 'math', 'phys', 'q-bio', 'q-fin', 'stat']\n"
     ]
    }
   ],
   "source": [
    "# 'cs' -> 0, ..., 'stat' -> 5\n",
    "\n",
    "label_e = LabelEncoder()\n",
    "y_train = label_e.fit_transform(label)\n",
    "\n",
    "print(list(label_e.classes_))\n",
    "\n",
    "#label_e.inverse_transform([0]) # array(['cs'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optionally, have a look at the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "count_v = CountVectorizer(strip_accents='unicode')\n",
    "word_counts_train = count_v.fit_transform(delatex.fit_transform(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(195000, 'the'),\n",
       " (121000, 'of'),\n",
       " (64000, 'and'),\n",
       " (60000, 'in'),\n",
       " (47000, 'to'),\n",
       " (39000, 'we'),\n",
       " (36000, 'is'),\n",
       " (32000, 'for'),\n",
       " (27000, '_latex_'),\n",
       " (25000, 'with')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_word_counts_train = word_counts_train.sum(axis=0)\n",
    "sorted([(round(sum_word_counts_train[0, i],-3), word) for word, i in count_v.vocabulary_.items()],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go step by step through an arbitrary pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX(behave='flag')\n",
    "tex_text_train = delatex.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(use_idf=True, min_df = 2, max_df=0.8, strip_accents='unicode')\n",
    "tfidf_scores_train = tfidf_v.fit_transform(tex_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1, class_weight='balanced')\n",
    "lsvc.fit(tfidf_scores_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's just have some fun first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'phys'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_abstracts = pd.Series([\"\"\"\n",
    "The Lack of A Priori Distinctions Between Learning Algorithms. This is the first of\n",
    "two papers that use off-training set (OTS) error to investigate the assumption-free\n",
    "relationship between learning algorithms. This first paper discusses the senses in\n",
    "which there are no a priori distinctions between learning algorithms. (The second\n",
    "paper discusses the senses in which there are such distinctions.) In this first paper\n",
    "it is shown, loosely speaking, that for any two algorithms A and B, there are \"as many\"\n",
    "targets (or priors over targets) for which A has lower expected OTS error than B as\n",
    "vice versa, for loss functions like zero-one loss. In particular, this is true if A\n",
    "is cross-validation and B is \"anti-cross-validation'' (choose the learning algorithm\n",
    "with largest cross-validation error). This paper ends with a discussion of the\n",
    "implications of these results for computational learning theory. It is shown that one\n",
    "cannot say: if empirical misclassification rate is low, the Vapnik-Chervonenkis\n",
    "dimension of your generalizer is small, and the training set is large, then with high\n",
    "probability your OTS error is small. Other implications for \"membership queries\"\n",
    "algorithms and \"punting\" algorithms are also discussed.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "X-rays quarks lepton scattering experiment field\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "genes DNA RNA sequencing protein species fenotype \n",
    "\"\"\",\n",
    "\"\"\"\n",
    "computer algorithm graph sorting depth first interface\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "novel intuitive proof of $\\limit_{x\\to 0} x = 0$ convergence fomula,\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "inflation resources market stock bonds derivatives\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "distribution Bayesian p value marginalization Monte Carlo\n",
    "\"\"\"\n",
    "])\n",
    "\n",
    "label_e.inverse_transform(lsvc.predict(tfidf_v.transform(delatex.transform(random_abstracts ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks promising :)\n",
    "Here's the actual score on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = data[small_num:2*small_num].text\n",
    "y_test = label_e.transform(data[small_num:2*small_num].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = lsvc.predict(tfidf_v.transform(delatex.transform(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.7266111723508383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.83      0.87      0.85      2613\n",
      "        math       0.88      0.92      0.90      5484\n",
      "        phys       0.96      0.95      0.95     11319\n",
      "       q-bio       0.55      0.44      0.49       233\n",
      "       q-fin       0.82      0.73      0.77       151\n",
      "        stat       0.63      0.28      0.39       200\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     20000\n",
      "   macro avg       0.78      0.70      0.73     20000\n",
      "weighted avg       0.91      0.91      0.91     20000\n",
      "\n",
      "[[ 2275   224    89    13     5     7]\n",
      " [  191  5037   223    12     5    16]\n",
      " [  173   367 10714    49    11     5]\n",
      " [   40    14    73   103     1     2]\n",
      " [    8    17    13     0   110     3]\n",
      " [   62    51    19     9     2    57]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro F1:\", f1_score(y_test, predicted_y_test, average=\"macro\"))\n",
    "print(classification_report(y_test, predicted_y_test, target_names=label_e.classes_))\n",
    "print(confusion_matrix(y_test, predicted_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"By definition a confusion matrix $C$ is such that $C_{ij}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\" https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained on 20k records with an untuned Linear SVM, we have reached ~0.7 macro-F1 (out of sample) pulled down by poor performomance on classification wrt rarer classes. E.g. many *cs* and *math* are confused with *stat* (and vice versa), and similarly for *q-bio* and *physics*. This is actually sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search with CV by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = []\n",
    "pipe.append(( 'delatex', DeLaTeX(behave='mask') ))\n",
    "pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=False, strip_accents='unicode', min_df = 2, max_df = 0.8)  ))\n",
    "pipe.append(( 'LinearSVC', LinearSVC(C=1, penalty='l2', class_weight='balanced')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delatex__behave': ['mask', None],\n",
       " 'tfidf_v__ngram_range': [(1, 1), (1, 2)],\n",
       " 'tfidf_v__use_idf': [False, True],\n",
       " 'tfidf_v__max_df': [0.7, 0.9],\n",
       " 'LinearSVC__C': [0.1, 1]}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'delatex__behave': ['mask', None],\n",
    "    'tfidf_v__ngram_range': [(1, 1),(1,2)],\n",
    "    'tfidf_v__use_idf': [False, True],\n",
    "    'tfidf_v__max_df': [0.7, 0.9],\n",
    "}\n",
    "params['LinearSVC' + '__' + 'C'] = [0.1, 1]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave=None)), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2'...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=False, n_jobs=1,\n",
       "       param_grid={'delatex__behave': ['mask', None], 'tfidf_v__ngram_range': [(1, 1), (1, 2)], 'tfidf_v__use_idf': [False, True], 'tfidf_v__max_df': [0.7, 0.9], 'LinearSVC__C': [0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LONG WAIT\n",
    "\n",
    "# there's some bug with njobs different than 1 because of the delatex in the pipe\n",
    "\n",
    "grid_s = GridSearchCV(Pipeline(pipe), params, cv=5, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False)\n",
    "grid_s.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC__C': 0.1,\n",
       " 'delatex__behave': 'mask',\n",
       " 'tfidf_v__max_df': 0.7,\n",
       " 'tfidf_v__ngram_range': (1, 1),\n",
       " 'tfidf_v__use_idf': True}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.762059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.762059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.760856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.760856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.748585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.748585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.746615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.746615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.734054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.734054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.732154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.732154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave param_tfidf_v__ngram_range param_tfidf_v__use_idf  \\\n",
       "17                  mask                     (1, 1)                   True   \n",
       "25                  None                     (1, 1)                   True   \n",
       "21                  mask                     (1, 1)                   True   \n",
       "29                  None                     (1, 1)                   True   \n",
       "20                  mask                     (1, 1)                  False   \n",
       "28                  None                     (1, 1)                  False   \n",
       "16                  mask                     (1, 1)                  False   \n",
       "24                  None                     (1, 1)                  False   \n",
       "19                  mask                     (1, 2)                   True   \n",
       "27                  None                     (1, 2)                   True   \n",
       "23                  mask                     (1, 2)                   True   \n",
       "31                  None                     (1, 2)                   True   \n",
       "22                  mask                     (1, 2)                  False   \n",
       "30                  None                     (1, 2)                  False   \n",
       "18                  mask                     (1, 2)                  False   \n",
       "26                  None                     (1, 2)                  False   \n",
       "1                   mask                     (1, 1)                   True   \n",
       "9                   None                     (1, 1)                   True   \n",
       "5                   mask                     (1, 1)                   True   \n",
       "13                  None                     (1, 1)                   True   \n",
       "7                   mask                     (1, 2)                   True   \n",
       "15                  None                     (1, 2)                   True   \n",
       "3                   mask                     (1, 2)                   True   \n",
       "11                  None                     (1, 2)                   True   \n",
       "0                   mask                     (1, 1)                  False   \n",
       "8                   None                     (1, 1)                  False   \n",
       "4                   mask                     (1, 1)                  False   \n",
       "12                  None                     (1, 1)                  False   \n",
       "6                   mask                     (1, 2)                  False   \n",
       "14                  None                     (1, 2)                  False   \n",
       "2                   mask                     (1, 2)                  False   \n",
       "10                  None                     (1, 2)                  False   \n",
       "\n",
       "   param_tfidf_v__max_df param_LinearSVC__C  mean_test_score  \n",
       "17                   0.7                  1         0.753318  \n",
       "25                   0.7                  1         0.753318  \n",
       "21                   0.9                  1         0.751887  \n",
       "29                   0.9                  1         0.751887  \n",
       "20                   0.9                  1         0.744601  \n",
       "28                   0.9                  1         0.744601  \n",
       "16                   0.7                  1         0.737964  \n",
       "24                   0.7                  1         0.737964  \n",
       "19                   0.7                  1         0.736053  \n",
       "27                   0.7                  1         0.736053  \n",
       "23                   0.9                  1         0.734947  \n",
       "31                   0.9                  1         0.734947  \n",
       "22                   0.9                  1         0.723301  \n",
       "30                   0.9                  1         0.723301  \n",
       "18                   0.7                  1         0.722968  \n",
       "26                   0.7                  1         0.722968  \n",
       "1                    0.7                0.1         0.762059  \n",
       "9                    0.7                0.1         0.762059  \n",
       "5                    0.9                0.1         0.760856  \n",
       "13                   0.9                0.1         0.760856  \n",
       "7                    0.9                0.1         0.748585  \n",
       "15                   0.9                0.1         0.748585  \n",
       "3                    0.7                0.1         0.746615  \n",
       "11                   0.7                0.1         0.746615  \n",
       "0                    0.7                0.1         0.744710  \n",
       "8                    0.7                0.1         0.744710  \n",
       "4                    0.9                0.1         0.744347  \n",
       "12                   0.9                0.1         0.744347  \n",
       "6                    0.9                0.1         0.734054  \n",
       "14                   0.9                0.1         0.734054  \n",
       "2                    0.7                0.1         0.732154  \n",
       "10                   0.7                0.1         0.732154  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_s.cv_results_)\n",
    "cols = ['param_' + param for param in params.keys()] + ['mean_test_score']\n",
    "\n",
    "results[cols].sort_values(by=['param_LinearSVC__C','mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regards to our preprocessing steps:\n",
    "    * our DeLaTeX does not help at all\n",
    "    * it is better to use IDF\n",
    "    * max_df=0.7 is slightly better than 0.9\n",
    "    * using 1-grams alone in the count-vectorizer proved to be no visibly better than adding *2grams*\n",
    "   \n",
    "### We will stick to those settings in tuning the classifiers' hyperparameters below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated GridSearchCV for multiple classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(name, model):\n",
    "    pipe = []\n",
    "    #pipe.append(( 'delatex', DeLaTeX(behave='flag') ))\n",
    "    pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=True, strip_accents='unicode', min_df = 2, max_df = 0.7)  ))\n",
    "    pipe.append(( name, model  ))\n",
    "    \n",
    "    return Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe_params(name, model_params):\n",
    "    params = {\n",
    "        #'delatex__behave': [None],\n",
    "        'tfidf_v__ngram_range': [(1, 1)],\n",
    "        'tfidf_v__use_idf': [True],\n",
    "        'tfidf_v__max_df': [0.7],\n",
    "    }\n",
    "    for (param_name, range_) in model_params:\n",
    "        params[name + '__' + param_name] = range_\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify models with grid of parametrs and run the GridSearchCV, cv=5 (stratified by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinSVC': [LinearSVC(class_weight='balanced'),\n",
    "                  [( 'C', [1] )]\n",
    "                 ],\n",
    "    'LogReg': [LogisticRegression(class_weight='balanced', solver='lbfgs', multi_class='multinomial', max_iter=500),\n",
    "                  [( 'C', [1] ), ('multi_class', ['multinomial'])]\n",
    "                 ],\n",
    "    'RndFClf': [RandomForestClassifier(class_weight='balanced', n_estimators=100),\n",
    "                 [('max_depth', [20]) , ('min_samples_leaf', [10])]\n",
    "                ],\n",
    "    'NearCen': [NearestCentroid(),\n",
    "                     [('metric', ['euclidean', 'cosine'])]\n",
    "                    ],\n",
    "    'MultNB': [MultinomialNB(),\n",
    "                [('alpha', [0.1]), ('fit_prior', [True])]\n",
    "               ],\n",
    "    'BernNB': [BernoulliNB(),\n",
    "                    [('alpha', [0.1]), ('fit_prior', [True])]\n",
    "                   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinSVC\n",
      "0.7034797878363567 \n",
      "\n",
      "LogReg\n",
      "0.7228257592656318 \n",
      "\n",
      "RndFClf\n",
      "0.624424803512567 \n",
      "\n",
      "NearCen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/nearest_centroid.py:141: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/nearest_centroid.py:141: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/nearest_centroid.py:141: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/nearest_centroid.py:141: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/nearest_centroid.py:141: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6868931354303107 \n",
      "\n",
      "MultNB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/olszewskip/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5054475856428579 \n",
      "\n",
      "BernNB\n",
      "0.6672216616130997 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GRID-SEARCH\n",
    "\n",
    "# collect the best_params for the models\n",
    "results = {}\n",
    "\n",
    "for name, (model, model_params) in models.items():\n",
    "    \n",
    "    print(name)\n",
    "    pipe = build_clf(name, model)\n",
    "    params = build_pipe_params(name, model_params)\n",
    "    \n",
    "    grid_s = GridSearchCV(pipe, params, cv=5, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False)\n",
    "    grid_s.fit(text_train, y_train)\n",
    "    \n",
    "    print(grid_s.best_score_, \"\\n\")\n",
    "    results[name] = [grid_s.best_params_, grid_s.best_score_, grid_s.cv_results_]\n",
    "\n",
    "    \n",
    "# store the best_params in the models dict\n",
    "for name, result in results.items():\n",
    "    \n",
    "    best_params = result[0]    \n",
    "    models[name][1] = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the whole train data to the tuned classifiers. Record final scores on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_num = 60_000\n",
    "train_vol = int(large_num*4/5)\n",
    "\n",
    "final_train = data[:train_vol]\n",
    "final_test = data[train_vol:large_num]\n",
    "\n",
    "\n",
    "final_text_train = final_train.text\n",
    "final_y_train = label_e.transform(final_train.label)\n",
    "\n",
    "final_text_test = final_test.text\n",
    "final_y_test = label_e.transform(final_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = {}\n",
    "\n",
    "for name, (model, pipe_best_params) in models.items():\n",
    "    \n",
    "    clf = build_clf(name, model)\n",
    "    clf.set_params(**pipe_best_params)\n",
    "    clf.fit(final_text_train, final_y_train)\n",
    "    \n",
    "    final_scores[name] = f1_score(final_y_test, clf.predict(final_text_test), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinSVC': 0.7707762108831197,\n",
       " 'LogReg': 0.7618005083247673,\n",
       " 'RndFClf': 0.6369622568461526,\n",
       " 'NearCen': 0.6891147145642181,\n",
       " 'MultNB': 0.637215428459177,\n",
       " 'BernNB': 0.7385950280121687,\n",
       " 'RidgeClf': 0.5723399898221054}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = range(len(final_scores))\n",
    "plt.ylim(0.5, 1)\n",
    "plt.bar(count, np.array(list(final_scores.values()))-0.5, bottom=0.5)\n",
    "plt.xticks(count, list(final_scores.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
