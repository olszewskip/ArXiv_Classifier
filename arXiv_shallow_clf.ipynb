{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7d07393b3e82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import SCORERS, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer #, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "#from sklearn.linear_model import SGDlassifier(loss = ...) # loss='hinge'/'log'\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "### Bag od words with SVMs, Log-Regression, Random-Forest etc. on top \n",
    "\n",
    "* Build and test a preprocessing pipe:\n",
    "    * Handle *LaTeX* formulas before count-vectorizatation and TFIDF transformation.\n",
    "    * Test a handful of preprocessing parameters (inc. 2-grams, idf switched on/off, maximal document frequency) with a single untuned classifier.\n",
    "* Test a handful of shallow multiclass classifiers with *macro-F1* as the objective, this time without broadly changing the preprocessing parameters:\n",
    "* The grid-search in both step is (likely) performed on a fraction of the train data.\n",
    "* Fit the tuned classifiers to the whole of train data.\n",
    "* Collect the *macro-f1* scores obtained on the test data.\n",
    "* ... Save the best fitted model to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the measure of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available scikit-learn's scorers\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my choice\n",
    "scoring = \"f1_macro\"\n",
    "average = \"macro\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the two-column data frame (text + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"data\", \"bare_all.csv\")\n",
    "\n",
    "data = pd.read_csv(file, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample of records to play with\n",
    "small_num = 10_000\n",
    "sample = data[:small_num]\n",
    "\n",
    "text = sample.text\n",
    "label = sample.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. all records in memory: 836551\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power sum decompositions of defining equations of reflection arrangements.  We determine the Waring rank of the fund...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Spectroscopic Survey of Massive Stars in M31 and M33.  We describe our spectroscopic follow-up to the Local Group ...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hamiltonian Thermodynamics of Black Holes in Generic 2-D Dilaton Gravity.  We consider the Hamiltonian mechanics and...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      text  \\\n",
       "0  Power sum decompositions of defining equations of reflection arrangements.  We determine the Waring rank of the fund...   \n",
       "1  A Spectroscopic Survey of Massive Stars in M31 and M33.  We describe our spectroscopic follow-up to the Local Group ...   \n",
       "2  Hamiltonian Thermodynamics of Black Holes in Generic 2-D Dilaton Gravity.  We consider the Hamiltonian mechanics and...   \n",
       "\n",
       "  label  \n",
       "0  math  \n",
       "1  phys  \n",
       "2  phys  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"No. all records in memory: {len(data)}\")\n",
    "with pd.option_context('display.max_colwidth', 120):\n",
    "    display(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts of scientific papers tend to be written in a formal style, to not contain typos, nor direct citations, little references, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A mathematical model of granulopoiesis incorporating the negative feedback dynamics and kinetics of G-CSF/neutrophil binding and internalisation.  We develop a physiological model of granulopoiesis which includes explicit modelling of the kinetics of the cytokine granulocyte colony-stimulating factor (G-CSF) incorporating both the freely circulating concentration and the concentration of the cytokine bound to mature neutrophils. G-CSF concentrations are used to directly regulate neutrophil production, with the rate of differentiation of stem cells to neutrophil precursors, the effective proliferation rate in mitosis, the maturation time, and the release rate from the mature marrow reservoir into circulation all dependent on the level of G-CSF in the system. The dependence of the maturation time on the cytokine concentration introduces a state-dependent delay into our differential equation model, and we show how this is derived from an age-structured partial differential equation model of the mitosis and maturation, and also detail the derivation of the rest of our model. The model and its estimated parameters are shown to successfully predict the neutrophil and G-CSF responses to a variety of treatment scenarios, including the combined administration of chemotherapy and exogenous G-CSF. This concomitant treatment was reproduced without any additional fitting to characterise drug-drug interactions. \n",
      "---\n",
      "The Advantage is at the Ladies: Brain Size Bias-Compensated Graph-Theoretical Parameters are Also Better in Women's Connectomes.  In our previous study we have shown that the female connectomes have significantly better, deep graph-theoretical parameters, related to superior \"connectivity\", than the connectome of the males. Since the average female brain is smaller than the average male brain, one cannot rule out that the significant advantages are due to the size- and not to the sex-differences in the data. To filter out the possible brain-volume related artifacts, we have chosen 36 small male and 36 large female brains such that all the brains in the female set are larger than all the brains in the male set. For the sets, we have computed the corresponding braingraphs and computed numerous graph-theoretical parameters. We have found that (i) the small male brains lack the better connectivity advantages shown in our previous study for female brains in general; (ii) in numerous parameters, the connectomes computed from the large-brain females, still have the significant, deep connectivity advantages, demonstrated in our previous study. \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(text.iloc[random.choice(range(len(text)))])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One messy but informative kind of writing they have are LaTeX formulas (*\\$...\\$*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Event shape sorting.  We propose a novel method for sorting events of multiparticle production according to the azimuthal anisotropy of their momentum distribution. Although the method is quite general, we advocate its use in analysis of ultra-relativistic heavy-ion collisions where large number of hadrons is produced. The advantage of our method is that it can automatically sort out samples of ev'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[6][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose to either mask them with * \\_latex\\_ * or flag them by appending * \\_latex\\_ * in front of each such expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask or flag LaTeX expression with a word ' _LATEX_ '\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "    # self.pattern = r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\"\n",
    "    # why does it differ from  r'(\\$.+?\\$)' ?\n",
    "    \n",
    "class DeLaTeX(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, behave=None, pattern=r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\", repl = ' _LATEX_ '):\n",
    "        self.repl = ' _LATEX_ '\n",
    "        self.pattern = pattern\n",
    "        self.behave = behave\n",
    "        \n",
    "        if self.behave == 'mask':\n",
    "            self.repl = ' _LATEX_ '\n",
    "        elif self.behave == 'flag':\n",
    "            self.repl = r' _LATEX_ \\1'\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.core.series.Series):\n",
    "            raise TypeError(\"The data must be a pandas Series of strings\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.behave:\n",
    "            return X.str.replace(self.pattern, self.repl)\n",
    "        return X\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.estimator_checks import check_estimator\n",
    "# check_estimator(DeLaTeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group $\\\\Gamma$ on a single element $\\\\psi$ of a given Hilbert space $\\\\mathcal{H}$. As $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the $L^1$-space associated to the group von Neumann algebra of $\\\\Gamma$. Our result generalizes recent work for LCA groups. In many cases, the b'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = None)\n",
    "delatex.transform(text[6:7]).iloc[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_  on a single element  _LATEX_  of a given Hilbert space  _LATEX_ . As  _LATEX_  might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ -space associated to the group von Neumann algebra of  _LATEX_ . Our result generalizes recent work for LCA groups. In many cases,'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'mask')\n",
    "delatex.transform(text[6:7]).iloc[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_ $\\\\Gamma$ on a single element  _LATEX_ $\\\\psi$ of a given Hilbert space  _LATEX_ $\\\\mathcal{H}$. As  _LATEX_ $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ $L^1$-space associated to the group von Neumann algebra of  _LATEX_ $\\\\Gamma$. Our result genera'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "delatex.transform(text[6:7]).iloc[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs', 'math', 'phys', 'q-bio', 'q-fin', 'stat']\n"
     ]
    }
   ],
   "source": [
    "# 'cs' -> 0, ..., 'stat' -> 5\n",
    "\n",
    "label_e = LabelEncoder()\n",
    "y_train = label_e.fit_transform(label)\n",
    "\n",
    "print(list(label_e.classes_))\n",
    "\n",
    "#label_e.inverse_transform([0]) # array(['cs'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the most frequent words. Choose winners as the stop-words.\n",
    "Take note of the rank of our '\\_latex\\_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 122807)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "count_v = CountVectorizer(strip_accents='unicode')\n",
    "word_counts_train = count_v.fit_transform(delatex.fit_transform(text))\n",
    "word_counts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1057000, 'the'),\n",
       " (670000, 'of'),\n",
       " (370000, 'and'),\n",
       " (332000, 'in'),\n",
       " (277000, 'to'),\n",
       " (213000, 'we'),\n",
       " (195000, 'is'),\n",
       " (181000, 'for'),\n",
       " (180000, '_latex_'),\n",
       " (142000, 'that')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_word_counts_train = word_counts_train.sum(axis=0)\n",
    "sorted([(round(sum_word_counts_train[0, i],-3), word) for word, i in count_v.vocabulary_.items()],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['the', 'of', 'and', 'in','to','we','is'] # 'for' seems already mathematical/computer-sciency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go step by step through an arbitrary pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX(behave='mask')\n",
    "tex_text_train = delatex.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(use_idf=True, stop_words=stopwords, min_df = 2, max_df=0.8, strip_accents='unicode')\n",
    "tfidf_scores_train = tfidf_v.fit_transform(tex_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1, class_weight='balanced')\n",
    "lsvc.fit(tfidf_scores_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's just have some fun first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_abstracts = pd.Series([\"\"\"\n",
    "The Lack of A Priori Distinctions Between Learning Algorithms. This is the first of\n",
    "two papers that use off-training set (OTS) error to investigate the assumption-free\n",
    "relationship between learning algorithms. This first paper discusses the senses in\n",
    "which there are no a priori distinctions between learning algorithms. (The second\n",
    "paper discusses the senses in which there are such distinctions.) In this first paper\n",
    "it is shown, loosely speaking, that for any two algorithms A and B, there are \"as many\"\n",
    "targets (or priors over targets) for which A has lower expected OTS error than B as\n",
    "vice versa, for loss functions like zero-one loss. In particular, this is true if A\n",
    "is cross-validation and B is \"anti-cross-validation'' (choose the learning algorithm\n",
    "with largest cross-validation error). This paper ends with a discussion of the\n",
    "implications of these results for computational learning theory. It is shown that one\n",
    "cannot say: if empirical misclassification rate is low, the Vapnik-Chervonenkis\n",
    "dimension of your generalizer is small, and the training set is large, then with high\n",
    "probability your OTS error is small. Other implications for \"membership queries\"\n",
    "algorithms and \"punting\" algorithms are also discussed.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "X-rays quarks lepton scattering experiment field\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "genes DNA RNA sequencing protein species fenotype \n",
    "\"\"\",\n",
    "\"\"\"\n",
    "computer algorithm graph sorting depth first interface\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "novel intuitive proof of $\\limit_{x\\to 0} x = 0$ convergence fomula,\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "inflation resources market stock bonds derivatives\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "distribution Bayesian p value marginalization Monte Carlo\n",
    "\"\"\"\n",
    "])\n",
    "\n",
    "label_e.inverse_transform(lsvc.predict(tfidf_v.transform(delatex.transform(random_abstracts ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks promising :)\n",
    "Here's the actual score on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = data[small_num:2*small_num].text\n",
    "y_test = label_e.transform(data[small_num:2*small_num].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = lsvc.predict(tfidf_v.transform(delatex.transform(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.7783206076010205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.84      0.88      0.86     13162\n",
      "        math       0.89      0.91      0.90     23035\n",
      "        phys       0.98      0.96      0.97     60193\n",
      "       q-bio       0.63      0.64      0.64      1241\n",
      "       q-fin       0.76      0.75      0.75       601\n",
      "        stat       0.55      0.56      0.56      1768\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    100000\n",
      "   macro avg       0.77      0.78      0.78    100000\n",
      "weighted avg       0.93      0.92      0.92    100000\n",
      "\n",
      "[[11581   868   299   104    19   291]\n",
      " [  953 20849   775    79    65   314]\n",
      " [  670  1382 57736   254    37   114]\n",
      " [  137    45   184   799     1    75]\n",
      " [   48    62    25     0   448    18]\n",
      " [  466   189    63    33    20   997]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro F1:\", f1_score(y_test, predicted_y_test, average=\"macro\"))\n",
    "print(classification_report(y_test, predicted_y_test, target_names=label_e.classes_))\n",
    "print(confusion_matrix(y_test, predicted_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"By definition a confusion matrix $C$ is such that $C_{ij}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\" https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained on a fraction of all records with an untuned Linear SVM, we have reached ~0.78 macro-F1 (out of sample) pulled down by poor performomance on classification wrt rarer classes. E.g. many *cs* and *math* are confused with *stat* (and vice versa), and similarly for *q-bio* and *physics*. This is actually sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid searching by hand through preprocessing params with Linear SVM Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = []\n",
    "pipe.append(( 'delatex', DeLaTeX(behave='mask') ))\n",
    "pipe.append(( 'tfidf_v', TfidfVectorizer(analyzer = 'word', strip_accents='unicode', min_df = 2)  ))\n",
    "pipe.append(( 'LinearSVC', LinearSVC(C=1, penalty='l2', class_weight='balanced')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delatex__behave': ['mask', None],\n",
       " 'tfidf_v__stop_words': [['the', 'of', 'and', 'in', 'to', 'we', 'is'], None],\n",
       " 'tfidf_v__ngram_range': [(1, 1), (1, 2)],\n",
       " 'tfidf_v__use_idf': [True, False],\n",
       " 'tfidf_v__max_df': [0.6, 0.75, 0.9],\n",
       " 'LinearSVC__C': [0.2, 2]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'delatex__behave': ['mask', None],\n",
    "    'tfidf_v__stop_words': [stopwords, None],\n",
    "    'tfidf_v__ngram_range': [(1, 1), (1,2)],\n",
    "    'tfidf_v__use_idf': [True, False],\n",
    "    'tfidf_v__max_df': [0.6, 0.75, 0.9],\n",
    "}\n",
    "params['LinearSVC' + '__' + 'C'] = [0.2, 2]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 96 candidates, totalling 384 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 384 out of 384 | elapsed: 258.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave='mask',\n",
       "    pattern='(\\\\${1,2}[\\\\s\\\\w\\\\d\\\\\\\\,\\\\.=\\\\(\\\\)*{}/\\\\[\\\\]^;:\\'`<>|%&@\\\\\"!\\\\?~#+-]*?\\\\${1,2})',\n",
       "    repl=' _LATEX_ ')), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=False, n_jobs=1,\n",
       "       param_grid={'delatex__behave': ['mask', None], 'tfidf_v__stop_words': [['the', 'of', 'and', 'in', 'to', 'we', 'is'], None], 'tfidf_v__ngram_range': [(1, 1), (1, 2)], 'tfidf_v__use_idf': [True, False], 'tfidf_v__max_df': [0.6, 0.75, 0.9], 'LinearSVC__C': [0.2, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LONG WAIT\n",
    "\n",
    "# there's some bug with njobs different than 1 because of the delatex in the pipe\n",
    "# may be related to the fact that check_estimator(DeLaTeX) raises an error due to DeLaTeX using the pandas' vectorized str method \n",
    "\n",
    "grid_s = GridSearchCV(Pipeline(pipe), params, cv=4, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False, verbose=1)\n",
    "grid_s.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7912419492069807"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC__C': 0.2,\n",
       " 'delatex__behave': 'mask',\n",
       " 'tfidf_v__max_df': 0.6,\n",
       " 'tfidf_v__ngram_range': (1, 2),\n",
       " 'tfidf_v__stop_words': None,\n",
       " 'tfidf_v__use_idf': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_results = pd.DataFrame(grid_s.cv_results_)\n",
    "cols = ['param_' + param for param in params.keys()] + ['mean_test_score']\n",
    "results_df = grid_cv_results[cols].sort_values(by=['mean_test_score','param_delatex__behave','param_tfidf_v__max_df'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.791242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.791209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.790569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.790383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.790162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.789770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "6                   mask                            None   \n",
       "30                  None                            None   \n",
       "38                  None                            None   \n",
       "46                  None                            None   \n",
       "14                  mask                            None   \n",
       "22                  mask                            None   \n",
       "28                  None  [the, of, and, in, to, we, is]   \n",
       "4                   mask  [the, of, and, in, to, we, is]   \n",
       "44                  None  [the, of, and, in, to, we, is]   \n",
       "36                  None  [the, of, and, in, to, we, is]   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "6                      (1, 2)                   True                   0.6   \n",
       "30                     (1, 2)                   True                   0.6   \n",
       "38                     (1, 2)                   True                  0.75   \n",
       "46                     (1, 2)                   True                   0.9   \n",
       "14                     (1, 2)                   True                  0.75   \n",
       "22                     (1, 2)                   True                   0.9   \n",
       "28                     (1, 2)                   True                   0.6   \n",
       "4                      (1, 2)                   True                   0.6   \n",
       "44                     (1, 2)                   True                   0.9   \n",
       "36                     (1, 2)                   True                  0.75   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "6                 0.2         0.791242  \n",
       "30                0.2         0.791209  \n",
       "38                0.2         0.790569  \n",
       "46                0.2         0.790383  \n",
       "14                0.2         0.790162  \n",
       "22                0.2         0.789770  \n",
       "28                0.2         0.788460  \n",
       "4                 0.2         0.788429  \n",
       "44                0.2         0.788314  \n",
       "36                0.2         0.788314  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 0.2) & (results_df.param_tfidf_v__ngram_range==(1,2))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.780536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.780056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.780056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.778934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.778753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "29                  None  [the, of, and, in, to, we, is]   \n",
       "21                  mask  [the, of, and, in, to, we, is]   \n",
       "13                  mask  [the, of, and, in, to, we, is]   \n",
       "7                   mask                            None   \n",
       "47                  None                            None   \n",
       "45                  None  [the, of, and, in, to, we, is]   \n",
       "37                  None  [the, of, and, in, to, we, is]   \n",
       "23                  mask                            None   \n",
       "15                  mask                            None   \n",
       "39                  None                            None   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "29                     (1, 2)                  False                   0.6   \n",
       "21                     (1, 2)                  False                   0.9   \n",
       "13                     (1, 2)                  False                  0.75   \n",
       "7                      (1, 2)                  False                   0.6   \n",
       "47                     (1, 2)                  False                   0.9   \n",
       "45                     (1, 2)                  False                   0.9   \n",
       "37                     (1, 2)                  False                  0.75   \n",
       "23                     (1, 2)                  False                   0.9   \n",
       "15                     (1, 2)                  False                  0.75   \n",
       "39                     (1, 2)                  False                  0.75   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "29                0.2         0.780536  \n",
       "21                0.2         0.780056  \n",
       "13                0.2         0.780056  \n",
       "7                 0.2         0.779726  \n",
       "47                0.2         0.779349  \n",
       "45                0.2         0.779298  \n",
       "37                0.2         0.779298  \n",
       "23                0.2         0.779035  \n",
       "15                0.2         0.778934  \n",
       "39                0.2         0.778753  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 0.2) & (results_df.param_tfidf_v__ngram_range==(1,2))][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.783177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.783177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.783177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "40                  None  [the, of, and, in, to, we, is]   \n",
       "32                  None  [the, of, and, in, to, we, is]   \n",
       "34                  None                            None   \n",
       "42                  None                            None   \n",
       "24                  None  [the, of, and, in, to, we, is]   \n",
       "26                  None                            None   \n",
       "16                  mask  [the, of, and, in, to, we, is]   \n",
       "8                   mask  [the, of, and, in, to, we, is]   \n",
       "10                  mask                            None   \n",
       "0                   mask  [the, of, and, in, to, we, is]   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "40                     (1, 1)                   True                   0.9   \n",
       "32                     (1, 1)                   True                  0.75   \n",
       "34                     (1, 1)                   True                  0.75   \n",
       "42                     (1, 1)                   True                   0.9   \n",
       "24                     (1, 1)                   True                   0.6   \n",
       "26                     (1, 1)                   True                   0.6   \n",
       "16                     (1, 1)                   True                   0.9   \n",
       "8                      (1, 1)                   True                  0.75   \n",
       "10                     (1, 1)                   True                  0.75   \n",
       "0                      (1, 1)                   True                   0.6   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "40                0.2         0.783177  \n",
       "32                0.2         0.783177  \n",
       "34                0.2         0.783177  \n",
       "42                0.2         0.782992  \n",
       "24                0.2         0.782940  \n",
       "26                0.2         0.782940  \n",
       "16                0.2         0.782872  \n",
       "8                 0.2         0.782872  \n",
       "10                0.2         0.782872  \n",
       "0                 0.2         0.782364  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 0.2) & (results_df.param_tfidf_v__ngram_range==(1,1))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.784678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.784561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "54                  mask                            None   \n",
       "70                  mask                            None   \n",
       "62                  mask                            None   \n",
       "94                  None                            None   \n",
       "86                  None                            None   \n",
       "78                  None                            None   \n",
       "92                  None  [the, of, and, in, to, we, is]   \n",
       "84                  None  [the, of, and, in, to, we, is]   \n",
       "68                  mask  [the, of, and, in, to, we, is]   \n",
       "60                  mask  [the, of, and, in, to, we, is]   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "54                     (1, 2)                   True                   0.6   \n",
       "70                     (1, 2)                   True                   0.9   \n",
       "62                     (1, 2)                   True                  0.75   \n",
       "94                     (1, 2)                   True                   0.9   \n",
       "86                     (1, 2)                   True                  0.75   \n",
       "78                     (1, 2)                   True                   0.6   \n",
       "92                     (1, 2)                   True                   0.9   \n",
       "84                     (1, 2)                   True                  0.75   \n",
       "68                     (1, 2)                   True                   0.9   \n",
       "60                     (1, 2)                   True                  0.75   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "54                  2         0.784678  \n",
       "70                  2         0.784561  \n",
       "62                  2         0.783827  \n",
       "94                  2         0.783620  \n",
       "86                  2         0.783560  \n",
       "78                  2         0.783283  \n",
       "92                  2         0.783071  \n",
       "84                  2         0.783071  \n",
       "68                  2         0.783070  \n",
       "60                  2         0.783070  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 2) & (results_df.param_tfidf_v__ngram_range==(1,2))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "83                  None                            None   \n",
       "64                  mask  [the, of, and, in, to, we, is]   \n",
       "56                  mask  [the, of, and, in, to, we, is]   \n",
       "58                  mask                            None   \n",
       "72                  None  [the, of, and, in, to, we, is]   \n",
       "74                  None                            None   \n",
       "48                  mask  [the, of, and, in, to, we, is]   \n",
       "50                  mask                            None   \n",
       "73                  None  [the, of, and, in, to, we, is]   \n",
       "75                  None                            None   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "83                     (1, 1)                  False                  0.75   \n",
       "64                     (1, 1)                   True                   0.9   \n",
       "56                     (1, 1)                   True                  0.75   \n",
       "58                     (1, 1)                   True                  0.75   \n",
       "72                     (1, 1)                   True                   0.6   \n",
       "74                     (1, 1)                   True                   0.6   \n",
       "48                     (1, 1)                   True                   0.6   \n",
       "50                     (1, 1)                   True                   0.6   \n",
       "73                     (1, 1)                  False                   0.6   \n",
       "75                     (1, 1)                  False                   0.6   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "83                  2         0.768993  \n",
       "64                  2         0.768403  \n",
       "56                  2         0.768403  \n",
       "58                  2         0.768403  \n",
       "72                  2         0.768203  \n",
       "74                  2         0.768203  \n",
       "48                  2         0.767866  \n",
       "50                  2         0.767866  \n",
       "73                  2         0.767772  \n",
       "75                  2         0.767772  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 2) & (results_df.param_tfidf_v__ngram_range==(1,1))][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regards to our preprocessing steps:\n",
    "    * By and large the search was performed over unimportant parameters.\n",
    "    * The most important ones (at the level of gaining 0.8 percentage points), aside from the model's *C*, were: using (1,2)-word-grams rather than 1-word-grams and using IDFs over not using it.\n",
    "    * The influence of max_df is small and not very consistent.\n",
    "    * Our DeLaTeX behavior and stopwords have no significant effect.\n",
    "   \n",
    "In light of the above we will stick to:\n",
    "    * no DeLaTeX\n",
    "    * no stop-words\n",
    "    * (1,2)-grams\n",
    "    * using IDFs\n",
    "    * no max_df limit (meaning the default =1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated GridSearchCV for multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(name, model):\n",
    "    pipe = []\n",
    "    #pipe.append(( 'delatex', DeLaTeX(behave='flag') ))\n",
    "    pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=True, strip_accents='unicode', min_df = 2, ngram_range=(1,2))  ))\n",
    "    pipe.append(( name, model  ))\n",
    "    \n",
    "    return Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe_params(name, model_params):\n",
    "    params = {\n",
    "        #'delatex__behave': [None],  # (bug) switch off in order to use n_jobs in GridSearchCV\n",
    "        #'tfidf_v__ngram_range': [(1, 1), (1,2)],\n",
    "        #'tfidf_v__use_idf': [True, False],\n",
    "        #'tfidf_v__max_df': [0.8, 1.0],\n",
    "    }\n",
    "    for (param_name, range_) in model_params:\n",
    "        params[name + '__' + param_name] = range_\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify models with grid of parametrs and run the GridSearchCV, cv=4 (stratified by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \n",
    "#     'rbfSVC': [SVC(class_weight='balanced', gamma='scale'),\n",
    "#             [( 'C', [0.04, 0.2, 1, 5] )]\n",
    "#            ],\n",
    "    'LogReg': [LogisticRegression(class_weight='balanced', solver='lbfgs', multi_class='multinomial', max_iter=500),\n",
    "                  [( 'C', [0.04, 0.2, 1, 5] ), ('multi_class', ['multinomial','ovr'])]\n",
    "                 ],\n",
    "    'RndFClf': [RandomForestClassifier(class_weight='balanced', n_estimators=300),\n",
    "                 [('max_depth', [10, 20, 30]) , ('min_samples_leaf', [ 1E-4, 1E-3, 1E-2])]\n",
    "                ],\n",
    "    'LinSVC': [LinearSVC(class_weight='balanced'),\n",
    "                  [( 'C', [0.04, 0.2, 1, 5] )]\n",
    "                 ],\n",
    "    'NearCen': [NearestCentroid(),\n",
    "                [('metric', ['euclidean','manhattan'])]\n",
    "               ],\n",
    "    'MultNB': [MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None),\n",
    "                [('alpha', [0.01, 0.1, 1])]\n",
    "               ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  32 out of  32 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7202029565422178 \n",
      "\n",
      "RndFClf\n",
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  36 out of  36 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5776860990524314 \n",
      "\n",
      "LinSVC\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  16 out of  16 | elapsed:   46.6s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7057201072157833 \n",
      "\n",
      "MultNB\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  12 out of  12 | elapsed:   29.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5588293031328937 \n",
      "\n",
      "NearCen\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "0.6776496360026673 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   8 out of   8 | elapsed:   35.1s finished\n"
     ]
    }
   ],
   "source": [
    "# GRID-SEARCH\n",
    "\n",
    "# collect the best_params for the models\n",
    "results = {}\n",
    "\n",
    "for name, (model, model_params) in models.items():\n",
    "    \n",
    "    print(name)\n",
    "    pipe = build_clf(name, model)\n",
    "    params = build_pipe_params(name, model_params)\n",
    "    \n",
    "    grid_s = GridSearchCV(pipe, params, cv=4, scoring=scoring, iid=False, return_train_score=True, n_jobs=3, refit=False, verbose=1)\n",
    "    grid_s.fit(text_train, y_train)\n",
    "    \n",
    "    print(grid_s.best_score_, \"\\n\")\n",
    "    results[name] = [grid_s.best_params_, grid_s.best_score_, grid_s.cv_results_]\n",
    "\n",
    "    \n",
    "# store the best_params in the models dict\n",
    "for name, result in results.items():\n",
    "    \n",
    "    best_params = result[0]    \n",
    "    models[name].append(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=None, max_features='auto',\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=300, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " [('max_depth', [10, 20, 30]), ('min_samples_leaf', [1e-05, 0.0001, 0.001])],\n",
       " {'RndFClf__max_depth': 20, 'RndFClf__min_samples_leaf': 0.001}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the obtaind best_params of Random Forest for example\n",
    "models[\"RndFClf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the whole train data to the tuned classifiers. Record final scores on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_num = 30_000 #len(data)\n",
    "train_vol = int(large_num*3/4)\n",
    "\n",
    "final_train = data[:train_vol]\n",
    "final_test = data[train_vol:large_num]\n",
    "\n",
    "\n",
    "final_text_train = final_train.text\n",
    "final_y_train = label_e.transform(final_train.label)\n",
    "\n",
    "final_text_test = final_test.text\n",
    "final_y_test = label_e.transform(final_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted LogReg.\n",
      "Fitted RndFClf.\n",
      "Fitted LinSVC.\n",
      "Fitted MultNB.\n",
      "Fitted NearCen.\n"
     ]
    }
   ],
   "source": [
    "final_scores = {}\n",
    "\n",
    "for name, (model, grid, pipe_best_params) in models.items():\n",
    "    \n",
    "    clf = build_clf(name, model)\n",
    "    clf.set_params(**pipe_best_params)\n",
    "    clf.fit(final_text_train, final_y_train)\n",
    "    models[name].append(clf)\n",
    "    print(f\"Fitted {name}.\")\n",
    "    \n",
    "    final_scores[name] = f1_score(final_y_test, clf.predict(final_text_test), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogReg': 0.768693128505065,\n",
       " 'RndFClf': 0.6015693773626525,\n",
       " 'LinSVC': 0.7664363039816285,\n",
       " 'MultNB': 0.683028785286442,\n",
       " 'NearCen': 0.7288619639172861}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = range(len(final_scores))\n",
    "plt.ylim(0.5, 1)\n",
    "plt.bar(count, np.array(list(final_scores.values())))\n",
    "plt.xticks(count, list(final_scores.keys()))\n",
    "plt.title(\"Macro F1 scores on unseen quarter of the data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the best model in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib / pickle\n",
    "# dump(models['?'], 'filename.joblib'?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load('filename.joblib')\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = model[2]\n",
    "# clf.predict(random_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
