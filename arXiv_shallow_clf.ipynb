{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer #, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "#from sklearn.linear_model import SGDlassifier(loss = ...) # loss='hinge'/'log'\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "### Bag od words with SVMs, Log-Regression, Random-Forest etc. on top \n",
    "\n",
    "* Build and test a preprocessing pipe:\n",
    "    * Handle *LaTeX* formulas before count-vectorizatation and TFIDF transformation.\n",
    "    * Test a handful of preprocessing parameters (inc. 2-grams, idf switched on/off, maximal document frequency) with a single untuned classifier.\n",
    "* Test a handful of shallow multiclass classifiers with *macro-F1* as the objective, this time without broadly changing the preprocessing parameters:\n",
    "* The grid-search in both step is (likely) performed on a fraction of the train data.\n",
    "* Fit the tuned classifiers to the whole of train data.\n",
    "* Collect the *macro-f1* scores obtained on the test data.\n",
    "* ... Save the best fitted model to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the measure of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available scores\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my choice\n",
    "scoring = \"f1_macro\"\n",
    "average = \"macro\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the two-column data frame (text + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"data\", \"bare_all.csv\")\n",
    "\n",
    "data = pd.read_csv(file, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample of records to play with\n",
    "small_num = 10_000\n",
    "sample = data[:small_num]\n",
    "\n",
    "text = sample.text\n",
    "label = sample.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. all records in memory: 838804\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On the interplay between star formation and feedback in galaxy formation simulations.  We investigate the star forma...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transversal Homotopy Monoids of Complex Projective Space.  We will give a geometric description of the nth transvers...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remarks on some typical assumptions in dynamo theory.  Some concepts used in the theory of convection-driven dynamos...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      text  \\\n",
       "0  On the interplay between star formation and feedback in galaxy formation simulations.  We investigate the star forma...   \n",
       "1  Transversal Homotopy Monoids of Complex Projective Space.  We will give a geometric description of the nth transvers...   \n",
       "2  Remarks on some typical assumptions in dynamo theory.  Some concepts used in the theory of convection-driven dynamos...   \n",
       "\n",
       "  label  \n",
       "0  phys  \n",
       "1  math  \n",
       "2  phys  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"No. all records in memory: {len(data)}\")\n",
    "with pd.option_context('display.max_colwidth', 120):\n",
    "    display(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts of scientific papers tend to be written in a formal style, to not contain typos, nor direct citations, little references, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring solutions of differential equations using noisy multi-fidelity data.  For more than two centuries, solutions of differential equations have been obtained either analytically or numerically based on typically well-behaved forcing and boundary conditions for well-posed problems. We are changing this paradigm in a fundamental way by establishing an interface between probabilistic machine learning and differential equations. We develop data-driven algorithms for general linear equations using Gaussian process priors tailored to the corresponding integro-differential operators. The only observables are scarce noisy multi-fidelity data for the forcing and solution that are not required to reside on the domain boundary. The resulting predictive posterior distributions quantify uncertainty and naturally lead to adaptive solution refinement via active learning. This general framework circumvents the tyranny of numerical discretization as well as the consistency and stability issues of time-integration, and is scalable to high-dimensions. \n",
      "---\n",
      "Magnetic anisotropy in the frustrated spin chain compound $\\beta$-TeVO$_4$.  Isotropic and anisotropic magnetic behavior of the frustrated spin chain compound $\\beta$-TeVO$_4$ is reported. Three magnetic transitions observed in zero magnetic field are tracked in fields applied along different crystallographic directions using magnetization, heat capacity, and magnetostriction measurements. Qualitatively different temperature-field diagrams are obtained below 10 T for the field applied along $a$ or $b$ and along $c$, respectively. In contrast, a nearly isotropic high-field phase emerges above 18 T and persists up to the saturation that occurs around 22.5 T. Upon cooling in low fields, the transitions at $T_{\\rm N1}$ and $T_{\\rm N2}$ toward the spin-density-wave and stripe phases are of the second order, whereas the transition at $T_{\\rm N3}$ toward the helical state is of the first order and entails a lattice component. Our microscopic analysis identifies frustrated $J_1-J_2$ spin chains with a sizable antiferromagnetic interchain coupling in the $bc$ plane and ferromagnetic couplings along the $a$ direction. The competition between these ferromagnetic interchain couplings and the helical order within the chain underlies the incommensurate order along the $a$-direction, as observed experimentally. Although a helical state is triggered by the competition between $J_1$ and $J_2$ within the chain, the plane of the helix is not uniquely defined because of competing magnetic anisotropies. Using high-resolution synchrotron diffraction and $^{125}$Te nuclear magnetic resonance, we also demonstrate that the crystal structure of $\\beta$-TeVO$_4$ does not change down to 10 K, and the orbital state of V$^{4+}$ is preserved. \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(text.iloc[random.choice(range(len(text)))])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One messy but informative kind of writing they have are LaTeX formulas (*\\$...\\$*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group $\\\\Gamma$ on a single element $\\\\psi$ of a given Hilbert space $\\\\mathcal{H}$. As $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the $L^1$-space associated to the group von '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[6][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose to either mask them with * \\_latex\\_ * or flag them by appending * \\_latex\\_ * in front of each such expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask or flag LaTeX expression with a word ' _LATEX_ '\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "    # self.pattern = r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\"\n",
    "    # why does it differ from  r'(\\$.+?\\$)' ?\n",
    "    \n",
    "class DeLaTeX(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, behave=None, pattern=r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\", repl = ' _LATEX_ '):\n",
    "        self.repl = ' _LATEX_ '\n",
    "        self.pattern = pattern\n",
    "        self.behave = behave\n",
    "        \n",
    "        if self.behave == 'mask':\n",
    "            self.repl = ' _LATEX_ '\n",
    "        elif self.behave == 'flag':\n",
    "            self.repl = r' _LATEX_ \\1'\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.core.series.Series):\n",
    "            raise TypeError(\"The data must be a pandas Series of strings\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.behave:\n",
    "            return X.str.replace(self.pattern, self.repl)\n",
    "        return X\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.estimator_checks import check_estimator\n",
    "# check_estimator(DeLaTeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group $\\\\Gamma$ on a single element $\\\\psi$ of a given Hilbert space $\\\\mathcal{H}$. As $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the $L^1$-space associated to the group von Neumann algebra of $\\\\Gamma$. Our result generalizes recent work for LCA groups. In many cases, the b'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = None)\n",
    "delatex.transform(text[6:7]).iloc[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_  on a single element  _LATEX_  of a given Hilbert space  _LATEX_ . As  _LATEX_  might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ -space associated to the group von Neumann algebra of  _LATEX_ . Our result generalizes recent work for LCA groups. In many cases,'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'mask')\n",
    "delatex.transform(text[6:7]).iloc[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_ $\\\\Gamma$ on a single element  _LATEX_ $\\\\psi$ of a given Hilbert space  _LATEX_ $\\\\mathcal{H}$. As  _LATEX_ $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ $L^1$-space associated to the group von Neumann algebra of  _LATEX_ $\\\\Gamma$. Our result genera'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "delatex.transform(text[6:7]).iloc[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs', 'math', 'phys', 'q-bio', 'q-fin', 'stat']\n"
     ]
    }
   ],
   "source": [
    "# 'cs' -> 0, ..., 'stat' -> 5\n",
    "\n",
    "label_e = LabelEncoder()\n",
    "y_train = label_e.fit_transform(label)\n",
    "\n",
    "print(list(label_e.classes_))\n",
    "\n",
    "#label_e.inverse_transform([0]) # array(['cs'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the most frequent words. Choose winners as the stop-words.\n",
    "Take note of the rank of our '\\_latex\\_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 122807)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "count_v = CountVectorizer(strip_accents='unicode')\n",
    "word_counts_train = count_v.fit_transform(delatex.fit_transform(text))\n",
    "word_counts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1057000, 'the'),\n",
       " (670000, 'of'),\n",
       " (370000, 'and'),\n",
       " (332000, 'in'),\n",
       " (277000, 'to'),\n",
       " (213000, 'we'),\n",
       " (195000, 'is'),\n",
       " (181000, 'for'),\n",
       " (180000, '_latex_'),\n",
       " (142000, 'that')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_word_counts_train = word_counts_train.sum(axis=0)\n",
    "sorted([(round(sum_word_counts_train[0, i],-3), word) for word, i in count_v.vocabulary_.items()],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['the', 'of', 'and', 'in','to','we','is'] # 'for' seems already mathematical/computer-sciency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go step by step through an arbitrary pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX(behave='mask')\n",
    "tex_text_train = delatex.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(use_idf=True, stop_words=stopwords, min_df = 2, max_df=0.8, strip_accents='unicode')\n",
    "tfidf_scores_train = tfidf_v.fit_transform(tex_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1, class_weight='balanced')\n",
    "lsvc.fit(tfidf_scores_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's just have some fun first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_abstracts = pd.Series([\"\"\"\n",
    "The Lack of A Priori Distinctions Between Learning Algorithms. This is the first of\n",
    "two papers that use off-training set (OTS) error to investigate the assumption-free\n",
    "relationship between learning algorithms. This first paper discusses the senses in\n",
    "which there are no a priori distinctions between learning algorithms. (The second\n",
    "paper discusses the senses in which there are such distinctions.) In this first paper\n",
    "it is shown, loosely speaking, that for any two algorithms A and B, there are \"as many\"\n",
    "targets (or priors over targets) for which A has lower expected OTS error than B as\n",
    "vice versa, for loss functions like zero-one loss. In particular, this is true if A\n",
    "is cross-validation and B is \"anti-cross-validation'' (choose the learning algorithm\n",
    "with largest cross-validation error). This paper ends with a discussion of the\n",
    "implications of these results for computational learning theory. It is shown that one\n",
    "cannot say: if empirical misclassification rate is low, the Vapnik-Chervonenkis\n",
    "dimension of your generalizer is small, and the training set is large, then with high\n",
    "probability your OTS error is small. Other implications for \"membership queries\"\n",
    "algorithms and \"punting\" algorithms are also discussed.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "X-rays quarks lepton scattering experiment field\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "genes DNA RNA sequencing protein species fenotype \n",
    "\"\"\",\n",
    "\"\"\"\n",
    "computer algorithm graph sorting depth first interface\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "novel intuitive proof of $\\limit_{x\\to 0} x = 0$ convergence fomula,\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "inflation resources market stock bonds derivatives\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "distribution Bayesian p value marginalization Monte Carlo\n",
    "\"\"\"\n",
    "])\n",
    "\n",
    "label_e.inverse_transform(lsvc.predict(tfidf_v.transform(delatex.transform(random_abstracts ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks promising :)\n",
    "Here's the actual score on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = data[small_num:2*small_num].text\n",
    "y_test = label_e.transform(data[small_num:2*small_num].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = lsvc.predict(tfidf_v.transform(delatex.transform(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.7783206076010205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.84      0.88      0.86     13162\n",
      "        math       0.89      0.91      0.90     23035\n",
      "        phys       0.98      0.96      0.97     60193\n",
      "       q-bio       0.63      0.64      0.64      1241\n",
      "       q-fin       0.76      0.75      0.75       601\n",
      "        stat       0.55      0.56      0.56      1768\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    100000\n",
      "   macro avg       0.77      0.78      0.78    100000\n",
      "weighted avg       0.93      0.92      0.92    100000\n",
      "\n",
      "[[11581   868   299   104    19   291]\n",
      " [  953 20849   775    79    65   314]\n",
      " [  670  1382 57736   254    37   114]\n",
      " [  137    45   184   799     1    75]\n",
      " [   48    62    25     0   448    18]\n",
      " [  466   189    63    33    20   997]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro F1:\", f1_score(y_test, predicted_y_test, average=\"macro\"))\n",
    "print(classification_report(y_test, predicted_y_test, target_names=label_e.classes_))\n",
    "print(confusion_matrix(y_test, predicted_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"By definition a confusion matrix $C$ is such that $C_{ij}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\" https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained on a fraction of all records with an untuned Linear SVM, we have reached ~0.78 macro-F1 (out of sample) pulled down by poor performomance on classification wrt rarer classes. E.g. many *cs* and *math* are confused with *stat* (and vice versa), and similarly for *q-bio* and *physics*. This is actually sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid searching by hand through preprocessing params with Linear SVM Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = []\n",
    "pipe.append(( 'delatex', DeLaTeX(behave='mask') ))\n",
    "pipe.append(( 'tfidf_v', TfidfVectorizer(analyzer = 'word', strip_accents='unicode', min_df = 2)  ))\n",
    "pipe.append(( 'LinearSVC', LinearSVC(C=1, penalty='l2', class_weight='balanced')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delatex__behave': ['mask', None],\n",
       " 'tfidf_v__stop_words': [['the', 'of', 'and', 'in', 'to', 'we', 'is'], None],\n",
       " 'tfidf_v__ngram_range': [(1, 1), (1, 2)],\n",
       " 'tfidf_v__use_idf': [True, False],\n",
       " 'tfidf_v__max_df': [0.6, 0.75, 0.9],\n",
       " 'LinearSVC__C': [0.2, 2]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'delatex__behave': ['mask', None],\n",
    "    'tfidf_v__stop_words': [stopwords, None],\n",
    "    'tfidf_v__ngram_range': [(1, 1), (1,2)],\n",
    "    'tfidf_v__use_idf': [True, False],\n",
    "    'tfidf_v__max_df': [0.6, 0.75, 0.9],\n",
    "}\n",
    "params['LinearSVC' + '__' + 'C'] = [0.2, 2]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 96 candidates, totalling 384 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 384 out of 384 | elapsed: 258.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave='mask',\n",
       "    pattern='(\\\\${1,2}[\\\\s\\\\w\\\\d\\\\\\\\,\\\\.=\\\\(\\\\)*{}/\\\\[\\\\]^;:\\'`<>|%&@\\\\\"!\\\\?~#+-]*?\\\\${1,2})',\n",
       "    repl=' _LATEX_ ')), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=False, n_jobs=1,\n",
       "       param_grid={'delatex__behave': ['mask', None], 'tfidf_v__stop_words': [['the', 'of', 'and', 'in', 'to', 'we', 'is'], None], 'tfidf_v__ngram_range': [(1, 1), (1, 2)], 'tfidf_v__use_idf': [True, False], 'tfidf_v__max_df': [0.6, 0.75, 0.9], 'LinearSVC__C': [0.2, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LONG WAIT\n",
    "\n",
    "# there's some bug with njobs different than 1 because of the delatex in the pipe\n",
    "# may be related to the fact that check_estimator(DeLaTeX) raises an error due to DeLaTeX using the pandas' vectorized str method \n",
    "\n",
    "grid_s = GridSearchCV(Pipeline(pipe), params, cv=4, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False, verbose=1)\n",
    "grid_s.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7912419492069807"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC__C': 0.2,\n",
       " 'delatex__behave': 'mask',\n",
       " 'tfidf_v__max_df': 0.6,\n",
       " 'tfidf_v__ngram_range': (1, 2),\n",
       " 'tfidf_v__stop_words': None,\n",
       " 'tfidf_v__use_idf': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_results = pd.DataFrame(grid_s.cv_results_)\n",
    "cols = ['param_' + param for param in params.keys()] + ['mean_test_score']\n",
    "results_df = grid_cv_results[cols].sort_values(by=['mean_test_score','param_delatex__behave','param_tfidf_v__max_df'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.791242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.791209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.790569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.790383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.790162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.789770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "6                   mask                            None   \n",
       "30                  None                            None   \n",
       "38                  None                            None   \n",
       "46                  None                            None   \n",
       "14                  mask                            None   \n",
       "22                  mask                            None   \n",
       "28                  None  [the, of, and, in, to, we, is]   \n",
       "4                   mask  [the, of, and, in, to, we, is]   \n",
       "44                  None  [the, of, and, in, to, we, is]   \n",
       "36                  None  [the, of, and, in, to, we, is]   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "6                      (1, 2)                   True                   0.6   \n",
       "30                     (1, 2)                   True                   0.6   \n",
       "38                     (1, 2)                   True                  0.75   \n",
       "46                     (1, 2)                   True                   0.9   \n",
       "14                     (1, 2)                   True                  0.75   \n",
       "22                     (1, 2)                   True                   0.9   \n",
       "28                     (1, 2)                   True                   0.6   \n",
       "4                      (1, 2)                   True                   0.6   \n",
       "44                     (1, 2)                   True                   0.9   \n",
       "36                     (1, 2)                   True                  0.75   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "6                 0.2         0.791242  \n",
       "30                0.2         0.791209  \n",
       "38                0.2         0.790569  \n",
       "46                0.2         0.790383  \n",
       "14                0.2         0.790162  \n",
       "22                0.2         0.789770  \n",
       "28                0.2         0.788460  \n",
       "4                 0.2         0.788429  \n",
       "44                0.2         0.788314  \n",
       "36                0.2         0.788314  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 0.2) & (results_df.param_tfidf_v__ngram_range==(1,2))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.780536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.780056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.780056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.779035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.778934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.778753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "29                  None  [the, of, and, in, to, we, is]   \n",
       "21                  mask  [the, of, and, in, to, we, is]   \n",
       "13                  mask  [the, of, and, in, to, we, is]   \n",
       "7                   mask                            None   \n",
       "47                  None                            None   \n",
       "45                  None  [the, of, and, in, to, we, is]   \n",
       "37                  None  [the, of, and, in, to, we, is]   \n",
       "23                  mask                            None   \n",
       "15                  mask                            None   \n",
       "39                  None                            None   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "29                     (1, 2)                  False                   0.6   \n",
       "21                     (1, 2)                  False                   0.9   \n",
       "13                     (1, 2)                  False                  0.75   \n",
       "7                      (1, 2)                  False                   0.6   \n",
       "47                     (1, 2)                  False                   0.9   \n",
       "45                     (1, 2)                  False                   0.9   \n",
       "37                     (1, 2)                  False                  0.75   \n",
       "23                     (1, 2)                  False                   0.9   \n",
       "15                     (1, 2)                  False                  0.75   \n",
       "39                     (1, 2)                  False                  0.75   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "29                0.2         0.780536  \n",
       "21                0.2         0.780056  \n",
       "13                0.2         0.780056  \n",
       "7                 0.2         0.779726  \n",
       "47                0.2         0.779349  \n",
       "45                0.2         0.779298  \n",
       "37                0.2         0.779298  \n",
       "23                0.2         0.779035  \n",
       "15                0.2         0.778934  \n",
       "39                0.2         0.778753  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 0.2) & (results_df.param_tfidf_v__ngram_range==(1,2))][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.783177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.783177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.783177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.782364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "40                  None  [the, of, and, in, to, we, is]   \n",
       "32                  None  [the, of, and, in, to, we, is]   \n",
       "34                  None                            None   \n",
       "42                  None                            None   \n",
       "24                  None  [the, of, and, in, to, we, is]   \n",
       "26                  None                            None   \n",
       "16                  mask  [the, of, and, in, to, we, is]   \n",
       "8                   mask  [the, of, and, in, to, we, is]   \n",
       "10                  mask                            None   \n",
       "0                   mask  [the, of, and, in, to, we, is]   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "40                     (1, 1)                   True                   0.9   \n",
       "32                     (1, 1)                   True                  0.75   \n",
       "34                     (1, 1)                   True                  0.75   \n",
       "42                     (1, 1)                   True                   0.9   \n",
       "24                     (1, 1)                   True                   0.6   \n",
       "26                     (1, 1)                   True                   0.6   \n",
       "16                     (1, 1)                   True                   0.9   \n",
       "8                      (1, 1)                   True                  0.75   \n",
       "10                     (1, 1)                   True                  0.75   \n",
       "0                      (1, 1)                   True                   0.6   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "40                0.2         0.783177  \n",
       "32                0.2         0.783177  \n",
       "34                0.2         0.783177  \n",
       "42                0.2         0.782992  \n",
       "24                0.2         0.782940  \n",
       "26                0.2         0.782940  \n",
       "16                0.2         0.782872  \n",
       "8                 0.2         0.782872  \n",
       "10                0.2         0.782872  \n",
       "0                 0.2         0.782364  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 0.2) & (results_df.param_tfidf_v__ngram_range==(1,1))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.784678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.784561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "54                  mask                            None   \n",
       "70                  mask                            None   \n",
       "62                  mask                            None   \n",
       "94                  None                            None   \n",
       "86                  None                            None   \n",
       "78                  None                            None   \n",
       "92                  None  [the, of, and, in, to, we, is]   \n",
       "84                  None  [the, of, and, in, to, we, is]   \n",
       "68                  mask  [the, of, and, in, to, we, is]   \n",
       "60                  mask  [the, of, and, in, to, we, is]   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "54                     (1, 2)                   True                   0.6   \n",
       "70                     (1, 2)                   True                   0.9   \n",
       "62                     (1, 2)                   True                  0.75   \n",
       "94                     (1, 2)                   True                   0.9   \n",
       "86                     (1, 2)                   True                  0.75   \n",
       "78                     (1, 2)                   True                   0.6   \n",
       "92                     (1, 2)                   True                   0.9   \n",
       "84                     (1, 2)                   True                  0.75   \n",
       "68                     (1, 2)                   True                   0.9   \n",
       "60                     (1, 2)                   True                  0.75   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "54                  2         0.784678  \n",
       "70                  2         0.784561  \n",
       "62                  2         0.783827  \n",
       "94                  2         0.783620  \n",
       "86                  2         0.783560  \n",
       "78                  2         0.783283  \n",
       "92                  2         0.783071  \n",
       "84                  2         0.783071  \n",
       "68                  2         0.783070  \n",
       "60                  2         0.783070  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 2) & (results_df.param_tfidf_v__ngram_range==(1,2))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "83                  None                            None   \n",
       "64                  mask  [the, of, and, in, to, we, is]   \n",
       "56                  mask  [the, of, and, in, to, we, is]   \n",
       "58                  mask                            None   \n",
       "72                  None  [the, of, and, in, to, we, is]   \n",
       "74                  None                            None   \n",
       "48                  mask  [the, of, and, in, to, we, is]   \n",
       "50                  mask                            None   \n",
       "73                  None  [the, of, and, in, to, we, is]   \n",
       "75                  None                            None   \n",
       "\n",
       "   param_tfidf_v__ngram_range param_tfidf_v__use_idf param_tfidf_v__max_df  \\\n",
       "83                     (1, 1)                  False                  0.75   \n",
       "64                     (1, 1)                   True                   0.9   \n",
       "56                     (1, 1)                   True                  0.75   \n",
       "58                     (1, 1)                   True                  0.75   \n",
       "72                     (1, 1)                   True                   0.6   \n",
       "74                     (1, 1)                   True                   0.6   \n",
       "48                     (1, 1)                   True                   0.6   \n",
       "50                     (1, 1)                   True                   0.6   \n",
       "73                     (1, 1)                  False                   0.6   \n",
       "75                     (1, 1)                  False                   0.6   \n",
       "\n",
       "   param_LinearSVC__C  mean_test_score  \n",
       "83                  2         0.768993  \n",
       "64                  2         0.768403  \n",
       "56                  2         0.768403  \n",
       "58                  2         0.768403  \n",
       "72                  2         0.768203  \n",
       "74                  2         0.768203  \n",
       "48                  2         0.767866  \n",
       "50                  2         0.767866  \n",
       "73                  2         0.767772  \n",
       "75                  2         0.767772  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df.param_LinearSVC__C == 2) & (results_df.param_tfidf_v__ngram_range==(1,1))][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regards to our preprocessing steps:\n",
    "    * By and large the search was performed over unimportant parameters.\n",
    "    * The most important ones (at the level of gaining 0.8 percentage points), aside from the model's *C*, were: using (1,2)-word-grams rather than 1-word-grams and using IDFs over not using it.\n",
    "    * The influence of max_df is small and not very consistent.\n",
    "    * Our DeLaTeX behavior and stopwords have no significant effect.\n",
    "   \n",
    "In light of the above we will stick to:\n",
    "    * no DeLaTeX\n",
    "    * no stop-words\n",
    "    * (1,2)-grams\n",
    "    * using IDFs\n",
    "    * no max_df limit (meaning the default =1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated GridSearchCV for multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(name, model):\n",
    "    pipe = []\n",
    "    #pipe.append(( 'delatex', DeLaTeX(behave='flag') ))\n",
    "    pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=True, strip_accents='unicode', min_df = 2, ngram_range=(1,2))  ))\n",
    "    pipe.append(( name, model  ))\n",
    "    \n",
    "    return Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe_params(name, model_params):\n",
    "    params = {\n",
    "        #'delatex__behave': [None],  # (bug) switch off in order to use n_jobs in GridSearchCV\n",
    "        #'tfidf_v__ngram_range': [(1, 1), (1,2)],\n",
    "        #'tfidf_v__use_idf': [True, False],\n",
    "        #'tfidf_v__max_df': [0.8, 1.0],\n",
    "    }\n",
    "    for (param_name, range_) in model_params:\n",
    "        params[name + '__' + param_name] = range_\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify models with grid of parametrs and run the GridSearchCV, cv=4 (stratified by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \n",
    "#     'rbfSVC': [SVC(class_weight='balanced', gamma='scale'),\n",
    "#             [( 'C', [0.04, 0.2, 1, 5] )]\n",
    "#            ],\n",
    "    'LogReg': [LogisticRegression(class_weight='balanced', solver='lbfgs', multi_class='multinomial', max_iter=500),\n",
    "                  [( 'C', [0.04, 0.2, 1, 5] ), ('multi_class', ['multinomial','ovr'])]\n",
    "                 ],\n",
    "    'RndFClf': [RandomForestClassifier(class_weight='balanced', n_estimators=300),\n",
    "                 [('max_depth', [10, 20, 30]) , ('min_samples_leaf', [1E-5, 1E-4, 1E-3])]\n",
    "                ],\n",
    "    'LinSVC': [LinearSVC(class_weight='balanced'),\n",
    "                  [( 'C', [0.04, 0.2, 1, 5] )]\n",
    "                 ],\n",
    "    'MultNB': [MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None),\n",
    "                [('alpha', [0.01, 0.1, 1])]\n",
    "               ],\n",
    "    'NearCen': [NearestCentroid(),\n",
    "                [('metric', ['euclidean','manhattan'])]\n",
    "               ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  32 out of  32 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7220762959521979 \n",
      "\n",
      "RndFClf\n",
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  36 out of  36 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6220591350084321 \n",
      "\n",
      "LinSVC\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  16 out of  16 | elapsed:   39.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7018498133838 \n",
      "\n",
      "MultNB\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  12 out of  12 | elapsed:   25.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6140310893111534 \n",
      "\n",
      "NearCen\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "0.6884823674920653 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   8 out of   8 | elapsed:   30.0s finished\n"
     ]
    }
   ],
   "source": [
    "# GRID-SEARCH\n",
    "\n",
    "# collect the best_params for the models\n",
    "results = {}\n",
    "\n",
    "for name, (model, model_params) in models.items():\n",
    "    \n",
    "    print(name)\n",
    "    pipe = build_clf(name, model)\n",
    "    params = build_pipe_params(name, model_params)\n",
    "    \n",
    "    grid_s = GridSearchCV(pipe, params, cv=4, scoring=scoring, iid=False, return_train_score=True, n_jobs=3, refit=False, verbose=1)\n",
    "    grid_s.fit(text_train, y_train)\n",
    "    \n",
    "    print(grid_s.best_score_, \"\\n\")\n",
    "    results[name] = [grid_s.best_params_, grid_s.best_score_, grid_s.cv_results_]\n",
    "\n",
    "    \n",
    "# store the best_params in the models dict\n",
    "for name, result in results.items():\n",
    "    \n",
    "    best_params = result[0]    \n",
    "    models[name].append(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=None, max_features='auto',\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=300, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " [('max_depth', [10, 20, 30]), ('min_samples_leaf', [1e-05, 0.0001, 0.001])],\n",
       " {'RndFClf__max_depth': 10, 'RndFClf__min_samples_leaf': 0.001}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the obtaind best_params of Random Forest for example\n",
    "models[\"RndFClf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the whole train data to the tuned classifiers. Record final scores on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_num = len(data)\n",
    "train_vol = int(large_num*3/4)\n",
    "\n",
    "final_train = data[:train_vol]\n",
    "final_test = data[train_vol:large_num]\n",
    "\n",
    "\n",
    "final_text_train = final_train.text\n",
    "final_y_train = label_e.transform(final_train.label)\n",
    "\n",
    "final_text_test = final_test.text\n",
    "final_y_test = label_e.transform(final_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-bf3fee768658>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mpipe_best_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_text_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1358\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m                       sample_weight=sample_weight)\n\u001b[1;32m-> 1360\u001b[1;33m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[0;32m    753\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[0;32m    756\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"warnflag\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 199\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    201\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x, *args)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_multi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[1;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m     grad = np.zeros((n_classes, n_features + bool(fit_intercept)),\n\u001b[0;32m    344\u001b[0m                     dtype=X.dtype)\n\u001b[1;32m--> 345\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[1;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[0mintercept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \"\"\"\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"toarray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    468\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[1;31m# csr_matvecs or csc_matvecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_matvecs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m         \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_vecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_scores = {}\n",
    "\n",
    "for name, (model, grid, pipe_best_params) in models.items():\n",
    "    \n",
    "    clf = build_clf(name, model)\n",
    "    clf.set_params(**pipe_best_params)\n",
    "    clf.fit(final_text_train, final_y_train)\n",
    "    models[name].append(clf)\n",
    "    print(f\"Fitted {name}.\")\n",
    "    \n",
    "    final_scores[name] = f1_score(final_y_test, clf.predict(final_text_test), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinSVC': 0.7707762108831197,\n",
       " 'LogReg': 0.7618005083247673,\n",
       " 'RndFClf': 0.6369622568461526,\n",
       " 'NearCen': 0.6891147145642181,\n",
       " 'MultNB': 0.637215428459177,\n",
       " 'BernNB': 0.7385950280121687,\n",
       " 'RidgeClf': 0.5723399898221054}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = range(len(final_scores))\n",
    "plt.ylim(0.5, 1)\n",
    "plt.bar(count, np.array(list(final_scores.values())))\n",
    "plt.xticks(count, list(final_scores.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the best model in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib / pickle\n",
    "dump(models['?'], 'filename.joblib'?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load('filename.joblib')\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = model[2]\n",
    "# clf.predict(random_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
