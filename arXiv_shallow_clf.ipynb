{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import SCORERS, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer #, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "#from sklearn.linear_model import SGDlassifier(loss = ...) # loss='hinge'/'log'\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "### Bag od words with SVMs, Log-Regression, Random-Forest etc. on top \n",
    "\n",
    "* Build and test a preprocessing pipe:\n",
    "    * Handle *LaTeX* formulas before count-vectorizatation and TFIDF transformation.\n",
    "    * Test a handful of preprocessing parameters (inc. 2-grams, idf switched on/off, maximal document frequency) with a single untuned classifier.\n",
    "* Test a handful of shallow multiclass classifiers with *macro-F1* as the objective, this time without broadly changing the preprocessing parameters:\n",
    "* The grid-search in both step is (likely) performed on a fraction of the train data.\n",
    "* Fit the tuned classifiers to the whole of train data.\n",
    "* Collect the *macro-f1* scores obtained on the test data.\n",
    "* ... Save the best fitted model to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the volume\n",
    "The whole forthcoming analysis in the notebook is parametrized by the number of records that we wish to use. The maximum that we have is 838_804 in *data/bare_all.csv*, but we will choose to work with a smaller sample for convenience. This is done conceptually before any considerations about testing, validating etc., as if we simply had harvested a smaller dataset. Also, we will first tune the classifiers on a *small_number* of records, and only later refit and evaluate them on a *big_number* of records as if we had harvested additional data after the tuning (see below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_number = 50_000\n",
    "big_number = 55_000 # 838_804"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the measure of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available scikit-learn's scorers\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my choice\n",
    "scoring = \"f1_macro\"\n",
    "average = \"macro\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the two-column data frame (text + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"data\", \"bare_all.csv\")\n",
    "data = pd.read_csv(file, delimiter='\\t', nrows=small_number)\n",
    "\n",
    "# it happens to be shuffled already\n",
    "data_train = data[: int(small_num*0.8)]\n",
    "data_test = data[int(small_num*0.8) :]\n",
    "\n",
    "text_train = data_train.text\n",
    "label_train = data_train.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. all records in memory: 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On the interplay between star formation and feedback in galaxy formation simulations.  We investigate the star forma...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transversal Homotopy Monoids of Complex Projective Space.  We will give a geometric description of the nth transvers...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remarks on some typical assumptions in dynamo theory.  Some concepts used in the theory of convection-driven dynamos...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      text  \\\n",
       "0  On the interplay between star formation and feedback in galaxy formation simulations.  We investigate the star forma...   \n",
       "1  Transversal Homotopy Monoids of Complex Projective Space.  We will give a geometric description of the nth transvers...   \n",
       "2  Remarks on some typical assumptions in dynamo theory.  Some concepts used in the theory of convection-driven dynamos...   \n",
       "\n",
       "  label  \n",
       "0  phys  \n",
       "1  math  \n",
       "2  phys  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"No. all records in memory: {len(data)}\")\n",
    "with pd.option_context('display.max_colwidth', 120):\n",
    "    display(data_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts of scientific papers tend to be written in a formal style, to not contain typos, nor direct citations, little references, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounds on generators and relations for the algebra of $SL_2(\\C)$ conformal blocks.  We show that the Cox ring of the moduli of $SL_2(\\C)$ quasi-parabolic principal bundles on a marked curve is generated by conformal blocks of level 1 and 2. We show that the ideal which vanishes on these generators is generated by forms of degrees $2, 3, 4.$ \n",
      "---\n",
      "T/Key: Second-Factor Authentication From Secure Hash Chains.  Time-based one-time password (TOTP) systems in use today require storing secrets on both the client and the server. As a result, an attack on the server can expose all second factors for all users in the system. We present T/Key, a time-based one-time password system that requires no secrets on the server. Our work modernizes the classic S/Key system and addresses the challenges in making such a system secure and practical. At the heart of our construction is a new lower bound analyzing the hardness of inverting hash chains composed of independent random functions, which formalizes the security of this widely used primitive. Additionally, we develop a near-optimal algorithm for quickly generating the required elements in a hash chain with little memory on the client. We report on our implementation of T/Key as an Android application. T/Key can be used as a replacement for current TOTP systems, and it remains secure in the event of a server-side compromise. The cost, as with S/Key, is that one-time passwords are longer than the standard six characters used in TOTP. \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(text_train.iloc[random.choice(range(len(text)))])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One messy but informative kind of writing they have are LaTeX formulas (*\\$...\\$*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group $\\\\Gamma$ on a single element $\\\\psi$ of a given Hilbert space $\\\\mathcal{H}$. As $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the $L^1$-space associated to the group von '"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[6][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose to either mask them with * \\_latex\\_ * or flag them by appending * \\_latex\\_ * in front of each such expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask or flag LaTeX expression with a word ' _LATEX_ '\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "    # self.pattern = r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\"\n",
    "    # why does it differ from  r'(\\$.+?\\$)' ?\n",
    "    \n",
    "class DeLaTeX(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, behave=None, pattern=r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\", repl = ' _LATEX_ '):\n",
    "        self.repl = ' _LATEX_ '\n",
    "        self.pattern = pattern\n",
    "        self.behave = behave\n",
    "        \n",
    "        if self.behave == 'mask':\n",
    "            self.repl = ' _LATEX_ '\n",
    "        elif self.behave == 'flag':\n",
    "            self.repl = r' _LATEX_ \\1'\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.core.series.Series):\n",
    "            raise TypeError(\"The data must be a pandas Series of strings\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.behave:\n",
    "            return X.str.replace(self.pattern, self.repl)\n",
    "        return X\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.estimator_checks import check_estimator\n",
    "# check_estimator(DeLaTeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group $\\\\Gamma$ on a single element $\\\\psi$ of a given Hilbert space $\\\\mathcal{H}$. As $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the $L^1$-space associated to the group von Neumann algebra of $\\\\Gamma$. Our result generalizes recent work for LCA groups. In many cases, the bracket map can be computed in terms of a noncommutative form of the Zak transform. '"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = None)\n",
    "delatex.transform(text_train[6:7]).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_  on a single element  _LATEX_  of a given Hilbert space  _LATEX_ . As  _LATEX_  might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ -space associated to the group von Neumann algebra of  _LATEX_ . Our result generalizes recent work for LCA groups. In many cases, the bracket map can be computed in terms of a noncommutative form of the Zak transform. '"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'mask')\n",
    "delatex.transform(text_train[6:7]).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_ $\\\\Gamma$ on a single element  _LATEX_ $\\\\psi$ of a given Hilbert space  _LATEX_ $\\\\mathcal{H}$. As  _LATEX_ $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ $L^1$-space associated to the group von Neumann algebra of  _LATEX_ $\\\\Gamma$. Our result generalizes recent work for LCA groups. In many cases, the bracket map can be computed in terms of a noncommutative form of the Zak transform. '"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "delatex.transform(text_train[6:7]).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs', 'math', 'phys', 'q-bio', 'q-fin', 'stat']\n"
     ]
    }
   ],
   "source": [
    "# 'cs' -> 0, ..., 'stat' -> 5\n",
    "\n",
    "label_e = LabelEncoder()\n",
    "y_train = label_e.fit_transform(label_train)\n",
    "\n",
    "print(list(label_e.classes_))\n",
    "\n",
    "#label_e.inverse_transform([0]) # array(['cs'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the most frequent words. Choose winners as the stop-words.\n",
    "Take note of the rank of our '\\_latex\\_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 76209)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "count_v = CountVectorizer(strip_accents='unicode')\n",
    "word_counts_train = count_v.fit_transform(delatex.fit_transform(text_train))\n",
    "word_counts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(423000, 'the'),\n",
       " (268000, 'of'),\n",
       " (148000, 'and'),\n",
       " (132000, 'in'),\n",
       " (110000, 'to'),\n",
       " (85000, 'we'),\n",
       " (78000, 'is'),\n",
       " (73000, 'for'),\n",
       " (71000, '_latex_'),\n",
       " (57000, 'that')]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_word_counts_train = word_counts_train.sum(axis=0)\n",
    "sorted([(round(sum_word_counts_train[0, i],-3), word) for word, i in count_v.vocabulary_.items()],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['the', 'of', 'and', 'in','to','we','is'] # 'for' seems already mathematical/computer-sciency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go step by step through an arbitrary pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX(behave='mask')\n",
    "notex_text_train = delatex.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(use_idf=True, stop_words=stopwords, min_df = 2, max_df=0.8, strip_accents='unicode')\n",
    "tfidf_scores_train = tfidf_v.fit_transform(notex_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1, class_weight='balanced')\n",
    "lsvc.fit(tfidf_scores_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's just have some fun first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_abstracts = pd.Series([\"\"\"\n",
    "The Lack of A Priori Distinctions Between Learning Algorithms. This is the first of\n",
    "two papers that use off-training set (OTS) error to investigate the assumption-free\n",
    "relationship between learning algorithms. This first paper discusses the senses in\n",
    "which there are no a priori distinctions between learning algorithms. (The second\n",
    "paper discusses the senses in which there are such distinctions.) In this first paper\n",
    "it is shown, loosely speaking, that for any two algorithms A and B, there are \"as many\"\n",
    "targets (or priors over targets) for which A has lower expected OTS error than B as\n",
    "vice versa, for loss functions like zero-one loss. In particular, this is true if A\n",
    "is cross-validation and B is \"anti-cross-validation'' (choose the learning algorithm\n",
    "with largest cross-validation error). This paper ends with a discussion of the\n",
    "implications of these results for computational learning theory. It is shown that one\n",
    "cannot say: if empirical misclassification rate is low, the Vapnik-Chervonenkis\n",
    "dimension of your generalizer is small, and the training set is large, then with high\n",
    "probability your OTS error is small. Other implications for \"membership queries\"\n",
    "algorithms and \"punting\" algorithms are also discussed.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "X-rays quarks lepton scattering experiment field\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "genes DNA RNA sequencing protein species fenotype \n",
    "\"\"\",\n",
    "\"\"\"\n",
    "computer algorithm graph sorting depth first interface\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "novel intuitive proof of $\\limit_{x\\to 0} x = 0$ convergence fomula,\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "inflation resources market stock bonds derivatives\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "confidence Bayesian p value marginalization Monte Carlo\n",
    "\"\"\"\n",
    "])\n",
    "\n",
    "label_e.inverse_transform(lsvc.predict(tfidf_v.transform(delatex.transform(random_abstracts ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks promising :)\n",
    "Here's the actual score on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.7645413819228147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.84      0.88      0.86      1378\n",
      "        math       0.88      0.90      0.89      2340\n",
      "        phys       0.97      0.95      0.96      5933\n",
      "       q-bio       0.63      0.57      0.60       139\n",
      "       q-fin       0.79      0.69      0.74        45\n",
      "        stat       0.52      0.55      0.54       165\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "[[1215   89   33   10    1   30]\n",
      " [  93 2114   89    4    1   39]\n",
      " [  73  170 5654   24    5    7]\n",
      " [  15   10   28   79    0    7]\n",
      " [   4    6    2    1   31    1]\n",
      " [  42   16    8    7    1   91]]\n"
     ]
    }
   ],
   "source": [
    "text_test = data_test.text\n",
    "label_test = data_test.label\n",
    "y_test = label_e.transform(label_test)\n",
    "\n",
    "predicted_y_test = lsvc.predict(tfidf_v.transform(delatex.transform(text_test)))\n",
    "\n",
    "print(\"Macro F1:\", f1_score(y_test, predicted_y_test, average=\"macro\"))\n",
    "print(classification_report(y_test, predicted_y_test, target_names=label_e.classes_))\n",
    "nofuss_conf_mtrx = confusion_matrix(y_test, predicted_y_test)\n",
    "print(nofuss_conf_mtrx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"By definition a confusion matrix $C$ is such that $C_{ij}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\" https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the above easily obtained confusion matrix in a *nofuss_conf_mtrx* variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained on a fraction of all records with an untuned Linear SVM, we have reached ~0.76 macro-F1 (out of sample) pulled down by poor performomance on classification wrt rarer classes. E.g. many *cs* and *math* are confused with *stat* (and vice versa), and similarly for *q-bio* and *physics*. This is actually sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid searching by hand through preprocessing params with Linear SVM Classifiers\n",
    "The goal now is to put a finger on reasonable preprocessing parameters. It would of course be better to include them in one global grid search with each classifier, but we do not have the resources for that. We are simply hoping to gain insight into whether any of the parameters (strategies) in the grid below is particularly important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = []\n",
    "pipe.append(( 'delatex', DeLaTeX(behave='mask') ))\n",
    "pipe.append(( 'tfidf_v', TfidfVectorizer(analyzer = 'word', strip_accents='unicode', min_df = 2)  ))\n",
    "pipe.append(( 'LinearSVC', LinearSVC(C=1, penalty='l2', class_weight='balanced')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'delatex__behave': ['mask', 'flag', None],\n",
    "    'tfidf_v__stop_words': [stopwords, None],\n",
    "#    'tfidf_v__ngram_range': [(1, 1), (1,2)], # cannot afford it computationally\n",
    "    'tfidf_v__use_idf': [True, False],\n",
    "    'tfidf_v__max_df': [0.6, 0.8, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n",
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "print(text_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed: 32.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave='mask',\n",
       "    pattern='(\\\\${1,2}[\\\\s\\\\w\\\\d\\\\\\\\,\\\\.=\\\\(\\\\)*{}/\\\\[\\\\]^;:\\'`<>|%&@\\\\\"!\\\\?~#+-]*?\\\\${1,2})',\n",
       "    repl=' _LATEX_ ')), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=False, n_jobs=1,\n",
       "       param_grid={'delatex__behave': ['mask', 'flag', None], 'tfidf_v__stop_words': [['the', 'of', 'and', 'in', 'to', 'we', 'is'], None], 'tfidf_v__use_idf': [True, False], 'tfidf_v__max_df': [0.6, 0.8, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=1)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LONG WAIT\n",
    "\n",
    "# there's some bug with njobs different than 1 because of the delatex in the pipe\n",
    "# may be related to the fact that check_estimator(DeLaTeX) raises an error due to DeLaTeX using the pandas' vectorized str method \n",
    "\n",
    "grid_s = GridSearchCV(Pipeline(pipe), params, cv=4, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False, verbose=1)\n",
    "grid_s.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7648662306066194"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delatex__behave': None,\n",
       " 'tfidf_v__max_df': 0.8,\n",
       " 'tfidf_v__stop_words': None,\n",
       " 'tfidf_v__use_idf': True}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_results = pd.DataFrame(grid_s.cv_results_)\n",
    "cols = ['param_' + param for param in params.keys()] + ['mean_test_score']\n",
    "results_df = grid_cv_results[cols].sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.764866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.764103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.764103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.764037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.763979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.763979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.762639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.762639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.762607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.762607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.762246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.762246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.761844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.761844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.761844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.761844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.760107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.755977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.755396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.755336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.755336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.754980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.754980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.754863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.754863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.754863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.754863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.753381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.753381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "30                  None                            None   \n",
       "10                  mask                            None   \n",
       "22                  flag                            None   \n",
       "34                  None                            None   \n",
       "32                  None  [the, of, and, in, to, we, is]   \n",
       "28                  None  [the, of, and, in, to, we, is]   \n",
       "26                  None                            None   \n",
       "24                  None  [the, of, and, in, to, we, is]   \n",
       "18                  flag                            None   \n",
       "6                   mask                            None   \n",
       "16                  flag  [the, of, and, in, to, we, is]   \n",
       "4                   mask  [the, of, and, in, to, we, is]   \n",
       "8                   mask  [the, of, and, in, to, we, is]   \n",
       "20                  flag  [the, of, and, in, to, we, is]   \n",
       "0                   mask  [the, of, and, in, to, we, is]   \n",
       "2                   mask                            None   \n",
       "12                  flag  [the, of, and, in, to, we, is]   \n",
       "14                  flag                            None   \n",
       "35                  None                            None   \n",
       "23                  flag                            None   \n",
       "11                  mask                            None   \n",
       "31                  None                            None   \n",
       "33                  None  [the, of, and, in, to, we, is]   \n",
       "29                  None  [the, of, and, in, to, we, is]   \n",
       "17                  flag  [the, of, and, in, to, we, is]   \n",
       "21                  flag  [the, of, and, in, to, we, is]   \n",
       "9                   mask  [the, of, and, in, to, we, is]   \n",
       "5                   mask  [the, of, and, in, to, we, is]   \n",
       "19                  flag                            None   \n",
       "7                   mask                            None   \n",
       "3                   mask                            None   \n",
       "15                  flag                            None   \n",
       "13                  flag  [the, of, and, in, to, we, is]   \n",
       "1                   mask  [the, of, and, in, to, we, is]   \n",
       "27                  None                            None   \n",
       "25                  None  [the, of, and, in, to, we, is]   \n",
       "\n",
       "   param_tfidf_v__use_idf param_tfidf_v__max_df  mean_test_score  \n",
       "30                   True                   0.8         0.764866  \n",
       "10                   True                     1         0.764103  \n",
       "22                   True                     1         0.764103  \n",
       "34                   True                     1         0.764037  \n",
       "32                   True                     1         0.763979  \n",
       "28                   True                   0.8         0.763979  \n",
       "26                   True                   0.6         0.762639  \n",
       "24                   True                   0.6         0.762639  \n",
       "18                   True                   0.8         0.762607  \n",
       "6                    True                   0.8         0.762607  \n",
       "16                   True                   0.8         0.762246  \n",
       "4                    True                   0.8         0.762246  \n",
       "8                    True                     1         0.762246  \n",
       "20                   True                     1         0.762246  \n",
       "0                    True                   0.6         0.761844  \n",
       "2                    True                   0.6         0.761844  \n",
       "12                   True                   0.6         0.761844  \n",
       "14                   True                   0.6         0.761844  \n",
       "35                  False                     1         0.760107  \n",
       "23                  False                     1         0.758532  \n",
       "11                  False                     1         0.758532  \n",
       "31                  False                   0.8         0.755977  \n",
       "33                  False                     1         0.755396  \n",
       "29                  False                   0.8         0.755396  \n",
       "17                  False                   0.8         0.755336  \n",
       "21                  False                     1         0.755336  \n",
       "9                   False                     1         0.755336  \n",
       "5                   False                   0.8         0.755336  \n",
       "19                  False                   0.8         0.754980  \n",
       "7                   False                   0.8         0.754980  \n",
       "3                   False                   0.6         0.754863  \n",
       "15                  False                   0.6         0.754863  \n",
       "13                  False                   0.6         0.754863  \n",
       "1                   False                   0.6         0.754863  \n",
       "27                  False                   0.6         0.753381  \n",
       "25                  False                   0.6         0.753381  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, with regards to our preprocessing steps, as a first order conclusion:\n",
    "    * All the parameters seem rather unimportant.\n",
    "    * The most important ones - in the sense of crowding the top of the above list - seem to be: using idf over not using it, and larger max_df rather than smaller.\n",
    "    * Our DeLaTeX behavior and stopwords do not have a significant effect.\n",
    "   \n",
    "In light of the above we will stick to:\n",
    "    * masking LaTeX\n",
    "    * no stop-words\n",
    "    * using IDFs\n",
    "    * no max_df limit (meaning the default =1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For convenience, I will mask the LaTeX in the whole dataset once, save it to file. From now on I will use it as the default dataset to work on.\n",
    "Imagining than I will be given a new arXiv metadata to classify, I would have to first explicitly push it through the DeLaTeX transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the records we have on disk\n",
    "file = os.path.join(\"data\", \"bare_all.csv\")\n",
    "all_data = pd.read_csv(file, delimiter='\\t', nrows=None)\n",
    "\n",
    "# mask away the LaTeX\n",
    "notex_data = pd.DataFrame()\n",
    "delatex = DeLaTeX(behave='mask')\n",
    "notex_data['text'] = delatex.transform(all_data.text)\n",
    "notex_data['label'] = all_data.label\n",
    "\n",
    "# and store it to disk\n",
    "file = os.path.join(\"data\", \"notex_all.csv\")\n",
    "notex_data.to_csv(file, sep = '\\t', index = False)\n",
    "\n",
    "# clear the pythonic variables from memory\n",
    "%reset_selective -f \"^all_data$\"\n",
    "%reset_selective -f \"^notex_data$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read back in the smaller sample for convenience\n",
    "small_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"data\", \"notex_all.csv\")\n",
    "data = pd.read_csv(file, delimiter='\\t', nrows=small_num)\n",
    "\n",
    "data_train = data[: int(small_num*0.8)]\n",
    "data_test = data[int(small_num*0.8) :]\n",
    "\n",
    "text_train = data_train.text\n",
    "label_train = data_train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_  on a single element  _LATEX_  of a given Hilbert space  _LATEX_ . As  _LATEX_  might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ -space associated to the group'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[6][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated GridSearchCV for multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify models with a grid of hyper-parameters to choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \n",
    "    'LogReg': [LogisticRegression(class_weight='balanced', solver='lbfgs', multi_class='multinomial', max_iter=500),\n",
    "                  [( 'C', [0.2, 1, 5, 10, 25] ), ('multi_class', ['multinomial','ovr'])]\n",
    "                 ],\n",
    "    'RndFClf': [RandomForestClassifier(class_weight='balanced', n_estimators=200, criterion=\"gini\"),\n",
    "                 [('max_depth', [10, 15, 20, 25]) , ('min_samples_leaf', [1E-5, 1E-4, 1E-3])]\n",
    "                ],\n",
    "    'LinSVC': [LinearSVC(class_weight='balanced'),\n",
    "                  [( 'C', [0.008, 0.04, 0.01, 0.2, 0.05, 1, 5] )]\n",
    "                 ],\n",
    "    'NearCen': [NearestCentroid(),\n",
    "                [('metric', ['euclidean','manhattan'])]\n",
    "               ],\n",
    "    'MultNB': [MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None),\n",
    "                [('alpha', [0.001, 0.003, 0.01, 0.03, 0.1])]\n",
    "               ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(name, model):\n",
    "    pipe = []\n",
    "    pipe.append(( 'delatex', DeLaTeX(behave='mask') ))\n",
    "    pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=True, strip_accents='unicode', min_df = 2)  ))\n",
    "    pipe.append(( name, model  ))\n",
    "    \n",
    "    return Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe_params(name, model_params):\n",
    "    \n",
    "    params = {}\n",
    "    for (param_name, range_) in model_params:\n",
    "        params[name + '__' + param_name] = range_\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search with cv=4 (stratified by default)\n",
    "Hyper-parameter tuning: Measure the score for each combination of values. Use cross-validation to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-281-a91d56572dc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgrid_s_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# GRID-SEARCH\n",
    "\n",
    "# collect the best_params for the models\n",
    "grid_s_results = {}\n",
    "\n",
    "for name, (model, model_params) in models.items():\n",
    "    \n",
    "    print(name)\n",
    "    pipe = build_clf(name, model)\n",
    "    params = build_pipe_params(name, model_params)\n",
    "    \n",
    "    grid_s = GridSearchCV(pipe, params, cv=4, scoring=scoring,\\\n",
    "                          iid=False, return_train_score=True,\\\n",
    "                          n_jobs=3, refit=False, verbose=1)\n",
    "    grid_s.fit(text_train, y_train)\n",
    "    \n",
    "    print(grid_s.best_score_, \"\\n\")\n",
    "    grid_s_results[name] = grid_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LogReg, 0.7662735115316531, {'LogReg__C': 5, 'LogReg__multi_class': 'ovr'}\n",
      " RndFClf, 0.6971225628503566, {'RndFClf__criterion': 'gini', 'RndFClf__max_depth': 25, 'RndFClf__min_samples_leaf': 0.0001}\n",
      "  LinSVC, 0.7657854576331379, {'LinSVC__C': 0.2}\n",
      " NearCen, 0.6603548185074385, {'NearCen__metric': 'euclidean'}\n",
      "  MultNB, 0.7443547450863567, {'MultNB__alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# examine the obtaind scores and best_params\n",
    "for name, grid_s in grid_s_results.items():\n",
    "    print(f\"{name:>8}, {grid_s.best_score_}, {grid_s.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append the best_params and f1-scores from grid-search to the *models* dict and store it in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, grid_s in grid_s_results.items():\n",
    "    \n",
    "    models[name].append(grid_s.best_score_)\n",
    "    models[name].append(grid_s.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arXiv_shallow_tuning_results.joblib']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib / pickle\n",
    "dump(models, f'arXiv_shallow_tuning_on_{small_number}.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display macro F1 for all the classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting to 40000 records. Testing on unseen 10000.\n",
      "Fitted LogReg\n",
      "Fitted RndFClf\n",
      "Fitted LinSVC\n",
      "Fitted NearCen\n",
      "Fitted MultNB\n"
     ]
    }
   ],
   "source": [
    "models = load('arXiv_shallow_tuning_results.joblib')\n",
    "\n",
    "# The grid_search did not do a final 'refit'\n",
    "# We do it by hand and store the scores obtained on the test data in a new dict\n",
    "# along with the refitted models\n",
    "\n",
    "small_test_ranking = {}\n",
    "\n",
    "print(f\"Fitting to {len(text_train)} records. Testing on unseen {len(text_test)}.\")\n",
    "\n",
    "for name, (model, original_grid, score, best_params_) in models.items():\n",
    "    \n",
    "    clf = build_clf(name, model)\n",
    "    clf.set_params(**best_params_)\n",
    "    tick = time.time()\n",
    "    clf.fit(text_train, y_train)\n",
    "    tock = time.time()\n",
    "    \n",
    "    small_test_ranking[name] = [f1_score(y_test, clf.predict(text_test), average='macro'), clf]\n",
    "    \n",
    "    print(f\"Fitted {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinSVC': 0.7761207948470307,\n",
       " 'LogReg': 0.7705683999116041,\n",
       " 'MultNB': 0.7510970904737243,\n",
       " 'RndFClf': 0.7134458431327917,\n",
       " 'NearCen': 0.6564957532555155}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the dict with final F1 scores\n",
    "\n",
    "scores_list = sorted(small_test_ranking.items(), key=lambda model: model[1][0], reverse = True)\n",
    "scores_sorted = {name: score for (name, [score, _] ) in scores_list}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bf14c05b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = range(len(scores_sorted))\n",
    "plt.ylim(0.5, 1)\n",
    "plt.bar(count, list(scores_sorted.values()))\n",
    "plt.xticks(count, list(scores_sorted.keys()))\n",
    "plt.title(f\"Macro F1 scores on test data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit more train data to the tuned classifiers.\n",
    "The classifiers were tuned on a small number of records. Now we fit them anew to a bigger chunk of data.\n",
    "It would of course be more desirable to do the grid-search on the bigger chunk to begin with. We are just imagining a scenario, where we've obtained more data after tuning, and we wish to refit the model without repeating the grid-search. On should bare in mind that in general the tuned parameters are functions of the volume of data, so this approach relies on the assumption that those functions are not varying very fast, and it probably makes sense only if the new chunk is not many orders of magnitude bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load('arXiv_shallow_tuning_results.joblib')\n",
    "\n",
    "file = os.path.join(\"data\", \"notex_all.csv\")\n",
    "big_data = pd.read_csv(file, delimiter='\\t', nrows=large_number)  # lol, \"big-data\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data_train = big_data[:int(0.8*large_number)]\n",
    "big_data_test = big_data[int(0.8*large_number):]\n",
    "\n",
    "big_text_train = big_data_train.text\n",
    "big_y_train = label_e.transform(big_data_train.label)\n",
    "\n",
    "big_text_test = big_data_test.text\n",
    "big_y_test = label_e.transform(big_data_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted LogReg in 2 min. on big-data.\n",
      "Fitted RndFClf in 2 min. on big-data.\n",
      "Fitted LinSVC in 0 min. on big-data.\n",
      "Fitted NearCen in 0 min. on big-data.\n",
      "Fitted MultNB in 0 min. on big-data.\n"
     ]
    }
   ],
   "source": [
    "# the scores obtained on the test sample are stored in a new dict and the refitted models are appended in the 'models' dict\n",
    "\n",
    "big_test_ranking = {}\n",
    "\n",
    "print(\"Fitting on big-data :)\")\n",
    "\n",
    "for name, (model, original_grid, score, best_params_) in models.items():\n",
    "    \n",
    "    clf = build_clf(name, model)\n",
    "    clf.set_params(**best_params_)\n",
    "    tick = time.time()\n",
    "    clf.fit(big_text_train, big_y_train)\n",
    "    tock = time.time()\n",
    "    \n",
    "    big_test_ranking[name] = [f1_score(big_y_test, clf.predict(big_text_test), average='macro'), clf]\n",
    "    \n",
    "    print(f\" {name} in {(tock - tick)/60:.0f} min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display macro F1 for all the classfiers - after refitting on bigger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogReg': 0.7888135808707667,\n",
       " 'LinSVC': 0.7834846803690315,\n",
       " 'MultNB': 0.7641103960001768,\n",
       " 'RndFClf': 0.6731152958808639,\n",
       " 'NearCen': 0.6384163392173875}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the dict with final F1 scores\n",
    "# Save the the winning classifier\n",
    "\n",
    "ranking_list = sorted(big_test_ranking.items(), key=lambda item: item[1][0], reverse = True)\n",
    "\n",
    "winner = ranking_list[0][0]\n",
    "winner_clf = big_test_ranking[winner][1]\n",
    "\n",
    "scores_sorted = {name: score for (name, [score, _]) in ranking_list}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1beb4949940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = range(len(scores_sorted))\n",
    "plt.ylim(0.5, 1)\n",
    "plt.bar(count, list(scores_sorted.values()))\n",
    "plt.xticks(count, list(scores_sorted.keys()))\n",
    "plt.title(\"Macro F1 scores on unseen quarter of the data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_big_y_test = winner_clf.predict(big_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.84      0.89      0.86      5236\n",
      "        math       0.89      0.91      0.90      9161\n",
      "        phys       0.98      0.95      0.97     24190\n",
      "       q-bio       0.60      0.77      0.67       462\n",
      "       q-fin       0.70      0.80      0.75       246\n",
      "        stat       0.55      0.62      0.58       705\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     40000\n",
      "   macro avg       0.76      0.82      0.79     40000\n",
      "weighted avg       0.93      0.93      0.93     40000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4639,   314,    85,    51,    17,   130],\n",
       "       [  395,  8294,   245,    35,    38,   154],\n",
       "       [  288,   595, 23100,   135,    19,    53],\n",
       "       [   44,    12,    32,   355,     0,    19],\n",
       "       [   19,    15,     5,     1,   198,     8],\n",
       "       [  165,    62,    12,    17,    10,   439]], dtype=int64)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(big_y_test, predicted_big_y_test, target_names=label_e.classes_))\n",
    "conf_mtrx = confusion_matrix(big_y_test, predicted_big_y_test)\n",
    "conf_mtrx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The *Statistics* class appears to be escpecially ambigous "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how the articles have flown between classes in the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_nofuss_conf_mtrx = nofuss_conf_mtrx * len(big_y_test)/len(y_test)\n",
    "(conf_mtrx - rescaled_nofuss_conf_mtrx).sum() # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-220.,  -40.,  -50.,   10.,   10.,   10.],\n",
       "       [  20., -160., -110.,   20.,   30.,   -0.],\n",
       "       [  -0.,  -80.,  480.,   40.,   -0.,   20.],\n",
       "       [ -20.,  -30.,  -80.,   40.,    0.,  -10.],\n",
       "       [   0.,  -10.,   -0.,   -0.,   70.,    0.],\n",
       "       [  -0.,   -0.,  -20.,  -10.,   10.,   80.]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(conf_mtrx - rescaled_nofuss_conf_mtrx, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *physics*, *q-bio*, *q-fin*, and *stat* classes got inflated, wheras *cs* and *math* depleted. Curious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the best model in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave='mask',\n",
       "    pattern='(\\\\${1,2}[\\\\s\\\\w\\\\d\\\\\\\\,\\\\.=\\\\(\\\\)*{}/\\\\[\\\\]^;:\\'`<>|%&@\\\\\"!\\\\?~#+-]*?\\\\${1,2})',\n",
       "    repl=' _LATEX_ ')), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', ...enalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogReg_fit-to-55000.joblib']"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib / pickle\n",
    "dump(winner_clf, winner+f'_fit-to-{big_number}.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave='mask',\n",
       "    pattern='(\\\\${1,2}[\\\\s\\\\w\\\\d\\\\\\\\,\\\\.=\\\\(\\\\)*{}/\\\\[\\\\]^;:\\'`<>|%&@\\\\\"!\\\\?~#+-]*?\\\\${1,2})',\n",
       "    repl=' _LATEX_ ')), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', ...enalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_clf = load(winner+f'_fit-to-{big_number}.joblib')\n",
    "some_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_e.inverse_transform(some_clf.predict(random_abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
