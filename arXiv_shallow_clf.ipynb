{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from my_utilities import heatmap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer #, HashingVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "#from sklearn.linear_model import SGDlassifier(loss = ...)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* Build and test a simple preprocessing pipe that handles *LaTeX* formulas prepended to count-vectorization and TFIDF transformation.\n",
    "* Test a handful of shallow multiclass classifiers with *macro-F1* as the objective (in a noninteractive fashion)\n",
    "* Plot the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the two-column data frame (text + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"data\", \"bare_all.csv\")\n",
    "\n",
    "data = pd.read_csv(file, delimiter='\\t')\n",
    "\n",
    "# take 20k records to play with\n",
    "sample = data[:20000]\n",
    "\n",
    "text = sample.text\n",
    "label = sample.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stratified split\n",
    "#text_train, text_test, label_train, label_test = train_test_split(text, label, stratify=label, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No all records in memory: 837'000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power sum decompositions of defining equations of reflection arrangements.  We determine the Waring rank of the fund...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Spectroscopic Survey of Massive Stars in M31 and M33.  We describe our spectroscopic follow-up to the Local Group ...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hamiltonian Thermodynamics of Black Holes in Generic 2-D Dilaton Gravity.  We consider the Hamiltonian mechanics and...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      text  \\\n",
       "0  Power sum decompositions of defining equations of reflection arrangements.  We determine the Waring rank of the fund...   \n",
       "1  A Spectroscopic Survey of Massive Stars in M31 and M33.  We describe our spectroscopic follow-up to the Local Group ...   \n",
       "2  Hamiltonian Thermodynamics of Black Holes in Generic 2-D Dilaton Gravity.  We consider the Hamiltonian mechanics and...   \n",
       "\n",
       "  label  \n",
       "0  math  \n",
       "1  phys  \n",
       "2  phys  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"No all records in memory: {round(len(data)/1000)}'000\")\n",
    "with pd.option_context('display.max_colwidth', 120):\n",
    "    display(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts of scientific papers tend to be written in a formal style, to not contain typos, nor direct citations, little references, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effect of an ordered azimuthal magnetic field on a migrating planet in a non-turbulent disc.  In this work, we consider the physics of the interaction between a planet and a magnetized gaseous protoplanetary disc. We investigate the migration of a planet in a disc that is threaded with an azimuthal magnetic field. We find that, for a larger magnetic field amplitude, there is an increasingly large positive torque on the planet from the disc, resulting in slowed and even outward migration. Our results indicate that magnetic resonances due to a purely azimuthal, ordered magnetic field can slow or stop the inward migration of Jupiter-mass, Saturn-mass, and $5 M_{\\oplus}$ planets. \n",
      "---\n",
      "Hot Subdwarf Stars Among the Objects Rejected from the PG Catalog: a First Assessment Using GALEX Photometry.  The hot subdwarf (sd) stars in the Palomar Green (PG) catalog of ultraviolet excess (UVX) objects play a key role in investigations of the frequency and types of binary companions and the distribution of orbital periods. These are important for establishing whether and by which channels the sd stars arise from interactions in close binary systems. It has been suggested that the list of PG sd stars is biased by the exclusion of many stars in binaries, whose spectra show the Ca II K line in absorption. A total of 1125 objects that were photometrically selected as candidates were ultimately rejected from the final PG catalog using this K-line criterion. We study 88 of these \"PG-Rejects\" (PGRs), to assess whether there are significant numbers of unrecognized sd stars in binaries among the PGR objects. The presence of a sd should cause a large UVX. We assemble GALEX, Johnson V, and 2MASS photometry and compare the colors of these PGR objects with those of known sd stars, cool single stars, and hot+cool binaries. Sixteen PGRs were detected in both the far- and near- ultraviolet GALEX passbands. Eleven of these, plus the 72 cases with only an upper limit in the far-ultraviolet band, are interpreted as single cool stars. Of the remaining five stars, three are consistent with being sd stars paired with a cool main sequence companion, while two may be single stars or composite systems of another type. We discuss the implications of these findings for the 1125 PGR objects as a whole. (slightly abridged) \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(text.iloc[random.choice(range(len(text)))])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One messy but informative kind of writing they have are LaTeX formulas (*\\$...\\$*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distribution of the roots of the equations $Z(t)=0$, $Z\\'(t)=0$ in the theory of the Riemann zeta-function.  Let the symbols $\\\\{\\\\gamma\\\\},\\\\ \\\\{t_0\\\\};\\\\ t_0\\\\not=\\\\gamma$ denote the sequences of the roots of the equations $$Z(t)=0,\\\\quad \\\\text{and}\\\\qquad Z\\'(t)=0,$$ respectively, and $$m(t_0)=\\\\min\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad Q(t_0)=\\\\max\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad \\\\gamma\\'<t_0<\\\\gamma\",$$ where $\\\\gamma\\',\\\\gamma\"$ are the neighboring zeroes. We have proved the following in this paper: on the Riemann hypothesis we have $$\\\\frac{Q(t_0)}{m(t_0)}<t_0\\\\ln^2t_0\\\\ln_2t_0\\\\ln_3t_0,\\\\quad t_0\\\\to\\\\infty.$$ This paper is the English version of the paper of ref. \\\\cite{5}. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose to either mask them with * \\_latex\\_ * or flag them by appending * \\_latex\\_ * in front of each such expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask or flag LaTeX expression with a word ' _LATEX_ '\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DeLaTeX(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Replace r\"(\\${1,2}[...]*?\\${1,2})\" with ' _latex_ ' or 'latex \\1'\n",
    "    \"\"\"\n",
    "    # why does it differ from  r'(\\$.+?\\$)' ?\n",
    "    \n",
    "    def __init__(self, behave = 'flag'):\n",
    "        self.pattern = r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\"\n",
    "        if behave:\n",
    "            self.repl = ' _LATEX_ ' if behave == 'mask' else  r' _LATEX_ \\1'\n",
    "        else:\n",
    "            self.repl = r'\\1' # do nothing with extra steps\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.str.replace(self.pattern, self.repl)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distribution of the roots of the equations $Z(t)=0$, $Z\\'(t)=0$ in the theory of the Riemann zeta-function.  Let the symbols $\\\\{\\\\gamma\\\\},\\\\ \\\\{t_0\\\\};\\\\ t_0\\\\not=\\\\gamma$ denote the sequences of the roots of the equations $$Z(t)=0,\\\\quad \\\\text{and}\\\\qquad Z\\'(t)=0,$$ respectively, and $$m(t_0)=\\\\min\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad Q(t_0)=\\\\max\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad \\\\gamma\\'<t_0<\\\\gamma\",$$ where $\\\\gamma\\',\\\\gamma\"$ are the neighboring zeroes. We have proved the following in this paper: on the Riemann hypothesis we have $$\\\\frac{Q(t_0)}{m(t_0)}<t_0\\\\ln^2t_0\\\\ln_2t_0\\\\ln_3t_0,\\\\quad t_0\\\\to\\\\infty.$$ This paper is the English version of the paper of ref. \\\\cite{5}. '"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = None)\n",
    "delatex.transform(text[9:10])[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distribution of the roots of the equations  _LATEX_ ,  _LATEX_  in the theory of the Riemann zeta-function.  Let the symbols  _LATEX_  denote the sequences of the roots of the equations  _LATEX_  respectively, and  _LATEX_  where  _LATEX_  are the neighboring zeroes. We have proved the following in this paper: on the Riemann hypothesis we have  _LATEX_  This paper is the English version of the paper of ref. \\\\cite{5}. '"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'mask')\n",
    "delatex.transform(text[9:10])[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distribution of the roots of the equations  _LATEX_ $Z(t)=0$,  _LATEX_ $Z\\'(t)=0$ in the theory of the Riemann zeta-function.  Let the symbols  _LATEX_ $\\\\{\\\\gamma\\\\},\\\\ \\\\{t_0\\\\};\\\\ t_0\\\\not=\\\\gamma$ denote the sequences of the roots of the equations  _LATEX_ $$Z(t)=0,\\\\quad \\\\text{and}\\\\qquad Z\\'(t)=0,$$ respectively, and  _LATEX_ $$m(t_0)=\\\\min\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad Q(t_0)=\\\\max\\\\{\\\\gamma\"-t_0,t_0-\\\\gamma\\'\\\\},\\\\quad \\\\gamma\\'<t_0<\\\\gamma\",$$ where  _LATEX_ $\\\\gamma\\',\\\\gamma\"$ are the neighboring zeroes. We have proved the following in this paper: on the Riemann hypothesis we have  _LATEX_ $$\\\\frac{Q(t_0)}{m(t_0)}<t_0\\\\ln^2t_0\\\\ln_2t_0\\\\ln_3t_0,\\\\quad t_0\\\\to\\\\infty.$$ This paper is the English version of the paper of ref. \\\\cite{5}. '"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "delatex.transform(text[9:10])[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs', 'math', 'phys', 'q-bio', 'q-fin', 'stat']\n"
     ]
    }
   ],
   "source": [
    "# 'cs' -> 0, ..., 'stat' -> 5\n",
    "\n",
    "label_e = LabelEncoder()\n",
    "y_train = label_e.fit_transform(label)\n",
    "\n",
    "print(list(label_e.classes_))\n",
    "\n",
    "#label_e.inverse_transform([0]) # array(['cs'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optionally, have a look at the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "count_v = CountVectorizer(strip_accents='unicode')\n",
    "word_counts_train = count_v.fit_transform(delatex.fit_transform(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(213000, 'the'),\n",
       " (135000, 'of'),\n",
       " (75000, 'and'),\n",
       " (67000, 'in'),\n",
       " (56000, 'to'),\n",
       " (43000, 'we'),\n",
       " (40000, 'is'),\n",
       " (36000, 'for'),\n",
       " (36000, '_latex_'),\n",
       " (29000, 'that')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_word_counts_train = word_counts_train.sum(axis=0)\n",
    "sorted([(round(sum_word_counts_train[0, i],-3), word) for word, i in count_v.vocabulary_.items()],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go step by step through an arbitrary pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX()\n",
    "tex_text_train = delatex.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(use_idf=True, min_df = 2, max_df=0.8, strip_accents='unicode')\n",
    "tfidf_scores_train = tfidf_v.fit_transform(tex_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1, class_weight='balanced')\n",
    "lsvc.fit(tfidf_scores_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's just have some fun first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_abstracts = pd.Series([\"\"\"\n",
    "The Lack of A Priori Distinctions Between Learning Algorithms. This is the first of\n",
    "two papers that use off-training set (OTS) error to investigate the assumption-free\n",
    "relationship between learning algorithms. This first paper discusses the senses in\n",
    "which there are no a priori distinctions between learning algorithms. (The second\n",
    "paper discusses the senses in which there are such distinctions.) In this first paper\n",
    "it is shown, loosely speaking, that for any two algorithms A and B, there are \"as many\"\n",
    "targets (or priors over targets) for which A has lower expected OTS error than B as\n",
    "vice versa, for loss functions like zero-one loss. In particular, this is true if A\n",
    "is cross-validation and B is \"anti-cross-validation'' (choose the learning algorithm\n",
    "with largest cross-validation error). This paper ends with a discussion of the\n",
    "implications of these results for computational learning theory. It is shown that one\n",
    "cannot say: if empirical misclassification rate is low, the Vapnik-Chervonenkis\n",
    "dimension of your generalizer is small, and the training set is large, then with high\n",
    "probability your OTS error is small. Other implications for \"membership queries\"\n",
    "algorithms and \"punting\" algorithms are also discussed.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "X-rays quarks lepton scattering experiment field\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "genes DNA RNA sequencing protein species fenotype \n",
    "\"\"\",\n",
    "\"\"\"\n",
    "computer algorithm graph sorting depth first interface\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "novel intuitive proof of $\\limit_{x\\to 0} x = 0$ convergence fomula,\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "inflation resources market stock bonds derivatives\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "distribution Bayesian p value marginalization Monte Carlo\n",
    "\"\"\"\n",
    "])\n",
    "\n",
    "label_e.inverse_transform(lsvc.predict(tfidf_v.transform(delatex.transform(random_abstracts ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks promising :)\n",
    "Here's the actual score on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = data[20000:40000].text\n",
    "y_test = label_e.transform(data[20000:40000].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = lsvc.predict(tfidf_v.transform(delatex.transform(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.7495900889782615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.82      0.86      0.84      2656\n",
      "        math       0.86      0.89      0.87      4465\n",
      "        phys       0.97      0.95      0.96     12194\n",
      "       q-bio       0.59      0.52      0.55       231\n",
      "       q-fin       0.81      0.70      0.75       110\n",
      "        stat       0.54      0.51      0.52       344\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     20000\n",
      "   macro avg       0.76      0.74      0.75     20000\n",
      "weighted avg       0.91      0.91      0.91     20000\n",
      "\n",
      "[[ 2292   234    64    14     6    46]\n",
      " [  208  3955   220    11     7    64]\n",
      " [  167   342 11612    48     3    22]\n",
      " [   35    16    47   119     0    14]\n",
      " [    8    14     8     0    77     3]\n",
      " [   90    53    14    10     2   175]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro F1:\", f1_score(y_test, predicted_y_test, average=\"macro\"))\n",
    "print(classification_report(y_test, predicted_y_test, target_names=label_e.classes_))\n",
    "print(confusion_matrix(y_test, predicted_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"By definition a confusion matrix $C$ is such that $C_{ij}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\" https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained on 20k records with an untuned Linear SVM, we have reached 0.75 macro-F1 (out of sample) pulled down by poor performomance on classification wrt rarer classes. E.g. many *cs* and *math* are confused with *stat* (and vice versa), and similarly for *q-bio* and *physics*. This is actually sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search with CV by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = []\n",
    "pipe.append(( 'delatex', DeLaTeX(behave='mask') ))\n",
    "pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=False, strip_accents='unicode', min_df = 2, max_df = 0.8)  ))\n",
    "pipe.append(( 'LinearSVC', LinearSVC(C=1, penalty='l2', class_weight='balanced')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delatex__behave': ['mask', None],\n",
       " 'tfidf_v__ngram_range': [(1, 1), (1, 2)],\n",
       " 'tfidf_v__use_idf': [False, True],\n",
       " 'tfidf_v__max_df': [0.7, 0.9],\n",
       " 'LinearSVC__C': [0.1, 1]}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'delatex__behave': ['mask', None],\n",
    "    'tfidf_v__ngram_range': [(1, 1),(1,2)],\n",
    "    'tfidf_v__use_idf': [False, True],\n",
    "    'tfidf_v__max_df': [0.7, 0.9],\n",
    "}\n",
    "params['LinearSVC' + '__' + 'C'] = [0.1, 1]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave=None)), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2'...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=False, n_jobs=1,\n",
       "       param_grid={'delatex__behave': ['mask', None], 'tfidf_v__ngram_range': [(1, 1), (1, 2)], 'tfidf_v__use_idf': [False, True], 'tfidf_v__max_df': [0.7, 0.9], 'LinearSVC__C': [0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LONG WAIT\n",
    "\n",
    "# there's some bug with njobs different than 1 because of the delatex in the pipe\n",
    "\n",
    "scoring = 'f1_macro'\n",
    "grid_s = GridSearchCV(Pipeline(pipe), params, cv=5, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False)\n",
    "grid_s.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC__C': 0.1,\n",
       " 'delatex__behave': 'mask',\n",
       " 'tfidf_v__max_df': 0.7,\n",
       " 'tfidf_v__ngram_range': (1, 1),\n",
       " 'tfidf_v__use_idf': True}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__ngram_range</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>param_LinearSVC__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.762059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.762059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.760856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.760856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.748585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.748585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.746615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.746615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.734054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.734054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mask</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.732154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.732154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave param_tfidf_v__ngram_range param_tfidf_v__use_idf  \\\n",
       "17                  mask                     (1, 1)                   True   \n",
       "25                  None                     (1, 1)                   True   \n",
       "21                  mask                     (1, 1)                   True   \n",
       "29                  None                     (1, 1)                   True   \n",
       "20                  mask                     (1, 1)                  False   \n",
       "28                  None                     (1, 1)                  False   \n",
       "16                  mask                     (1, 1)                  False   \n",
       "24                  None                     (1, 1)                  False   \n",
       "19                  mask                     (1, 2)                   True   \n",
       "27                  None                     (1, 2)                   True   \n",
       "23                  mask                     (1, 2)                   True   \n",
       "31                  None                     (1, 2)                   True   \n",
       "22                  mask                     (1, 2)                  False   \n",
       "30                  None                     (1, 2)                  False   \n",
       "18                  mask                     (1, 2)                  False   \n",
       "26                  None                     (1, 2)                  False   \n",
       "1                   mask                     (1, 1)                   True   \n",
       "9                   None                     (1, 1)                   True   \n",
       "5                   mask                     (1, 1)                   True   \n",
       "13                  None                     (1, 1)                   True   \n",
       "7                   mask                     (1, 2)                   True   \n",
       "15                  None                     (1, 2)                   True   \n",
       "3                   mask                     (1, 2)                   True   \n",
       "11                  None                     (1, 2)                   True   \n",
       "0                   mask                     (1, 1)                  False   \n",
       "8                   None                     (1, 1)                  False   \n",
       "4                   mask                     (1, 1)                  False   \n",
       "12                  None                     (1, 1)                  False   \n",
       "6                   mask                     (1, 2)                  False   \n",
       "14                  None                     (1, 2)                  False   \n",
       "2                   mask                     (1, 2)                  False   \n",
       "10                  None                     (1, 2)                  False   \n",
       "\n",
       "   param_tfidf_v__max_df param_LinearSVC__C  mean_test_score  \n",
       "17                   0.7                  1         0.753318  \n",
       "25                   0.7                  1         0.753318  \n",
       "21                   0.9                  1         0.751887  \n",
       "29                   0.9                  1         0.751887  \n",
       "20                   0.9                  1         0.744601  \n",
       "28                   0.9                  1         0.744601  \n",
       "16                   0.7                  1         0.737964  \n",
       "24                   0.7                  1         0.737964  \n",
       "19                   0.7                  1         0.736053  \n",
       "27                   0.7                  1         0.736053  \n",
       "23                   0.9                  1         0.734947  \n",
       "31                   0.9                  1         0.734947  \n",
       "22                   0.9                  1         0.723301  \n",
       "30                   0.9                  1         0.723301  \n",
       "18                   0.7                  1         0.722968  \n",
       "26                   0.7                  1         0.722968  \n",
       "1                    0.7                0.1         0.762059  \n",
       "9                    0.7                0.1         0.762059  \n",
       "5                    0.9                0.1         0.760856  \n",
       "13                   0.9                0.1         0.760856  \n",
       "7                    0.9                0.1         0.748585  \n",
       "15                   0.9                0.1         0.748585  \n",
       "3                    0.7                0.1         0.746615  \n",
       "11                   0.7                0.1         0.746615  \n",
       "0                    0.7                0.1         0.744710  \n",
       "8                    0.7                0.1         0.744710  \n",
       "4                    0.9                0.1         0.744347  \n",
       "12                   0.9                0.1         0.744347  \n",
       "6                    0.9                0.1         0.734054  \n",
       "14                   0.9                0.1         0.734054  \n",
       "2                    0.7                0.1         0.732154  \n",
       "10                   0.7                0.1         0.732154  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_s.cv_results_)\n",
    "cols = ['param_' + param for param in params.keys()] + ['mean_test_score']\n",
    "\n",
    "results[cols].sort_values(by=['param_LinearSVC__C','mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regards to our preprocessing steps:\n",
    "    * our DeLaTeX does not help at all\n",
    "    * it is better to use IDF\n",
    "    * max_df=0.7 is slightly better than 0.9\n",
    "    * using 1-grams alone in the count-vectorizer proved to be no visibly better than adding *2grams*\n",
    "   \n",
    "### We will stick to those settings in tuning the classifiers' hyperparameters below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated GridSearchCV for multiple classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(name, model):\n",
    "    pipe = []\n",
    "    #pipe.append(( 'delatex', DeLaTeX(behave='flag') ))\n",
    "    pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=True, strip_accents='unicode', min_df = 2, max_df = 0.7)  ))\n",
    "    pipe.append(( name, model  ))\n",
    "    \n",
    "    return Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe_params(name, model_params):\n",
    "    params = {\n",
    "        #'delatex__behave': [None],\n",
    "        'tfidf_v__ngram_range': [(1, 1)],\n",
    "        'tfidf_v__use_idf': [True],\n",
    "        'tfidf_v__max_df': [0.7],\n",
    "    }\n",
    "    for (param_name, range_) in model_params:\n",
    "        params[name + '__' + param_name] = range_\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify models with grid of parametrs for GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearSVC': [LinearSVC(class_weight='balanced'),\n",
    "                  [( 'C', [1] )]\n",
    "                 ],\n",
    "    'LogisticR': [LogisticRegression(class_weight='balanced', solver='lbfgs', multi_class='ovr'),\n",
    "                  [( 'C', [1] )]\n",
    "                 ],\n",
    "    'RandomFC': [RandomForestClassifier(class_weight='balanced', n_estimators=100, ),\n",
    "                 [('max_depth', [20]) , ('min_samples_leaf', [10])]\n",
    "                ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "0.7533176359424341 \n",
      "\n",
      "LogisticR\n",
      "0.7461565618083735 \n",
      "\n",
      "RandomFC\n",
      "0.6557099809492183 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GRID-SEARCH\n",
    "\n",
    "# collect the best_params for the models\n",
    "results = {}\n",
    "\n",
    "for name, (model, model_params) in models.items():\n",
    "    \n",
    "    print(name)\n",
    "    pipe = build_clf(name, model)\n",
    "    params = build_pipe_params(name, model_params)\n",
    "    \n",
    "    grid_s = GridSearchCV(pipe, params, cv=5, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False)\n",
    "    grid_s.fit(text_train, y_train)\n",
    "    \n",
    "    print(grid_s.best_score_, \"\\n\")\n",
    "    results[name] = [grid_s.best_params_, grid_s.best_score_, grid_s.cv_results_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC {'LinearSVC__C': 1, 'tfidf_v__max_df': 0.7, 'tfidf_v__ngram_range': (1, 1), 'tfidf_v__use_idf': True}\n",
      "LogisticR {'LogisticR__C': 1, 'tfidf_v__max_df': 0.7, 'tfidf_v__ngram_range': (1, 1), 'tfidf_v__use_idf': True}\n",
      "RandomFC {'RandomFC__max_depth': 20, 'RandomFC__min_samples_leaf': 10, 'tfidf_v__max_df': 0.7, 'tfidf_v__ngram_range': (1, 1), 'tfidf_v__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "# store the best_params in the models dict\n",
    "\n",
    "for name, result in results.items():\n",
    "    \n",
    "    best_params = result[0]\n",
    "    \n",
    "    print(name, best_params)\n",
    "    models[name][1] = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the whole train data to the tuned classifiers. Record final scores on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_vol = int(len(data)/5)\n",
    "\n",
    "#final_train = data[:test_vol]\n",
    "#final_test = data[test_vol:]\n",
    "\n",
    "final_train = data[:5000]\n",
    "final_test = data[5000:10000]\n",
    "\n",
    "\n",
    "final_text_train = final_train.text\n",
    "final_y_train = label_e.transform(final_train.label)\n",
    "\n",
    "final_text_test = final_test.text\n",
    "final_y_test = label_e.transform(final_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models['LinearSVC'][0]\n",
    "# clf = build_clf('LinearSVC', models['LinearSVC'][0])\n",
    "# clf.set_params(**models['LinearSVC'][2])\n",
    "# clf.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = {}\n",
    "\n",
    "for name, (model, pipe_best_params) in models.items():\n",
    "    \n",
    "    clf = build_clf(name, model)\n",
    "    clf.set_params(**pipe_best_params)\n",
    "    clf.fit(final_text_train, final_y_train)\n",
    "    \n",
    "    final_scores[name] = f1_score(final_y_test, clf.predict(final_text_test), average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC': 0.6894057859800524,\n",
       " 'LogisticR': 0.6845400115750883,\n",
       " 'RandomFC': 0.5485700329238364}"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEqtJREFUeJzt3X+Q3Hd93/HnKxJqQqChqa8pWJKlEjmt+FEbDpFMaRMS6MjDVGoGmkh1mpgQVBqEk7owiIZxqTppHZyUCY2YICgpZbCF4+nQI6gVTQKlSW3QGYSNZEQOGfCNZuDiYCcUx0b43T/2e3g5r3TfO+1Zvo+ej5kb7efz/ex337d7+9rPfna/X6WqkCS15bsudAGSpPEz3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNWnuhbviSSy6pTZs2Xaibl6RV6Y477vjTqppYbNwFC/dNmzYxPT19oW5eklalJF/qM85lGUlqkOEuSQ3qFe5Jtic5mWQmyb4R29+W5Fj38/kk94+/VElSX4uuuSdZAxwAXgrMAkeTTFXVifkxVfUvh8a/DrhyBWqVJPXUZ+a+DZipqlNV9TBwCNh5jvG7gZvHUZwkaXn6hPulwL1D7dmu7zGSXAZsBv7w/EuTJC1Xn3DPiL6z/fdNu4Bbq+pbI3eU7EkynWR6bm6ub42SpCXqE+6zwIah9nrg9FnG7uIcSzJVdbCqJqtqcmJi0e/gS5KWqU+4HwW2JNmcZB2DAJ9aOCjJDwF/DbhtvCVKkpZq0W/LVNWZJHuBI8Aa4D1VdTzJfmC6quaDfjdwqB6H/3F7074Pr/RNXLS+eMPLLnQJksag1+kHquowcHhB3/UL2m8ZX1lqjS/IK8cXZI3iEaqS1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDeoV7km2JzmZZCbJvrOM+akkJ5IcT3LTeMuUJC3F2sUGJFkDHABeCswCR5NMVdWJoTFbgDcBf6+qvpbkb6xUwZKkxfWZuW8DZqrqVFU9DBwCdi4Y82rgQFV9DaCqvjreMiVJS9En3C8F7h1qz3Z9wy4HLk/yx0luT7J9XAVKkpZu0WUZICP6asR+tgA/BqwH/k+SZ1fV/d+xo2QPsAdg48aNSy5WktRPn5n7LLBhqL0eOD1izH+vqm9W1T3ASQZh/x2q6mBVTVbV5MTExHJrliQtok+4HwW2JNmcZB2wC5haMOaDwIsBklzCYJnm1DgLlST1t2i4V9UZYC9wBLgbuKWqjifZn2RHN+wIcF+SE8BHgTdU1X0rVbQk6dz6rLlTVYeBwwv6rh+6XMB13Y8k6QLzCFVJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDep1+gFJF59N+z58oUto1hdveNmK34Yzd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkN6hXuSbYnOZlkJsm+EduvSTKX5Fj38wvjL1WS1Nei55ZJsgY4ALwUmAWOJpmqqhMLhn6gqvauQI2SpCXqM3PfBsxU1amqehg4BOxc2bIkSeejT7hfCtw71J7t+hZ6eZI7k9yaZMNYqpMkLUufcM+IvlrQ/hCwqaqeC/w+8N6RO0r2JJlOMj03N7e0SiVJvfUJ91lgeCa+Hjg9PKCq7quqh7rmu4Dnj9pRVR2sqsmqmpyYmFhOvZKkHvqE+1FgS5LNSdYBu4Cp4QFJnj7U3AHcPb4SJUlLtei3ZarqTJK9wBFgDfCeqjqeZD8wXVVTwLVJdgBngD8DrlnBmiVJi+j13+xV1WHg8IK+64cuvwl403hLkyQtl0eoSlKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDWoV7gn2Z7kZJKZJPvOMe4VSSrJ5PhKlCQt1aLhnmQNcAC4CtgK7E6ydcS4pwLXAp8Yd5GSpKXpM3PfBsxU1amqehg4BOwcMe7fAW8F/nKM9UmSlqFPuF8K3DvUnu36vi3JlcCGqvq9MdYmSVqmPuGeEX317Y3JdwFvA/7VojtK9iSZTjI9NzfXv0pJ0pL0CfdZYMNQez1weqj9VODZwMeSfBH4YWBq1IeqVXWwqiaranJiYmL5VUuSzqlPuB8FtiTZnGQdsAuYmt9YVQ9U1SVVtamqNgG3AzuqanpFKpYkLWrRcK+qM8Be4AhwN3BLVR1Psj/JjpUuUJK0dGv7DKqqw8DhBX3Xn2Xsj51/WZKk8+ERqpLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkN6hXuSbYnOZlkJsm+Edtfk+SuJMeS/FGSreMvVZLU16LhnmQNcAC4CtgK7B4R3jdV1XOq6grgrcB/HHulkqTe+szctwEzVXWqqh4GDgE7hwdU1Z8PNb8XqPGVKElaqrU9xlwK3DvUngVeuHBQktcC1wHrgB8fS3WSpGXpM3PPiL7HzMyr6kBVPRN4I/DmkTtK9iSZTjI9Nze3tEolSb31CfdZYMNQez1w+hzjDwH/eNSGqjpYVZNVNTkxMdG/SknSkvQJ96PAliSbk6wDdgFTwwOSbBlqvgz4k/GVKElaqkXX3KvqTJK9wBFgDfCeqjqeZD8wXVVTwN4kLwG+CXwN+LmVLFqSdG59PlClqg4Dhxf0XT90+ZfGXJck6Tx4hKokNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg3qFe5LtSU4mmUmyb8T265KcSHJnkj9Ictn4S5Uk9bVouCdZAxwArgK2AruTbF0w7NPAZFU9F7gVeOu4C5Uk9ddn5r4NmKmqU1X1MHAI2Dk8oKo+WlXf6Jq3A+vHW6YkaSn6hPulwL1D7dmu72xeBfyP8ylKknR+1vYYkxF9NXJg8jPAJPCjZ9m+B9gDsHHjxp4lSpKWqs/MfRbYMNReD5xeOCjJS4BfAXZU1UOjdlRVB6tqsqomJyYmllOvJKmHPuF+FNiSZHOSdcAuYGp4QJIrgXcyCPavjr9MSdJSLBruVXUG2AscAe4Gbqmq40n2J9nRDbsReArwu0mOJZk6y+4kSY+DPmvuVNVh4PCCvuuHLr9kzHVJks6DR6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNahXuCfZnuRkkpkk+0Zs/wdJPpXkTJJXjL9MSdJSLBruSdYAB4CrgK3A7iRbFwz7MnANcNO4C5QkLd3aHmO2ATNVdQogySFgJ3BifkBVfbHb9sgK1ChJWqI+yzKXAvcOtWe7PknSE1SfcM+IvlrOjSXZk2Q6yfTc3NxydiFJ6qFPuM8CG4ba64HTy7mxqjpYVZNVNTkxMbGcXUiSeugT7keBLUk2J1kH7AKmVrYsSdL5WDTcq+oMsBc4AtwN3FJVx5PsT7IDIMkLkswC/wR4Z5LjK1m0JOnc+nxbhqo6DBxe0Hf90OWjDJZrJElPAB6hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgXuGeZHuSk0lmkuwbsf2vJPlAt/0TSTaNu1BJUn+LhnuSNcAB4CpgK7A7ydYFw14FfK2qfhB4G/Br4y5UktRfn5n7NmCmqk5V1cPAIWDngjE7gfd2l28FfiJJxlemJGkp+oT7pcC9Q+3Zrm/kmKo6AzwA/PVxFChJWrq1PcaMmoHXMsaQZA+wp2t+PcnJHrffgkuAP73QRfQRF9RgFT1e4GPWuZges8v6DOoT7rPAhqH2euD0WcbMJlkLfB/wZwt3VFUHgYN9CmtJkumqmrzQdagfH6/Vx8fssfosyxwFtiTZnGQdsAuYWjBmCvi57vIrgD+sqsfM3CVJj49FZ+5VdSbJXuAIsAZ4T1UdT7IfmK6qKeA/A+9LMsNgxr5rJYuWJJ1bnGCvvCR7uiUprQI+XquPj9ljGe6S1CBPPyBJDbrowz3J10f0vSbJzz4Ot/3zSe5KcmeSzybZmeSaJDcvGHdJkrnuNA9PSnJDkj/prvPJJFetdK1PVKMev2Xs4xlJbj3H9qcl+cW+47sxH+tO2fGZJEeTXHG+da5GSb6V5Fj3t/qhJE8b0343JfnsmPb1X5Lc09V5LMm1Xf9TkrwzyReSHE/y8SQvHMdtPh76fBXyolNVv72S+++O3t0A/ArwvKp6IMlTgAngPuDXkzy5qr7RXeUVwFRVPZTkBuDpwLO79g8AP7qS9bauqk4zuI/P5mnALwLv6Dl+3tVVNZ3klcCNwEvPt9ZV6MGqugIgyXuB1wK/emFLGukNVbXwBfvdwD3Alqp6JMnfAv7O41/a8lz0M/dRkrwlyeu7yx9L8mvdDPnzSf5+178myY3drOzOJP+8639Kkj9I8qluVr6z69+U5O4k7wA+BWwG/gL4OkBVfb2q7qmqPwc+DvyjoZJ2ATcneTLwauB1VfVQd72vVNUtj8f9slokuax7DO7s/t3Y9T8zye3dY7Z/ftY/PAtM8qzusT7WXX8LcAPwzK7vxgXj1yT59aF3YK8bUdJtPPao7ovRt++HHs+Td3Wz5Y8k+Z5u2/O7d0K3MXiRoOv/7iS/0+3n00le3PVfk+SD3TuGe5LsTXJdN+b2JN9/tkKTPBN4IfDmqnoEoDsFy4dX6s4ZN8O9n7VVtQ34ZeDfdH2vAh6oqhcALwBenWQz8JfAT1bV84AXA7/RzdQBfgj4r1V1JfBHwFeAe7o/zOEwv5nu66RJngFcDnwU+EHgy90LgM7utxjcz88F3g+8vev/TeA3u8ds4YF4817TjbkCmGRwgN4+4AtVdUVVvWHB+D0MXqivHLq9hbYDHzyfX2i1y+AEhD/Bo8fInOt5sgU4UFXPAu4HXt71/w5wbVX9yILdvxagqp4D7Abem+S7u23PBv4pg3Nk/Srwje75dxswvPR649CyzHOAZwHHqupbY/j1LwjDvZ//1v17B7Cpu/wPgZ9Ncgz4BINz6WxhcCqGf5/kTuD3GcxUfqC7zpeq6naA7o9mO4O3958H3pbkLd243wNelOSvAj8F3Lqa/8gugB8Bbuouvw940VD/73aXb1p4pc5twL9O8kbgsqp6cJHbegnw2905laiq4SOz359kFngj8J+W9is043u658h9wPcD/6vrP9fz5J6qOtZdvgPYlOT7gKdV1f/u+t83dBsvmm9X1eeALzGYEAF8tKr+oqrmGJzz6kNd/108+lyGwbLMFd3PXef7Sz8RGO79PNT9+y0e/ZwiDJZH5v8gNlfVR4CrGaydP7+b/X0FmJ9F/L/hndbAJ6vqPzCYqb+8638Q+J/AT3b98x+wzgAbkzx1JX7JhvX+vm9V3QTsAB4EjiT58UWuknPs/2oGs/qbGJw2+2I0v+Z+GbCOR5dTzvU8eWjo+vPPuXPdz+c6A+3wvh4Zaj/CuT9zPA783SSrNiNXbeFPAEeAf5HkSQBJLk/yvQzOq/PVqvpmt/Y38iQ/GXzj4nlDXVcwmHHMuxm4jsFsZn62/w0GRwO/PYNTQZDk6Ul+Zry/2qr3f3n0KOmrGSyBweB+nH+LP/Io6u5Ds1NV9XYGSwjPZfDZyNleUD8CvCaDcyqxcB23qr4JvBn44SSr5sO4cauqB4Brgdd3z5lez5Oh698PPJBk/l3Y1UObPz7fTnI5sBE4r5MSVtUXgGng384vFyXZMv/ZwGpguMOTk8wO/VzX83rvBk4An+o+XHsng5nA+4HJJNMM/uA+d5brP4nBt2I+171t/Wngl4a2fwR4BvCBBefpeTMwB5zobveDXftiNerxuxZ4ZfeW/5/x6P36y8B1ST7J4BtHD4zY308Dn+0ek7/NYO3+PuCPM/g6340Lxr8b+DJwZ5LPMFjf/Q7dO7HfAF5/3r/tKlZVnwY+w+CFte/zZNgrgQPdB6rDy2XvANYkuQv4AHDN/BcOztMvAH8TmOn2/S7O/lnNE45HqOqi0X3b6MGqqiS7gN1VtWpmYtJS+D13XUyeD/xW9zb7fuDnL3A90opx5i5JDXLNXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXo/wNysiWSDjQMzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count = range(len(final_scores))\n",
    "plt.bar(count, list(final_scores.values()))\n",
    "plt.xticks(count, list(final_scores.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
