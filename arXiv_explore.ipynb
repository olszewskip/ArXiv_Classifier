{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using arXivMeta_all_from_2010-01-01_to_2010-07-01.csv\n",
      "using arXivMeta_all_from_2010-07-02_to_2010-12-31.csv\n"
     ]
    }
   ],
   "source": [
    "dir_ = os.path.join(\"data\", \"arXivMeta_sample\")\n",
    "\n",
    "file_list = []\n",
    "for file in os.listdir(dir_):\n",
    "    file_path = os.path.join(dir_, file)\n",
    "    file_list.append(file_path)\n",
    "    print(f\"using {file}\")\n",
    "    \n",
    "all_data = pd.concat([pd.read_csv(file, delimiter='\\t', na_values='nan') for file in file_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            6\n",
       "authors       0\n",
       "title         6\n",
       "abstract      6\n",
       "categories    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the NaNs\n",
    "all_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows with NaNs:  6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22299</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23584</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id authors title abstract categories\n",
       "22299  NaN      []   NaN      NaN        NaN\n",
       "22300  NaN      []   NaN      NaN        NaN\n",
       "23584  NaN      []   NaN      NaN        NaN"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the NaNs\n",
    "rows_with_nulls = all_data.isnull().any(axis=1)\n",
    "print(\"No. of rows with NaNs: \", sum(rows_with_nulls))\n",
    "all_data[rows_with_nulls][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the NaNs are aligned in empty rows.\n",
    "# We can just drop them.\n",
    "all_data = all_data.dropna(axis=0, how='any', inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove suspiciously short abstracts\n",
    "There are articles where the abstarct serves as a comment rather than a summary, e.g. \"Discussion on SOME_REFERENCE.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment on \"Harold Jeffreys's Theory of Probability Revisited\"\n",
      "[arXiv:0804.3173]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = all_data[all_data.id == '1001.2975'].abstract.values[0].strip()\n",
    "print(example)\n",
    "len(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just decide that abstracts shorter than 120 characters are not informative (or worse) and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.loc[all_data.abstract.str.len() > 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for repeated entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. repeated entries:\n",
      "         id 0\n",
      "    authors 8805\n",
      "      title 62\n",
      "   abstract 90\n",
      " categories 51466\n"
     ]
    }
   ],
   "source": [
    "# count repeated entries\n",
    "\n",
    "print(\"No. repeated entries:\")\n",
    "for column in all_data:\n",
    "    print( f\"{column:>11}\", len(all_data) - len(all_data[column].unique()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0709.0595</td>\n",
       "      <td>['Shao-Hsuan Chiu']</td>\n",
       "      <td>Observables in multi-detector analyses of supe...</td>\n",
       "      <td>This paper has been withdrawn by the author,...</td>\n",
       "      <td>hep-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0805.0198</td>\n",
       "      <td>['Alexander N. Jourjine']</td>\n",
       "      <td>Minimal gauging of Dirac, Kahler, and Dirac-Ka...</td>\n",
       "      <td>This paper has been withdrawn by the author.\\n</td>\n",
       "      <td>math-ph math.MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>0902.2788</td>\n",
       "      <td>['Ali Pourmohammad', 'Seyed Mohammad Ahadi']</td>\n",
       "      <td>Using SLP Neural Network to Persian Handwritte...</td>\n",
       "      <td>This paper has been withdrawn by the author ...</td>\n",
       "      <td>cs.CV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                       authors  \\\n",
       "234   0709.0595                           ['Shao-Hsuan Chiu']   \n",
       "747   0805.0198                     ['Alexander N. Jourjine']   \n",
       "2059  0902.2788  ['Ali Pourmohammad', 'Seyed Mohammad Ahadi']   \n",
       "\n",
       "                                                  title  \\\n",
       "234   Observables in multi-detector analyses of supe...   \n",
       "747   Minimal gauging of Dirac, Kahler, and Dirac-Ka...   \n",
       "2059  Using SLP Neural Network to Persian Handwritte...   \n",
       "\n",
       "                                               abstract       categories  \n",
       "234     This paper has been withdrawn by the author,...           hep-ph  \n",
       "747      This paper has been withdrawn by the author.\\n  math-ph math.MP  \n",
       "2059    This paper has been withdrawn by the author ...            cs.CV  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the duplicated abstracts\n",
    "duplicated_abstracts = all_data[nonan_all_data.duplicated(subset='abstract')]\n",
    "print(len(duplicated_abstracts))\n",
    "duplicated_abstracts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# among the duplicated abstracts many are just \"This paper has been withdrawn ...\"\n",
    "withdrawn = duplicated_abstracts[duplicated_abstracts.abstract.str.contains(\"^\\s+This paper has been withdrawn\")]\n",
    "print(len(withdrawn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6136</th>\n",
       "      <td>1001.1922</td>\n",
       "      <td>['Frédéric Planchet', 'Laurent Faucillon', 'Ma...</td>\n",
       "      <td>Etude du risque syst\\'ematique de mortalit\\'e</td>\n",
       "      <td>The aim of this paper is to propose a realis...</td>\n",
       "      <td>q-fin.GN q-fin.RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>1001.2058</td>\n",
       "      <td>['S A Sisson', 'Y Fan']</td>\n",
       "      <td>Likelihood-free Markov chain Monte Carlo</td>\n",
       "      <td>To appear to MCMC handbook, S. P. Brooks, A....</td>\n",
       "      <td>stat.ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>1001.2975</td>\n",
       "      <td>['Stephen Senn']</td>\n",
       "      <td>Comment on \"Harold Jeffreys's Theory of Probab...</td>\n",
       "      <td>Comment on \"Harold Jeffreys's Theory of Prob...</td>\n",
       "      <td>stat.ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>1001.2985</td>\n",
       "      <td>['Arnold Zellner']</td>\n",
       "      <td>Comment on \"Harold Jeffreys's Theory of Probab...</td>\n",
       "      <td>Comment on \"Harold Jeffreys's Theory of Prob...</td>\n",
       "      <td>stat.ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6576</th>\n",
       "      <td>1001.3073</td>\n",
       "      <td>['Dennis Lindley']</td>\n",
       "      <td>Comment on \"Harold Jeffreys's Theory of Probab...</td>\n",
       "      <td>Comment on \"Harold Jeffreys's Theory of Prob...</td>\n",
       "      <td>stat.ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>1001.5100</td>\n",
       "      <td>['Xiwang Cao', 'Lei Hu']</td>\n",
       "      <td>On Exponential Sums, Nowton identities and Dic...</td>\n",
       "      <td>Let $\\mathbb{F}_{q}$ be a finite field, $\\ma...</td>\n",
       "      <td>cs.IT math.IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8475</th>\n",
       "      <td>1002.3222</td>\n",
       "      <td>['Jeroen Keiren', 'Michel A. Reniers', 'Tim A....</td>\n",
       "      <td>Structural Analysis of Boolean Equation Systems</td>\n",
       "      <td>We analyse the problem of solving Boolean eq...</td>\n",
       "      <td>cs.LO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8873</th>\n",
       "      <td>1002.4496</td>\n",
       "      <td>['Robert Serfling', 'Yijun Zuo']</td>\n",
       "      <td>Discussion of \"Multivariate quantiles and mult...</td>\n",
       "      <td>Discussion of \"Multivariate quantiles and mu...</td>\n",
       "      <td>math.ST stat.TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>1002.4509</td>\n",
       "      <td>['Linglong Kong', 'Ivan Mizera']</td>\n",
       "      <td>Discussion of \"Multivariate quantiles and mult...</td>\n",
       "      <td>Discussion of \"Multivariate quantiles and mu...</td>\n",
       "      <td>math.ST stat.TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10719</th>\n",
       "      <td>1003.5865</td>\n",
       "      <td>['Dakshina Ranjan Kisku', 'Phalguni Gupta', 'J...</td>\n",
       "      <td>Offline Signature Identification by Fusion of ...</td>\n",
       "      <td>This paper uses Support Vector Machines (SVM...</td>\n",
       "      <td>cs.CV cs.LG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            authors  \\\n",
       "6136   1001.1922  ['Frédéric Planchet', 'Laurent Faucillon', 'Ma...   \n",
       "6192   1001.2058                            ['S A Sisson', 'Y Fan']   \n",
       "6538   1001.2975                                   ['Stephen Senn']   \n",
       "6544   1001.2985                                 ['Arnold Zellner']   \n",
       "6576   1001.3073                                 ['Dennis Lindley']   \n",
       "7297   1001.5100                           ['Xiwang Cao', 'Lei Hu']   \n",
       "8475   1002.3222  ['Jeroen Keiren', 'Michel A. Reniers', 'Tim A....   \n",
       "8873   1002.4496                   ['Robert Serfling', 'Yijun Zuo']   \n",
       "8879   1002.4509                   ['Linglong Kong', 'Ivan Mizera']   \n",
       "10719  1003.5865  ['Dakshina Ranjan Kisku', 'Phalguni Gupta', 'J...   \n",
       "\n",
       "                                                   title  \\\n",
       "6136       Etude du risque syst\\'ematique de mortalit\\'e   \n",
       "6192            Likelihood-free Markov chain Monte Carlo   \n",
       "6538   Comment on \"Harold Jeffreys's Theory of Probab...   \n",
       "6544   Comment on \"Harold Jeffreys's Theory of Probab...   \n",
       "6576   Comment on \"Harold Jeffreys's Theory of Probab...   \n",
       "7297   On Exponential Sums, Nowton identities and Dic...   \n",
       "8475     Structural Analysis of Boolean Equation Systems   \n",
       "8873   Discussion of \"Multivariate quantiles and mult...   \n",
       "8879   Discussion of \"Multivariate quantiles and mult...   \n",
       "10719  Offline Signature Identification by Fusion of ...   \n",
       "\n",
       "                                                abstract         categories  \n",
       "6136     The aim of this paper is to propose a realis...  q-fin.GN q-fin.RM  \n",
       "6192     To appear to MCMC handbook, S. P. Brooks, A....            stat.ME  \n",
       "6538     Comment on \"Harold Jeffreys's Theory of Prob...            stat.ME  \n",
       "6544     Comment on \"Harold Jeffreys's Theory of Prob...            stat.ME  \n",
       "6576     Comment on \"Harold Jeffreys's Theory of Prob...            stat.ME  \n",
       "7297     Let $\\mathbb{F}_{q}$ be a finite field, $\\ma...      cs.IT math.IT  \n",
       "8475     We analyse the problem of solving Boolean eq...              cs.LO  \n",
       "8873     Discussion of \"Multivariate quantiles and mu...    math.ST stat.TH  \n",
       "8879     Discussion of \"Multivariate quantiles and mu...    math.ST stat.TH  \n",
       "10719    This paper uses Support Vector Machines (SVM...        cs.CV cs.LG  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove those \"withdrawn\" from all_data and from duplicated\n",
    "all_data = all_data[~all_data.id.isin(withdrawn.id.values)]\n",
    "duplicated_abstracts = duplicated_abstracts[~duplicated_abstracts.id.isin(withdrawn.id.values)]\n",
    "print(len(duplicated_abstracts))\n",
    "duplicated_abstracts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>1001.2985</td>\n",
       "      <td>['Arnold Zellner']</td>\n",
       "      <td>Comment on \"Harold Jeffreys's Theory of Probab...</td>\n",
       "      <td>Comment on \"Harold Jeffreys's Theory of Prob...</td>\n",
       "      <td>stat.ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6576</th>\n",
       "      <td>1001.3073</td>\n",
       "      <td>['Dennis Lindley']</td>\n",
       "      <td>Comment on \"Harold Jeffreys's Theory of Probab...</td>\n",
       "      <td>Comment on \"Harold Jeffreys's Theory of Prob...</td>\n",
       "      <td>stat.ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>1002.4509</td>\n",
       "      <td>['Linglong Kong', 'Ivan Mizera']</td>\n",
       "      <td>Discussion of \"Multivariate quantiles and mult...</td>\n",
       "      <td>Discussion of \"Multivariate quantiles and mu...</td>\n",
       "      <td>math.ST stat.TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16952</th>\n",
       "      <td>1010.0836</td>\n",
       "      <td>['Arthur Gretton', 'Kenji Fukumizu', 'Bharath ...</td>\n",
       "      <td>Discussion of: Brownian distance covariance</td>\n",
       "      <td>Discussion on \"Brownian distance covariance\"...</td>\n",
       "      <td>stat.AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16954</th>\n",
       "      <td>1010.0839</td>\n",
       "      <td>['Christopher R. Genovese']</td>\n",
       "      <td>Discussion of: Brownian distance covariance</td>\n",
       "      <td>Discussion on \"Brownian distance covariance\"...</td>\n",
       "      <td>stat.AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            authors  \\\n",
       "6544   1001.2985                                 ['Arnold Zellner']   \n",
       "6576   1001.3073                                 ['Dennis Lindley']   \n",
       "8879   1002.4509                   ['Linglong Kong', 'Ivan Mizera']   \n",
       "16952  1010.0836  ['Arthur Gretton', 'Kenji Fukumizu', 'Bharath ...   \n",
       "16954  1010.0839                        ['Christopher R. Genovese']   \n",
       "\n",
       "                                                   title  \\\n",
       "6544   Comment on \"Harold Jeffreys's Theory of Probab...   \n",
       "6576   Comment on \"Harold Jeffreys's Theory of Probab...   \n",
       "8879   Discussion of \"Multivariate quantiles and mult...   \n",
       "16952        Discussion of: Brownian distance covariance   \n",
       "16954        Discussion of: Brownian distance covariance   \n",
       "\n",
       "                                                abstract       categories  \n",
       "6544     Comment on \"Harold Jeffreys's Theory of Prob...          stat.ME  \n",
       "6576     Comment on \"Harold Jeffreys's Theory of Prob...          stat.ME  \n",
       "8879     Discussion of \"Multivariate quantiles and mu...  math.ST stat.TH  \n",
       "16952    Discussion on \"Brownian distance covariance\"...          stat.AP  \n",
       "16954    Discussion on \"Brownian distance covariance\"...          stat.AP  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_abstracts[duplicated_abstracts.duplicated(subset='title')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abstract\n",
       "  After two decades of repository development, some conclusions may be drawn as\\nto which type of repository and what kind of service best supports digital\\nscholarly communication, and thus the production of new knowledge. Four types\\nof publication repository may be distinguished, namely the subject-based\\nrepository, research repository, national repository system and institutional\\nrepository. Two important shifts in the role of repositories may be noted. With\\nregard to content, a well-defined and high quality corpus is essential. This\\nimplies that repository services are likely to be most successful when\\nconstructed with the user and reader uppermost in mind. With regard to service,\\nhigh value to specific scholarly communities is essential. This implies that\\nrepositories are likely to be most useful to scholars when they offer dedicated\\nservices supporting the production of new knowledge. Along these lines,\\nchallenges and barriers to repository development may be identified in three\\nkey dimensions: a) identification and deposit of content; b) access and use of\\nservices; and c) preservation of content and sustainability of service. An\\nindicative comparison of challenges and barriers in some major world regions\\nsuch as Europe, North America and East Asia plus Australia is offered in\\nconclusion.\\n    [Comparing Repository Types - Challenges and b...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_abstracts[:].groupby('abstract')['title'].apply(list)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "A New Email Retrieval Ranking Approach                                                                                                                                                                             [id, authors, title, abstract, categories]\n",
       "A Parsing Scheme for Finding the Design Pattern and Reducing the\\n  Development Cost of Reusable Object Oriented Software                                                                                          [id, authors, title, abstract, categories]\n",
       "A fast and robust patient specific Finite Element mesh registration\\n  technique: application to 60 clinical cases                                                                                                 [id, authors, title, abstract, categories]\n",
       "A note on precised Hardy inequalities on Carnot groups and Riemannian\\n  manifolds                                                                                                                                 [id, authors, title, abstract, categories]\n",
       "A partial $A_\\infty$-structure on the cohomology of $C_n\\times C_m$                                                                                                                                                [id, authors, title, abstract, categories]\n",
       "Action of Non Abelian Group Generated by Affine Homotheties on R^n                                                                                                                                                 [id, authors, title, abstract, categories]\n",
       "An Algorithm for Odd Graceful Labeling of the Union of Paths and Cycles                                                                                                                                            [id, authors, title, abstract, categories]\n",
       "An Application-oriented Model for Wireless Sensor Networks integrated\\n  with Telecom Infra                                                                                                                        [id, authors, title, abstract, categories]\n",
       "Analysis of semidiscretization of the compressible Navier-Stokes\\n  equations                                                                                                                                      [id, authors, title, abstract, categories]\n",
       "Applications of the Digital-Discrete Method in Smooth-Continuous Data\\n  Reconstruction                                                                                                                            [id, authors, title, abstract, categories]\n",
       "Associative Geometries. I: Torsors, linear relations and Grassmannians                                                                                                                                             [id, authors, title, abstract, categories]\n",
       "Associative Geometries. II: Involutions, the classical torsors, and\\n  their homotopes                                                                                                                             [id, authors, title, abstract, categories]\n",
       "Asymptotic normality of randomly truncated stochastic algorithms                                                                                                                                                   [id, authors, title, abstract, categories]\n",
       "B Physics at the Tevatron                                                                                                                                                                                          [id, authors, title, abstract, categories]\n",
       "Biometric Authentication using Nonparametric Methods                                                                                                                                                               [id, authors, title, abstract, categories]\n",
       "Breaking Symmetries                                                                                                                                                                                                [id, authors, title, abstract, categories]\n",
       "Breaking the Legend: Maxmin Fairness notion is no longer effective                                                                                                                                                 [id, authors, title, abstract, categories]\n",
       "CDF Hot Topics                                                                                                                                                                                                     [id, authors, title, abstract, categories]\n",
       "Comment on \"Harold Jeffreys's Theory of Probability Revisited\"                                                                                                                                                     [id, authors, title, abstract, categories]\n",
       "Comparing Repository Types - Challenges and barriers for subject-based\\n  repositories, research repositories, national repository systems and\\n  institutional repositories in serving scholarly communication    [id, authors, title, abstract, categories]\n",
       "D\\'eveloppements asymptotiques combin\\'es et points tournants\\n  d'\\'equations diff\\'erentielles singuli\\`erement perturb\\'ees                                                                                     [id, authors, title, abstract, categories]\n",
       "Discussion of \"Multivariate quantiles and multiple-output regression\\n  quantiles: From $L_1$ optimization to halfspace depth\"                                                                                     [id, authors, title, abstract, categories]\n",
       "Discussion of Likelihood Inference for Models with Unobservables:\\n  Another View                                                                                                                                  [id, authors, title, abstract, categories]\n",
       "Discussion of: Brownian distance covariance                                                                                                                                                                        [id, authors, title, abstract, categories]\n",
       "Generic design of Chinese remaindering schemes                                                                                                                                                                     [id, authors, title, abstract, categories]\n",
       "Goodness of fit statistics for sparse contingency tables                                                                                                                                                           [id, authors, title, abstract, categories]\n",
       "HYMAD: Hybrid DTN-MANET Routing for Dense and Highly Dynamic Wireless\\n  Networks                                                                                                                                  [id, authors, title, abstract, categories]\n",
       "Impact of squark generation mixing on the search for gluinos at LHC                                                                                                                                                [id, authors, title, abstract, categories]\n",
       "Interoperability, Trust Based Information Sharing Protocol and Security:\\n  Digital Government Key Issues                                                                                                          [id, authors, title, abstract, categories]\n",
       "LVMB manifolds and simplicial spheres                                                                                                                                                                              [id, authors, title, abstract, categories]\n",
       "Neutrino Physics                                                                                                                                                                                                   [id, authors, title, abstract, categories]\n",
       "New Ideas for Resolution of Singularities in Arbitrary Characteristic                                                                                                                                              [id, authors, title, abstract, categories]\n",
       "Non-existence of stationary two-black-hole configurations                                                                                                                                                          [id, authors, title, abstract, categories]\n",
       "Observation of New Charmless Decays of Bottom Hadrons                                                                                                                                                              [id, authors, title, abstract, categories]\n",
       "On Exponential Sums, Nowton identities and Dickson Polynomials over\\n  Finite Fields                                                                                                                               [id, authors, title, abstract, categories]\n",
       "On The Characteristic Polynomial of Frobenius of Supersingular Abelian\\n  Varieties Of Dimension up to 7 over Finite Fields                                                                                        [id, authors, title, abstract, categories]\n",
       "On certain constructions of p-adic families of Siegel modular forms of\\n  even genus                                                                                                                               [id, authors, title, abstract, categories]\n",
       "On the two-dimensional moment problem                                                                                                                                                                              [id, authors, title, abstract, categories]\n",
       "Panchromatic study of GRB 060124: from precursor to afterglow                                                                                                                                                      [id, authors, title, abstract, categories]\n",
       "Performance Evaluation of Components Using a Granularity-based Interface\\n  Between Real-Time Calculus and Timed Automata                                                                                          [id, authors, title, abstract, categories]\n",
       "Periodicity, Thermal Effects, and Vacuum Force: Rotation in Random\\n  Classical Zero-Point Radiation                                                                                                               [id, authors, title, abstract, categories]\n",
       "Quantum ChromoDynamics                                                                                                                                                                                             [id, authors, title, abstract, categories]\n",
       "Quasi-degenerate neutrinos and tri-bi-maximal mixing                                                                                                                                                               [id, authors, title, abstract, categories]\n",
       "Search for CP violating charge asymmetry in B^+ -> J/psi K^+ decays                                                                                                                                                [id, authors, title, abstract, categories]\n",
       "Searches for New Physics in Diphoton Events in proton anti-proton\\n  collisions at sqrt(s)=1.8TeV                                                                                                                  [id, authors, title, abstract, categories]\n",
       "Searches for inspiral gravitational waves associated with short\\n  gamma-ray bursts in LIGO's fifth and Virgo's first science run                                                                                  [id, authors, title, abstract, categories]\n",
       "Single-shot qubit readout in circuit Quantum Electrodynamics                                                                                                                                                       [id, authors, title, abstract, categories]\n",
       "Spectral variability of ultraluminous X-ray sources                                                                                                                                                                [id, authors, title, abstract, categories]\n",
       "The Mayer-Vietoris Property in Differential Cohomology                                                                                                                                                             [id, authors, title, abstract, categories]\n",
       "The Topological Centers Of Module Actions                                                                                                                                                                          [id, authors, title, abstract, categories]\n",
       "The modular branching rule for affine Hecke algebras of type A                                                                                                                                                     [id, authors, title, abstract, categories]\n",
       "Three-Dimensional Manifolds, Skew-Gorenstein Rings and their Cohomology                                                                                                                                            [id, authors, title, abstract, categories]\n",
       "Transcendence of generating functions whose coefficients are\\n  multiplicative                                                                                                                                     [id, authors, title, abstract, categories]\n",
       "Using Repeating Decimals As An Alternative To Prime Numbers In\\n  Encryption                                                                                                                                       [id, authors, title, abstract, categories]\n",
       "What does Newcomb's paradox teach us?                                                                                                                                                                              [id, authors, title, abstract, categories]\n",
       "dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonan_all_data[nonan_all_data.duplicated(subset='title')].groupby('title').apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  A  1\n",
       "1  A  2\n",
       "2  B  5\n",
       "3  B  5\n",
       "4  B  4\n",
       "5  C  6"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame( {'a':['A','A','B','B','B','C'], 'b':[1,2,5,5,4,6]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a\n",
       "A       [1, 2]\n",
       "B    [5, 5, 4]\n",
       "C          [6]\n",
       "Name: b, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('a')['b'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4091766514130017"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# franction of records with more than one category\n",
    "sum( len(str(category).split())>1 for category in all_data.categories ) / len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23427"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mygen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-970320e44e6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nan'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "np.isnan('nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cs: from_2016-01-01_to_2016-12-31\n",
      "     math: from_2016-01-01_to_2016-07-01\n",
      "     math: from_2016-07-02_to_2016-12-31\n",
      "  physics: from_2016-01-01_to_2016-05-01\n",
      "  physics: from_2016-05-02_to_2016-09-01\n",
      "  physics: from_2016-09-02_to_2016-12-31\n",
      "    q-bio: from_2016-01-01_to_2016-12-31\n",
      "    q-fin: from_2016-01-01_to_2016-12-31\n",
      "     stat: from_2016-01-01_to_2016-12-31\n"
     ]
    }
   ],
   "source": [
    "# load the csv's obtained with 'arXiv_metadata_harvester.ipynb'\n",
    "\n",
    "#dir_ = os.path.join(\"data\", \"arXivMeta_completed\")\n",
    "#dir_ = os.path.join(\"data\", \"arXivMeta_example_bak\")\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "# create dict of file-lists dfs = {'cs': [file1, ...], 'math': ..., etc.}\n",
    "for file in os.listdir(dir_):\n",
    "    info = re.search(r'arXivMeta_(.+?)_(.+?)\\.(\\w+?)', file)\n",
    "    cat = info.group(1)\n",
    "    date = info.group(2)\n",
    "    print(f'{cat:>9}: {date}')\n",
    "    \n",
    "    file_path = os.path.join(dir_, file)\n",
    "    \n",
    "    if cat not in dfs:\n",
    "        dfs[cat] = [file_path]\n",
    "    else:\n",
    "        dfs[cat].append(file_path)\n",
    "\n",
    "# create dict of data_frames dfs = {'cs': pd.DataFrame(), 'math': ..., etc.}       \n",
    "def getdf(file_list):\n",
    "    cat_dfs = [pd.read_csv(file, delimiter='\\t') for file in file_list]\n",
    "    return pd.concat(cat_dfs)\n",
    "\n",
    "dfs = {cat: getdf(cat_files) for (cat, cat_files) in dfs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and select the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prim_cat</th>\n",
       "      <th>sec_cats</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0189</td>\n",
       "      <td>math</td>\n",
       "      <td>math.GR</td>\n",
       "      <td>Monoid generalizations of the Richard Thompson...</td>\n",
       "      <td>The groups G_{k,1} of Richard Thompson and G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.1313</td>\n",
       "      <td>math</td>\n",
       "      <td>math.GT math.CO</td>\n",
       "      <td>Mutant knots and intersection graphs</td>\n",
       "      <td>We prove that if a finite order knot invaria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.2146</td>\n",
       "      <td>math</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>Connected Edge-Disjoint Unions of Tur\\'an Graphs</td>\n",
       "      <td>A finite connected graph $G_r^\\sigma$ is con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id prim_cat         sec_cats  \\\n",
       "0  0704.0189     math          math.GR   \n",
       "1  0704.1313     math  math.GT math.CO   \n",
       "2  0704.2146     math          math.CO   \n",
       "\n",
       "                                               title  \\\n",
       "0  Monoid generalizations of the Richard Thompson...   \n",
       "1               Mutant knots and intersection graphs   \n",
       "2   Connected Edge-Disjoint Unions of Tur\\'an Graphs   \n",
       "\n",
       "                                            abstract  \n",
       "0    The groups G_{k,1} of Richard Thompson and G...  \n",
       "1    We prove that if a finite order knot invaria...  \n",
       "2    A finite connected graph $G_r^\\sigma$ is con...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have for example\n",
    "\n",
    "dfs['math'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cs', True),\n",
       " ('math', True),\n",
       " ('physics', True),\n",
       " ('q-bio', True),\n",
       " ('q-fin', True),\n",
       " ('stat', True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are no duplicates (at least by 'id')\n",
    "\n",
    "[(cat, 0 == len(df.id) - len(df.id.unique())) for (cat,df) in dfs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all data_frames into one\n",
    "\n",
    "full_df = pd.concat(dfs.values())\n",
    "\n",
    "# get a 10% sample to play with\n",
    "\n",
    "sample_df = full_df.sample(frac=0.1, random_state=123)\n",
    "sample_df.reset_index(inplace=True)\n",
    "len(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cats(df):\n",
    "    \n",
    "    cats = df.prim_cat.unique()\n",
    "    record_counts = []\n",
    "    \n",
    "    for cat in cats:\n",
    "        count = sum(df.prim_cat == cat)\n",
    "        record_counts.append( [cat, count/1000] )\n",
    "    \n",
    "    record_counts = sorted(record_counts, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    record_counts = np.array(record_counts)\n",
    "    record_counts_df = pd.DataFrame({'categories': record_counts[:,0], '1000 papers': record_counts[:,1]}).set_index('categories')\n",
    "    display(record_counts_df)\n",
    "    record_counts_df.astype('float').plot.bar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000 papers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>physics</th>\n",
       "      <td>8.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math</th>\n",
       "      <td>4.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat</th>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q-bio</th>\n",
       "      <td>0.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q-fin</th>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1000 papers\n",
       "categories            \n",
       "physics          8.003\n",
       "math             4.546\n",
       "cs                2.62\n",
       "stat             0.565\n",
       "q-bio            0.295\n",
       "q-fin            0.099"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1afc51f7358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the number of papers in each class\n",
    "# the dataset is highly unbalanced, there's orders of magnitude between the most and the least frequent class\n",
    "\n",
    "show_cats(sample_df)\n",
    "\n",
    "# the world of quantative finance seems to be less keen on spending time writing papers than physicists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get primary_categories (prim_cat) and text (title+abstract) only\n",
    "# and safe those in 'bare data_frames'\n",
    "\n",
    "def strip(df):\n",
    "    df_2 = pd.concat([(df.title + \" \" + df.abstract).astype('str'),\n",
    "                      df.prim_cat.astype('category')], axis=1)\n",
    "    df_2.columns = ['text', 'label']\n",
    "    return df_2\n",
    "\n",
    "bare_dfs = {cat: strip(df) for (cat, df) in dfs.items()}\n",
    "\n",
    "bare_sample_df = strip(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The IBM 2016 Speaker Recognition System   In this paper we describe the recent advancements made in the IB...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 2(2S+1)- Formalism and Its Connection with Other Descriptions   In the framework of the Joos-Weinberg ...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regression-based Intra-prediction for Image and Video Coding   By utilizing previously known areas in an i...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            text  \\\n",
       "0  The IBM 2016 Speaker Recognition System   In this paper we describe the recent advancements made in the IB...   \n",
       "1  The 2(2S+1)- Formalism and Its Connection with Other Descriptions   In the framework of the Joos-Weinberg ...   \n",
       "2  Regression-based Intra-prediction for Image and Video Coding   By utilizing previously known areas in an i...   \n",
       "\n",
       "  label  \n",
       "0    cs  \n",
       "1  math  \n",
       "2    cs  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now we have for example\n",
    "\n",
    "with pd.option_context('display.max_colwidth', 110):\n",
    "    display(bare_sample_df[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One could also have a look at the papers' secondary categories of which there are almost 200 and there can be many such categories per paper. Maybe later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO side-project:\n",
    "# classify by subcategories (first entries in the list in 'sec_cats' of each paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          \n",
      "0704.0361  0      cs.IT\n",
      "           1    math.IT\n",
      "0704.0590  0      cs.IT\n",
      "           1    math.IT\n",
      "0704.0671  0      cs.IT\n",
      "           1      cs.LG\n",
      "           2    math.IT\n",
      "0704.0805  0      cs.IT\n",
      "           1    math.IT\n",
      "0704.0858  0      cs.CR\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc-phys</th>\n",
       "      <th>adap-org</th>\n",
       "      <th>alg-geom</th>\n",
       "      <th>ao-sci</th>\n",
       "      <th>astro-ph</th>\n",
       "      <th>astro-ph.CO</th>\n",
       "      <th>astro-ph.EP</th>\n",
       "      <th>astro-ph.GA</th>\n",
       "      <th>astro-ph.HE</th>\n",
       "      <th>astro-ph.IM</th>\n",
       "      <th>...</th>\n",
       "      <th>q-fin.TR</th>\n",
       "      <th>quant-ph</th>\n",
       "      <th>solv-int</th>\n",
       "      <th>stat.AP</th>\n",
       "      <th>stat.CO</th>\n",
       "      <th>stat.ME</th>\n",
       "      <th>stat.ML</th>\n",
       "      <th>stat.OT</th>\n",
       "      <th>stat.TH</th>\n",
       "      <th>supr-con</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0704.0189</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0704.0334</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0704.0345</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc-phys  adap-org  alg-geom  ao-sci  astro-ph  astro-ph.CO  \\\n",
       "id                                                                       \n",
       "0704.0189         0         0         0       0         0            0   \n",
       "0704.0334         0         0         0       0         0            0   \n",
       "0704.0345         0         0         0       0         0            0   \n",
       "\n",
       "           astro-ph.EP  astro-ph.GA  astro-ph.HE  astro-ph.IM    ...     \\\n",
       "id                                                               ...      \n",
       "0704.0189            0            0            0            0    ...      \n",
       "0704.0334            0            0            0            0    ...      \n",
       "0704.0345            0            0            0            0    ...      \n",
       "\n",
       "           q-fin.TR  quant-ph  solv-int  stat.AP  stat.CO  stat.ME  stat.ML  \\\n",
       "id                                                                            \n",
       "0704.0189         0         0         0        0        0        0        0   \n",
       "0704.0334         0         0         0        0        0        0        0   \n",
       "0704.0345         0         0         0        0        0        0        0   \n",
       "\n",
       "           stat.OT  stat.TH  supr-con  \n",
       "id                                     \n",
       "0704.0189        0        0         0  \n",
       "0704.0334        0        0         0  \n",
       "0704.0345        0        0         0  \n",
       "\n",
       "[3 rows x 168 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot-encode the \n",
    "ids_with_cats_ugly = full_df[['id', 'sec_cats']].set_index('id').sec_cats.str.split(expand=True).stack()\n",
    "print(ids_with_cats_ugly[:10])\n",
    "\n",
    "id_with_cats_df = pd.get_dummies(ids_with_cats_ugly).groupby(level=0).sum()\n",
    "id_with_cats_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_with_cats_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO take care of adap-org (nlin.AO), chao-dyn(nlin.CD), patt-sol (nlin.PS) etc.:\n",
    "\n",
    "# Each category should be in the format 'general.specic' (e.g. 'astr-ph.CO') or just 'general' (e.g. 'astro-ph')\n",
    "# but some of our columns are assigned to 'specific' in the spelled-out format (eg. chao-dyn instead of nlin.CD)\n",
    "# See https://arxiv.org/ and http://arxitics.com/help/categories\n",
    "\n",
    "# for column in id_with_cats_df:\n",
    "#     print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstracts of scientific papers tend to be written in a formal style, not contain typos, no direct citations, little references, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical Abundance Analysis of Moving Group W11450 (Latham 1)   We present elemental abundances for all seven stars in Moving Group W11450\r\n",
      "(Latham 1) to determine if they may be chemically related. These stars appear\r\n",
      "to be both spatially and kinematically related, but no spectroscopic abundance\r\n",
      "analysis exists in literature. Abundances for eight elements were derived via\r\n",
      "equivalent width analyses of high resolution (R $\\sim$60,000), high\r\n",
      "signal-to-noise ratio ($\\langle$SNR$\\rangle\\sim$100) spectra obtained with the\r\n",
      "Otto Struve 2.1m telescope and Sandiford Echelle Spectrograph at McDonald\r\n",
      "Observatory. The large star-to-star scatter in metallicity, -0.55 $\\leq$ [Fe/H]\r\n",
      "$\\leq$ 0.06 dex ($\\sigma$= 0.25), implies these stars were not produced from\r\n",
      "the same chemically homogeneous molecular cloud, and are therefore not part of\r\n",
      "a remnant or open cluster as previously proposed. Prior to this analysis, it\r\n",
      "was suggested that two stars in the group, W11449 & W11450, are possible wide\r\n",
      "binaries. The candidate wide binary pair show similar chemical abundance\r\n",
      "patterns with not only iron, but with other elements analyzed in this study,\r\n",
      "suggesting the proposed connection between these two stars may be real.\r\n",
      "\n",
      "---\n",
      "Helical spin texture and interference of Majorana bound states in\r\n",
      "  one-dimensional topological superconductor   We investigate one-dimensional (1D) Majorana bound states (MBSs) realized in\r\n",
      "terms of the helical edge states of a 2D quantum spin-Hall insulator (QSHI) in\r\n",
      "a heterostructure with a superconducting substrate and two ferromagnetic\r\n",
      "insulators (FIs). By means of Bogoliubov-de Gennes approach we demonstrate that\r\n",
      "there is a helical spin texture in the MBS wave function with a pitch\r\n",
      "proportional to the Fermi momentum of the helical edge states of QSHI.\r\n",
      "Moreover, simultaneous detection on local density of states by scanning\r\n",
      "tunneling microscopy and spectroscopy at a position close to one FI edge and at\r\n",
      "the midpoint between two FIs can not only map out the energy spectrum $\\pm E\r\n",
      "\\cos(\\phi/2)$, but also prove experimentally that the two quasiparticle\r\n",
      "excitations do not mix with each other as protected by the parity conservation\r\n",
      "associated with the MBSs.\r\n",
      "\n",
      "---\n",
      "Exploit Bounding Box Annotations for Multi-label Object Recognition   Convolutional neural networks (CNNs) have shown great performance as general\r\n",
      "feature representations for object recognition applications. However, for\r\n",
      "multi-label images that contain multiple objects from different categories,\r\n",
      "scales and locations, global CNN features are not optimal. In this paper, we\r\n",
      "incorporate local information to enhance the feature discriminative power. In\r\n",
      "particular, we first extract object proposals from each image. With each image\r\n",
      "treated as a bag and object proposals extracted from it treated as instances,\r\n",
      "we transform the multi-label recognition problem into a multi-class\r\n",
      "multi-instance learning problem. Then, in addition to extracting the typical\r\n",
      "CNN feature representation from each proposal, we propose to make use of\r\n",
      "ground-truth bounding box annotations (strong labels) to add another level of\r\n",
      "local information by using nearest-neighbor relationships of local regions to\r\n",
      "form a multi-view pipeline. The proposed multi-view multi-instance framework\r\n",
      "utilizes both weak and strong labels effectively, and more importantly it has\r\n",
      "the generalization ability to even boost the performance of unseen categories\r\n",
      "by partial strong labels from other categories. Our framework is extensively\r\n",
      "compared with state-of-the-art hand-crafted feature based methods and CNN based\r\n",
      "methods on two multi-label benchmark datasets. The experimental results\r\n",
      "validate the discriminative power and the generalization ability of the\r\n",
      "proposed framework. With strong labels, our framework is able to achieve\r\n",
      "state-of-the-art results in both datasets.\r\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# take a look at a few abstracts\n",
    "\n",
    "import random\n",
    "  \n",
    "for _ in range(3):\n",
    "    print(bare_sample_df.text.iloc[random.choice(range(len(bare_sample_df)))])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One messy but informative kind of writing they have are LateX formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Functional determinants, index theorems, and exact quantum black hole\\r\\n  entropy   The exact quantum entropy of BPS black holes can be evaluated using\\r\\nlocalization in supergravity. An important ingredient in this program, that has\\r\\nbeen lacking so far, is the one-loop effect arising from the quadratic\\r\\nfluctuations of the exact deformation (the $Q\\\\mathcal{V}$ operator). We compute\\r\\nthe fluctuation determinant for vector multiplets and hyper multiplets around\\r\\n$Q$-invariant off-shell configurations in four-dimensional $\\\\mathcal{N}=2$\\r\\nsupergravity with $AdS_{2} \\\\times S^{2}$ boundary conditions, using the\\r\\nAtiyah-Bott fixed-point index theorem and a subsequent zeta function\\r\\nregularization. Our results extend the large-charge on-shell entropy\\r\\ncomputations in the literature to a regime of finite charges. Based on our\\r\\nresults, we present an exact formula for the quantum entropy of BPS black holes\\r\\nin $\\\\mathcal{N}=2$ supergravity. We explain cancellations concerning\\r\\n$\\\\frac18$-BPS black holes in $\\\\mathcal{N}=8$ supergravity that were observed in\\r\\narXiv:1111.1161. We also make comments about the interpretation of a\\r\\nlogarithmic term in the topological string partition function in the low energy\\r\\nsupergravity theory.\\r\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bare_sample_df.text[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's map those into a single 'word'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask all LaTeX with a single word ' _LATEX_ '\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DeLaTeX(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Replace '\\$(.+)?\\$' with ' _LATEX_ '\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.str.replace(r'\\$(.+)?\\$', ' _LATEX_ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Functional determinants, index theorems, and exact quantum black hole\\r\\n  entropy   The exact quantum entropy of BPS black holes can be evaluated using\\r\\nlocalization in supergravity. An important ingredient in this program, that has\\r\\nbeen lacking so far, is the one-loop effect arising from the quadratic\\r\\nfluctuations of the exact deformation (the  _LATEX_  operator). We compute\\r\\nthe fluctuation determinant for vector multiplets and hyper multiplets around\\r\\n _LATEX_ \\r\\nsupergravity with  _LATEX_  boundary conditions, using the\\r\\nAtiyah-Bott fixed-point index theorem and a subsequent zeta function\\r\\nregularization. Our results extend the large-charge on-shell entropy\\r\\ncomputations in the literature to a regime of finite charges. Based on our\\r\\nresults, we present an exact formula for the quantum entropy of BPS black holes\\r\\nin  _LATEX_  supergravity. We explain cancellations concerning\\r\\n _LATEX_  supergravity that were observed in\\r\\narXiv:1111.1161. We also make comments about the interpretation of a\\r\\nlogarithmic term in the topological string partition function in the low energy\\r\\nsupergravity theory.\\r\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX()\n",
    "delatex.transform(bare_sample_df.text)[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build a simple untuned pipeline with a couple shallow classifiers\n",
    "### We relay on the *class_weight* argument to account for the imbalance of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text       object\n",
       "label    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the data_frame\n",
    "\n",
    "work_df = bare_sample_df\n",
    "\n",
    "print(len(work_df))\n",
    "work_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_train, text_test, label_train, label_test = train_test_split(work_df.text, work_df.label, test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs', 'math', 'physics', 'q-bio', 'q-fin', 'stat']\n"
     ]
    }
   ],
   "source": [
    "# encode the labels, 'cs' -> 0, ..., 'stat' -> 5\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_e = preprocessing.LabelEncoder()\n",
    "y_train = label_e.fit_transform(label_train)\n",
    "y_test = label_e.transform(label_test)\n",
    "\n",
    "print(list(label_e.classes_))\n",
    "\n",
    "#label_e.inverse_transform([0]) # array(['cs'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's first build the pipe and push the data trough step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "notex_text_train = delatex.fit_transform(text_train)\n",
    "notex_text_test = delatex.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10805, 37937)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_v = CountVectorizer(strip_accents='unicode')\n",
    "word_counts_train = count_v.fit_transform(notex_text_train)\n",
    "word_counts_test = count_v.transform(notex_text_test)\n",
    "word_counts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is there fewer rows? Were they empty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(113420, 'the'),\n",
       " (71769, 'of'),\n",
       " (39808, 'and'),\n",
       " (35847, 'in'),\n",
       " (30939, 'to'),\n",
       " (23502, 'we'),\n",
       " (21230, 'is'),\n",
       " (20436, 'for'),\n",
       " (15495, 'that'),\n",
       " (14938, '_latex_'),\n",
       " (14689, 'with'),\n",
       " (12535, 'on'),\n",
       " (11021, 'this'),\n",
       " (10733, 'are'),\n",
       " (10459, 'by')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the most frequent words (after using the 'max_df' above)\n",
    "\n",
    "sum_word_counts_train = word_counts_train.sum(axis=0)\n",
    "sorted([(sum_word_counts_train[0, i], word) for word, i in count_v.vocabulary_.items()],reverse=True)[:15]\n",
    "\n",
    "# The '_latex_' word of ours id dangerously high.\n",
    "# Yet I would still hope that it is underrepresented in quantitative biology or quantitative finance\n",
    "# We'll settle on max_df=0.8\n",
    "# \n",
    "# Maybe we should have balanced the classes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "def build_arXivMeta_clf(model):\n",
    "    pipe = []\n",
    "    pipe.append(( 'delatex', DeLaTeX() ))\n",
    "    pipe.append(( 'count_v', CountVectorizer(strip_accents='unicode', min_df = 2, max_df = 0.8)  ))\n",
    "    pipe.append(( 'tfidf_t', TfidfTransformer(use_idf=False)  ))\n",
    "    pipe.append(( 'sgd_clf', model  ))\n",
    "\n",
    "    return Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX()), ('count_v', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, sto..._state=None, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our first model, an linear SVMM with stochastic gradient descent\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "arXivMeta_clf_1 = build_arXivMeta_clf(\n",
    "    SGDClassifier(loss='hinge', class_weight=\"balanced\", n_jobs=-1, max_iter=1000, tol=1e-3)\n",
    ")\n",
    "arXivMeta_clf_1.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, let's just have some fun first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'physics', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_abstracts = pd.Series([\"\"\"\n",
    "The Lack of A Priori Distinctions Between Learning Algorithms  This is the first of\n",
    "two papers that use off-training set (OTS) error to investigate the assumption-free\n",
    "relationship between learning algorithms. This first paper discusses the senses in\n",
    "which there are no a priori distinctions between learning algorithms. (The second\n",
    "paper discusses the senses in which there are such distinctions.) In this first paper\n",
    "it is shown, loosely speaking, that for any two algorithms A and B, there are \"as many\"\n",
    "targets (or priors over targets) for which A has lower expected OTS error than B as\n",
    "vice versa, for loss functions like zero-one loss. In particular, this is true if A\n",
    "is cross-validation and B is \"anti-cross-validation'' (choose the learning algorithm\n",
    "with largest cross-validation error). This paper ends with a discussion of the\n",
    "implications of these results for computational learning theory. It is shown that one\n",
    "cannot say: if empirical misclassification rate is low, the Vapnik-Chervonenkis\n",
    "dimension of your generalizer is small, and the training set is large, then with high\n",
    "probability your OTS error is small. Other implications for \"membership queries\"\n",
    "algorithms and \"punting\" algorithms are also discussed.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "X-rays quarks lepton scattering experiment field\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "genes DNA RNA sequencing protein species fenotype \n",
    "\"\"\",\n",
    "\"\"\"\n",
    "computer algorithm graph sorting depth first interface\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "We offer a novel less intuitive proof of $\\limit_{x\\to 0} x = 0$,\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "infllation resources market stock bonds derivatives\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "distribution Bayesian p value marginalization Monte Carlo\n",
    "\"\"\"\n",
    "])\n",
    "\n",
    "\n",
    "label_e.inverse_transform(arXivMeta_clf_1.predict(random_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks promising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the multilabel classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def show_metrics(clf):\n",
    "    predicted_y_test = clf.predict(text_test)\n",
    "    print(metrics.classification_report(y_test, predicted_y_test, target_names=label_e.classes_))\n",
    "    print(metrics.confusion_matrix(y_test, predicted_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.69      0.71      0.70       894\n",
      "        math       0.80      0.74      0.77      1510\n",
      "     physics       0.93      0.90      0.91      2633\n",
      "       q-bio       0.42      0.55      0.48        80\n",
      "       q-fin       0.31      0.57      0.40        30\n",
      "        stat       0.33      0.59      0.42       176\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5323\n",
      "   macro avg       0.58      0.67      0.61      5323\n",
      "weighted avg       0.82      0.80      0.81      5323\n",
      "\n",
      "[[ 633  107   37   12    8   97]\n",
      " [ 179 1115  121   10   16   69]\n",
      " [  66  143 2362   29    7   26]\n",
      " [  10    4   11   44    1   10]\n",
      " [   1    6    1    0   17    5]\n",
      " [  30   26    3    9    5  103]]\n"
     ]
    }
   ],
   "source": [
    "show_metrics(arXivMeta_clf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: understand what the above values are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX()), ('count_v', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, sto...tors=100, n_jobs=None, oob_score=False,\n",
       "            random_state=123, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "arXivMeta_clf_2 = build_arXivMeta_clf(\n",
    "    RandomForestClassifier(class_weight = 'balanced', n_estimators=100, max_depth=10, criterion='entropy', random_state=123)\n",
    ")\n",
    "arXivMeta_clf_2.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.61      0.59      0.60       894\n",
      "        math       0.67      0.74      0.70      1510\n",
      "     physics       0.89      0.81      0.85      2633\n",
      "       q-bio       0.31      0.41      0.35        80\n",
      "       q-fin       0.62      0.43      0.51        30\n",
      "        stat       0.33      0.48      0.40       176\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      5323\n",
      "   macro avg       0.57      0.58      0.57      5323\n",
      "weighted avg       0.75      0.74      0.74      5323\n",
      "\n",
      "[[ 530  198   64   15    3   84]\n",
      " [ 176 1119  156    7    5   47]\n",
      " [  96  318 2145   45    0   29]\n",
      " [  15    3   22   33    0    7]\n",
      " [   4    9    2    0   13    2]\n",
      " [  46   30    8    7    0   85]]\n"
     ]
    }
   ],
   "source": [
    "show_metrics(arXivMeta_clf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "# add LogisticRegression, RidgeClassifier with the 'class_weight=balanced' argument\n",
    "\n",
    "# make a prettier confusion matrix with a heat_map \n",
    "\n",
    "# grid search with cross validation\n",
    "\n",
    "# try Hash Vectorizer instead of CountVectorizer\n",
    "# balance the classes by up-/down-sampling and use other models (MultiNomial Naive Bayes)\n",
    "# out-of-core learning ?\n",
    "\n",
    "# see how accuracy scales with data volume (we have 800 MB to go around)\n",
    "\n",
    "# unsupervised learning:\n",
    "# LDA\n",
    "# clustering\n",
    "# visualization: t-SNE ?\n",
    "\n",
    "# deep learning ?\n",
    "\n",
    "# multilabel learning (with the secondary classes) ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
