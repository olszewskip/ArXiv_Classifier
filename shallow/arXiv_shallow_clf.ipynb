{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import SCORERS, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer #, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "#from sklearn.linear_model import SGDlassifier(loss = ...) # loss='hinge'/'log'\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "### Bag od words with SVMs, Log-Regression, Random-Forest etc. on top \n",
    "\n",
    "* Build and test a preprocessing pipe:\n",
    "    * Handle *LaTeX* formulas before count-vectorizatation and TFIDF transformation.\n",
    "    * Test a handful of preprocessing parameters (inc. 2-grams, idf switched on/off, maximal document frequency) with a single untuned classifier.\n",
    "* Test a handful of shallow multiclass classifiers with *macro-F1* as the objective, this time without broadly changing the preprocessing parameters:\n",
    "* The grid-search in both step is (likely) performed on a fraction of the train data.\n",
    "* Fit the tuned classifiers to the whole of train data.\n",
    "* Collect the *macro-f1* scores obtained on the test data.\n",
    "* ... Save the best fitted model to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the volume\n",
    "The whole forthcoming analysis in the notebook is parametrized by the number of records that we wish to use. The maximum that we have is 838_804 in *data/bare_all.csv*, but we will choose to work with a smaller sample for convenience. This is done conceptually before any considerations about testing, validating etc., as if we simply had harvested a smaller dataset. Also, we will first tune the classifiers on a *small_number* of records, and only later refit and evaluate them on a *big_number* of records as if we had harvested additional data after the tuning (see below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_number = 200_000\n",
    "big_number = 700_000\n",
    "total = 838_804"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the measure of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available scikit-learn's scorers\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my choice\n",
    "scoring = \"f1_macro\"\n",
    "average = \"macro\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the two-column data frame (text + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"data\", \"bare_all.csv\")\n",
    "data = pd.read_csv(file, delimiter='\\t', nrows=small_number)\n",
    "\n",
    "# it happens to be shuffled already\n",
    "data_train = data[: int(small_number*0.8)]\n",
    "data_test = data[int(small_number*0.8) :]\n",
    "\n",
    "text_train = data_train.text\n",
    "label_train = data_train.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. all records in memory: 200000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On the interplay between star formation and feedback in galaxy formation simulations.  We investigate the star forma...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transversal Homotopy Monoids of Complex Projective Space.  We will give a geometric description of the nth transvers...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remarks on some typical assumptions in dynamo theory.  Some concepts used in the theory of convection-driven dynamos...</td>\n",
       "      <td>phys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      text  \\\n",
       "0  On the interplay between star formation and feedback in galaxy formation simulations.  We investigate the star forma...   \n",
       "1  Transversal Homotopy Monoids of Complex Projective Space.  We will give a geometric description of the nth transvers...   \n",
       "2  Remarks on some typical assumptions in dynamo theory.  Some concepts used in the theory of convection-driven dynamos...   \n",
       "\n",
       "  label  \n",
       "0  phys  \n",
       "1  math  \n",
       "2  phys  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"No. all records in memory: {len(data)}\")\n",
    "with pd.option_context('display.max_colwidth', 120):\n",
    "    display(data_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts of scientific papers tend to be written in a formal style, to not contain typos, nor direct citations, little references, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thermo-magnonic diode: rectification of energy and magnetization currents.  We investigate the dynamics of two coupled macrospins connected to thermal baths at different temperatures. The system behaves like a diode which allows the propagation of energy and mag- netization currents in one direction only. This effect is described by a simple model of two coupled nonlinear oscillators interacting with two independent reservoirs. It is shown that the rectification phenomenon can be interpreted as a a stochastic phase synchronization of the two spin-oscillators. A brief comparison with realistic micromagnetic simulations is presented. This new effect yields promising opportunities in spin-caloritronics devices. \n",
      "---\n",
      "Vibrational and optical properties of MoS$_2$: from monolayer to bulk.  Molybdenum disulfide, MoS2, has recently gained considerable attention as a layered material where neighboring layers are only weakly interacting and can easily slide against each other. Therefore, mechanical exfoliation allows the fabrication of single and multi-layers and opens the possibility to generate atomically thin crystals with outstanding properties. In contrast to graphene, it has an optical gap of 1.9 eV. This makes it a prominent candidate for transistor and opto-electronic applications. Single-layer MoS$_2$ exhibits remarkably different physical properties compared to bulk MoS$_2$ due to the absence of interlayer hybridization. For instance, while the band gap of bulk and multi-layer MoS$_2$ is indirect, it becomes direct with decreasing number of layers. In this review, we analyze from a theoretical point of view the electronic, optical, and vibrational properties of single-layer, few-layer and bulk MoS$_2$. In particular, we focus on the effects of spin-orbit interaction, number of layers, and applied tensile strain on the vibrational and optical properties. We examine the results obtained by different methodologies, mainly ab initio approaches. We also discuss which approximations are suitable for MoS$_2$ and layered materials. The effect of external strain on the band gap of single-layer MoS$_2$ and the crossover from indirect to direct band gap is investigated. We analyze the excitonic effects on the absorption spectra. The main features, such as the double peak at the absorption threshold and the high-energy exciton are presented. Furthermore, we report on the phonon dispersion relations of single-layer, few-layer and bulk MoS$_2$. Based on the latter, we explain the behavior of the Raman-active $A_{1g}$ and $E^1_{2g}$ modes as a function of the number of layers. \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(text_train.iloc[random.choice(range(len(text_train)))])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One messy but informative kind of writing they have are LaTeX formulas (*\\$...\\$*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group $\\\\Gamma$ on a single element $\\\\psi$ of a given Hilbert space $\\\\mathcal{H}$. As $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the $L^1$-space associated to the group von '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[6][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose to either mask them with * \\_latex\\_ * or flag them by appending * \\_latex\\_ * in front of each such expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask or flag LaTeX expression with a word ' _LATEX_ '\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "    # self.pattern = r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\"\n",
    "    # why does it differ from  r'(\\$.+?\\$)' ?\n",
    "    \n",
    "class DeLaTeX(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, behave=None, pattern=r\"(\\${1,2}[\\s\\w\\d\\\\,\\.=\\(\\)*{}/\\[\\]^;:'`<>|%&@\\\"!\\?~#+-]*?\\${1,2})\", repl = ' _LATEX_ '):\n",
    "        self.repl = ' _LATEX_ '\n",
    "        self.pattern = pattern\n",
    "        self.behave = behave\n",
    "        \n",
    "        if self.behave == 'mask':\n",
    "            self.repl = ' _LATEX_ '\n",
    "        elif self.behave == 'flag':\n",
    "            self.repl = r' _LATEX_ \\1'\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.core.series.Series):\n",
    "            raise TypeError(\"The data must be a pandas Series of strings\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.behave:\n",
    "            return X.str.replace(self.pattern, self.repl)\n",
    "        return X\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.estimator_checks import check_estimator\n",
    "# check_estimator(DeLaTeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group $\\\\Gamma$ on a single element $\\\\psi$ of a given Hilbert space $\\\\mathcal{H}$. As $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the $L^1$-space associated to the group von Neumann algebra of $\\\\Gamma$. Our result generalizes recent work for LCA groups. In many cases, the bracket map can be computed in terms of a noncommutative form of the Zak transform. '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = None)\n",
    "delatex.transform(text_train[6:7]).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_  on a single element  _LATEX_  of a given Hilbert space  _LATEX_ . As  _LATEX_  might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ -space associated to the group von Neumann algebra of  _LATEX_ . Our result generalizes recent work for LCA groups. In many cases, the bracket map can be computed in terms of a noncommutative form of the Zak transform. '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'mask')\n",
    "delatex.transform(text_train[6:7]).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_ $\\\\Gamma$ on a single element  _LATEX_ $\\\\psi$ of a given Hilbert space  _LATEX_ $\\\\mathcal{H}$. As  _LATEX_ $\\\\Gamma$ might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ $L^1$-space associated to the group von Neumann algebra of  _LATEX_ $\\\\Gamma$. Our result generalizes recent work for LCA groups. In many cases, the bracket map can be computed in terms of a noncommutative form of the Zak transform. '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "delatex.transform(text_train[6:7]).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs', 'math', 'phys', 'q-bio', 'q-fin', 'stat']\n"
     ]
    }
   ],
   "source": [
    "# 'cs' -> 0, ..., 'stat' -> 5\n",
    "\n",
    "label_e = LabelEncoder()\n",
    "y_train = label_e.fit_transform(label_train)\n",
    "\n",
    "print(list(label_e.classes_))\n",
    "\n",
    "#label_e.inverse_transform([0]) # array(['cs'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the most frequent words. Choose winners as the stop-words.\n",
    "Take note of the rank of our '\\_latex\\_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 157416)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delatex = DeLaTeX(behave = 'flag')\n",
    "count_v = CountVectorizer(strip_accents='unicode')\n",
    "word_counts_train = count_v.fit_transform(delatex.fit_transform(text_train))\n",
    "word_counts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1689000, 'the'),\n",
       " (1072000, 'of'),\n",
       " (595000, 'and'),\n",
       " (532000, 'in'),\n",
       " (443000, 'to'),\n",
       " (341000, 'we'),\n",
       " (311000, 'is'),\n",
       " (290000, 'for'),\n",
       " (288000, '_latex_'),\n",
       " (227000, 'that')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_word_counts_train = word_counts_train.sum(axis=0)\n",
    "sorted([(round(sum_word_counts_train[0, i],-3), word) for word, i in count_v.vocabulary_.items()],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['the', 'of', 'and', 'in','to','we','is'] # 'for' seems already mathematical/computer-sciency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go step by step through an arbitrary pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "delatex = DeLaTeX(behave='mask')\n",
    "notex_text_train = delatex.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(use_idf=True, stop_words=stopwords, min_df = 2, max_df=0.8, strip_accents='unicode')\n",
    "tfidf_scores_train = tfidf_v.fit_transform(notex_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1, class_weight='balanced')\n",
    "lsvc.fit(tfidf_scores_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's just have some fun first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_abstracts = pd.Series([\"\"\"\n",
    "The Lack of A Priori Distinctions Between Learning Algorithms. This is the first of\n",
    "two papers that use off-training set (OTS) error to investigate the assumption-free\n",
    "relationship between learning algorithms. This first paper discusses the senses in\n",
    "which there are no a priori distinctions between learning algorithms. (The second\n",
    "paper discusses the senses in which there are such distinctions.) In this first paper\n",
    "it is shown, loosely speaking, that for any two algorithms A and B, there are \"as many\"\n",
    "targets (or priors over targets) for which A has lower expected OTS error than B as\n",
    "vice versa, for loss functions like zero-one loss. In particular, this is true if A\n",
    "is cross-validation and B is \"anti-cross-validation'' (choose the learning algorithm\n",
    "with largest cross-validation error). This paper ends with a discussion of the\n",
    "implications of these results for computational learning theory. It is shown that one\n",
    "cannot say: if empirical misclassification rate is low, the Vapnik-Chervonenkis\n",
    "dimension of your generalizer is small, and the training set is large, then with high\n",
    "probability your OTS error is small. Other implications for \"membership queries\"\n",
    "algorithms and \"punting\" algorithms are also discussed.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "X-rays quarks lepton scattering experiment field\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "genes DNA RNA sequencing protein species fenotype \n",
    "\"\"\",\n",
    "\"\"\"\n",
    "computer algorithm graph sorting depth first interface\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "novel intuitive proof of $\\limit_{x\\to 0} x = 0$ convergence fomula,\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "inflation resources market stock bonds derivatives\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "confidence Bayesian p value marginalization Monte Carlo\n",
    "\"\"\"\n",
    "])\n",
    "\n",
    "label_e.inverse_transform(lsvc.predict(tfidf_v.transform(delatex.transform(random_abstracts ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks promising :)\n",
    "Here's the actual score on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.7791247885477873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.84      0.88      0.86      5236\n",
      "        math       0.90      0.90      0.90      9161\n",
      "        phys       0.98      0.96      0.97     24190\n",
      "       q-bio       0.61      0.71      0.66       462\n",
      "       q-fin       0.71      0.72      0.71       246\n",
      "        stat       0.54      0.61      0.57       705\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     40000\n",
      "   macro avg       0.76      0.80      0.78     40000\n",
      "weighted avg       0.93      0.93      0.93     40000\n",
      "\n",
      "[[ 4607   313   117    48    12   139]\n",
      " [  389  8273   282    37    35   145]\n",
      " [  243   514 23262   106    19    46]\n",
      " [   50    15    45   326     0    26]\n",
      " [   22    23    10     0   178    13]\n",
      " [  171    65    17    14     8   430]]\n"
     ]
    }
   ],
   "source": [
    "text_test = data_test.text\n",
    "label_test = data_test.label\n",
    "y_test = label_e.transform(label_test)\n",
    "\n",
    "predicted_y_test = lsvc.predict(tfidf_v.transform(delatex.transform(text_test)))\n",
    "\n",
    "print(\"Macro F1:\", f1_score(y_test, predicted_y_test, average=\"macro\"))\n",
    "print(classification_report(y_test, predicted_y_test, target_names=label_e.classes_))\n",
    "nofuss_conf_mtrx = confusion_matrix(y_test, predicted_y_test)\n",
    "print(nofuss_conf_mtrx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"By definition a confusion matrix $C$ is such that $C_{ij}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\" https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the above easily obtained confusion matrix in a *nofuss_conf_mtrx* variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained on a fraction of all records with an untuned Linear SVM, we have reached ~0.78 macro-F1 (out of sample) pulled down by poor performomance on classification wrt rarer classes. E.g. many *cs* and *math* are confused with *stat* (and vice versa), and similarly for *q-bio* and *physics*. This is actually sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid searching by hand through preprocessing params with Linear SVM Classifiers\n",
    "The goal now is to put a finger on reasonable preprocessing parameters. It would of course be better to include them in one global grid search with each classifier, but we do not have the resources for that. We are simply hoping to gain insight into whether any of the parameters (strategies) in the grid below is particularly important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = []\n",
    "pipe.append(( 'delatex', DeLaTeX(behave='mask') ))\n",
    "pipe.append(( 'tfidf_v', TfidfVectorizer(analyzer = 'word', strip_accents='unicode', min_df = 2)  ))\n",
    "pipe.append(( 'LinearSVC', LinearSVC(C=1, penalty='l2', class_weight='balanced')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'delatex__behave': ['mask', 'flag', None],\n",
    "    'tfidf_v__stop_words': [stopwords, None],\n",
    "#    'tfidf_v__ngram_range': [(1, 1), (1,2)], # cannot afford it computationally\n",
    "    'tfidf_v__use_idf': [True, False],\n",
    "    'tfidf_v__max_df': [0.6, 0.8, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000,)\n",
      "(160000,)\n"
     ]
    }
   ],
   "source": [
    "print(text_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed: 115.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave='mask',\n",
       "    pattern='(\\\\${1,2}[\\\\s\\\\w\\\\d\\\\\\\\,\\\\.=\\\\(\\\\)*{}/\\\\[\\\\]^;:\\'`<>|%&@\\\\\"!\\\\?~#+-]*?\\\\${1,2})',\n",
       "    repl=' _LATEX_ ')), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=False, n_jobs=1,\n",
       "       param_grid={'delatex__behave': ['mask', 'flag', None], 'tfidf_v__stop_words': [['the', 'of', 'and', 'in', 'to', 'we', 'is'], None], 'tfidf_v__use_idf': [True, False], 'tfidf_v__max_df': [0.6, 0.8, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LONG WAIT\n",
    "\n",
    "# there's some bug with njobs different than 1 because of the delatex in the pipe\n",
    "# may be related to the fact that check_estimator(DeLaTeX) raises an error due to DeLaTeX using the pandas' vectorized str method \n",
    "\n",
    "grid_s = GridSearchCV(Pipeline(pipe), params, cv=4, scoring=scoring, iid=False, return_train_score=True, n_jobs=1, refit=False, verbose=1)\n",
    "grid_s.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7849201807730376"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So no improvement over our first try above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delatex__behave': None,\n",
       " 'tfidf_v__max_df': 1.0,\n",
       " 'tfidf_v__stop_words': None,\n",
       " 'tfidf_v__use_idf': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_results = pd.DataFrame(grid_s.cv_results_)\n",
    "cols = ['param_' + param for param in params.keys()] + ['mean_test_score']\n",
    "results_df = grid_cv_results[cols].sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_delatex__behave</th>\n",
       "      <th>param_tfidf_v__stop_words</th>\n",
       "      <th>param_tfidf_v__use_idf</th>\n",
       "      <th>param_tfidf_v__max_df</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.784518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.784164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.784001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.784001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.784001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.784001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.783943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.783943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.783808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.783808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.783437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.783437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.779317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.779317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.778317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>None</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.778268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.777776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.777776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.777776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.777776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.777771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.777771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mask</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>flag</td>\n",
       "      <td>[the, of, and, in, to, we, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mask</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.777464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>flag</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.777464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_delatex__behave       param_tfidf_v__stop_words  \\\n",
       "34                  None                            None   \n",
       "30                  None                            None   \n",
       "22                  flag                            None   \n",
       "10                  mask                            None   \n",
       "32                  None  [the, of, and, in, to, we, is]   \n",
       "28                  None  [the, of, and, in, to, we, is]   \n",
       "0                   mask  [the, of, and, in, to, we, is]   \n",
       "12                  flag  [the, of, and, in, to, we, is]   \n",
       "2                   mask                            None   \n",
       "14                  flag                            None   \n",
       "26                  None                            None   \n",
       "24                  None  [the, of, and, in, to, we, is]   \n",
       "18                  flag                            None   \n",
       "6                   mask                            None   \n",
       "8                   mask  [the, of, and, in, to, we, is]   \n",
       "20                  flag  [the, of, and, in, to, we, is]   \n",
       "4                   mask  [the, of, and, in, to, we, is]   \n",
       "16                  flag  [the, of, and, in, to, we, is]   \n",
       "35                  None                            None   \n",
       "23                  flag                            None   \n",
       "11                  mask                            None   \n",
       "27                  None                            None   \n",
       "25                  None  [the, of, and, in, to, we, is]   \n",
       "29                  None  [the, of, and, in, to, we, is]   \n",
       "33                  None  [the, of, and, in, to, we, is]   \n",
       "31                  None                            None   \n",
       "3                   mask                            None   \n",
       "15                  flag                            None   \n",
       "13                  flag  [the, of, and, in, to, we, is]   \n",
       "1                   mask  [the, of, and, in, to, we, is]   \n",
       "17                  flag  [the, of, and, in, to, we, is]   \n",
       "5                   mask  [the, of, and, in, to, we, is]   \n",
       "9                   mask  [the, of, and, in, to, we, is]   \n",
       "21                  flag  [the, of, and, in, to, we, is]   \n",
       "7                   mask                            None   \n",
       "19                  flag                            None   \n",
       "\n",
       "   param_tfidf_v__use_idf param_tfidf_v__max_df  mean_test_score  \n",
       "34                   True                     1         0.784920  \n",
       "30                   True                   0.8         0.784518  \n",
       "22                   True                     1         0.784420  \n",
       "10                   True                     1         0.784420  \n",
       "32                   True                     1         0.784164  \n",
       "28                   True                   0.8         0.784164  \n",
       "0                    True                   0.6         0.784001  \n",
       "12                   True                   0.6         0.784001  \n",
       "2                    True                   0.6         0.784001  \n",
       "14                   True                   0.6         0.784001  \n",
       "26                   True                   0.6         0.783943  \n",
       "24                   True                   0.6         0.783943  \n",
       "18                   True                   0.8         0.783808  \n",
       "6                    True                   0.8         0.783808  \n",
       "8                    True                     1         0.783437  \n",
       "20                   True                     1         0.783437  \n",
       "4                    True                   0.8         0.783437  \n",
       "16                   True                   0.8         0.783437  \n",
       "35                  False                     1         0.781454  \n",
       "23                  False                     1         0.780541  \n",
       "11                  False                     1         0.780541  \n",
       "27                  False                   0.6         0.779317  \n",
       "25                  False                   0.6         0.779317  \n",
       "29                  False                   0.8         0.778317  \n",
       "33                  False                     1         0.778317  \n",
       "31                  False                   0.8         0.778268  \n",
       "3                   False                   0.6         0.777776  \n",
       "15                  False                   0.6         0.777776  \n",
       "13                  False                   0.6         0.777776  \n",
       "1                   False                   0.6         0.777776  \n",
       "17                  False                   0.8         0.777771  \n",
       "5                   False                   0.8         0.777771  \n",
       "9                   False                     1         0.777771  \n",
       "21                  False                     1         0.777771  \n",
       "7                   False                   0.8         0.777464  \n",
       "19                  False                   0.8         0.777464  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, with regards to our preprocessing steps, as a first order conclusion:\n",
    "    * All the parameters seem rather unimportant.\n",
    "    * The most important ones - in the sense of crowding the top of the above list - seem to be: using idf over not using it, and larger max_df rather than smaller.\n",
    "    * Our DeLaTeX behavior and stopwords do not have a significant effect.\n",
    "   \n",
    "In light of the above we will stick to:\n",
    "    * masking LaTeX\n",
    "    * no stop-words\n",
    "    * using IDFs\n",
    "    * no max_df limit (meaning the default =1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For convenience, I will mask the LaTeX in the whole dataset once, save it to file. From now on I will use it as the default dataset to work on.\n",
    "Imagining than I will be given a new arXiv metadata to classify, I would have to first explicitly push it through the DeLaTeX transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the records we have on disk\n",
    "file = os.path.join(\"data\", \"bare_all.csv\")\n",
    "all_data = pd.read_csv(file, delimiter='\\t', nrows=None)\n",
    "\n",
    "# mask away the LaTeX\n",
    "notex_data = pd.DataFrame()\n",
    "delatex = DeLaTeX(behave='mask')\n",
    "notex_data['text'] = delatex.transform(all_data.text)\n",
    "notex_data['label'] = all_data.label\n",
    "\n",
    "# and store it to disk\n",
    "file = os.path.join(\"data\", \"notex_all.csv\")\n",
    "notex_data.to_csv(file, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear the pythonic variables from memory\n",
    "%reset_selective -f \"^data$\"\n",
    "%reset_selective -f \"^all_data$\"\n",
    "%reset_selective -f \"^notex_data$\"\n",
    "\n",
    "# read back in the smaller sample\n",
    "small_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"data\", \"notex_all.csv\")\n",
    "data = pd.read_csv(file, delimiter='\\t', nrows=small_number)\n",
    "\n",
    "data_train = data[: int(small_number*0.8)]\n",
    "data_test = data[int(small_number*0.8) :]\n",
    "\n",
    "text_train = data_train.text\n",
    "label_train = data_train.label\n",
    "label_e = LabelEncoder()\n",
    "y_train = label_e.fit_transform(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Riesz and frame systems generated by unitary actions of discrete groups.  We characterize orthonormal bases, Riesz bases and frames which arise from the action of a countable discrete group  _LATEX_  on a single element  _LATEX_  of a given Hilbert space  _LATEX_ . As  _LATEX_  might not be abelian, this is done in terms of a bracket map taking values in the  _LATEX_ -space associated to the group'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[6][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated GridSearchCV for multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify models with a grid of hyper-parameters to choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \n",
    "    'LogReg': [LogisticRegression(class_weight='balanced', solver='lbfgs', multi_class='multinomial', max_iter=500),\n",
    "                  [( 'C', [4, 5, 6, 7, 8] ), ('multi_class', ['multinomial','ovr'])]\n",
    "                 ],\n",
    "    'LinSVC': [LinearSVC(class_weight='balanced', multi_class='ovr'),\n",
    "                  [('loss', ['hinge', 'squared_hinge']), ( 'C', [0.05, 0.1, 0.2, 0.4, 0.8] )]\n",
    "                 ],\n",
    "    'RndFClf': [RandomForestClassifier(class_weight='balanced', n_estimators=200, criterion=\"gini\"),\n",
    "                 [('max_depth', [20, 25, 30, 35]) , ('min_samples_leaf', [1, 1E-5, 1E-4])]\n",
    "                ],\n",
    "    'NearCen': [NearestCentroid(),\n",
    "                [('metric', ['euclidean','manhattan'])]\n",
    "               ],\n",
    "    'MultNB': [MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None),\n",
    "                [('alpha', [0.001, 0.003, 0.01, 0.03, 0.1])]\n",
    "               ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(name, model):\n",
    "    pipe = []\n",
    "    pipe.append(( 'delatex', DeLaTeX(behave='mask') ))\n",
    "    pipe.append(( 'tfidf_v', TfidfVectorizer(use_idf=True, strip_accents='unicode', min_df = 2)  ))\n",
    "    pipe.append(( name, model  ))\n",
    "    \n",
    "    return Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe_params(name, model_params):\n",
    "    \n",
    "    params = {}\n",
    "    for (param_name, range_) in model_params:\n",
    "        params[name + '__' + param_name] = range_\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search with cv=5 (stratified by default)\n",
    "Hyper-parameter tuning: Measure the score for each combination of values. Use cross-validation to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed: 44.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7893991702002847 \n",
      "\n",
      "LinSVC\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed: 12.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7887082763338273 \n",
      "\n",
      "RndFClf\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed: 66.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7259306523052589 \n",
      "\n",
      "NearCen\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6469201094267972 \n",
      "\n",
      "MultNB\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7765948727033288 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed: 15.2min finished\n"
     ]
    }
   ],
   "source": [
    "# GRID-SEARCH\n",
    "\n",
    "# collect the best_params for the models\n",
    "grid_s_results = {}\n",
    "\n",
    "for name, (model, model_params) in models.items():\n",
    "    \n",
    "    print(name)\n",
    "    pipe = build_clf(name, model)\n",
    "    params = build_pipe_params(name, model_params)\n",
    "    \n",
    "    grid_s = GridSearchCV(pipe, params, cv=5, scoring=scoring,\\\n",
    "                          iid=False, return_train_score=True,\\\n",
    "                          n_jobs=4, refit=False, verbose=1)\n",
    "    grid_s.fit(text_train, y_train)\n",
    "    \n",
    "    print(grid_s.best_score_, \"\\n\")\n",
    "    grid_s_results[name] = grid_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LogReg, 0.7907205499864248, {'LogReg__C': 6, 'LogReg__multi_class': 'ovr'}\n",
      "  LinSVC, 0.7882176340946864, {'LinSVC__C': 0.2, 'LinSVC__loss': 'squared_hinge'}\n",
      " RndFClf, 0.7180456405396348, {'RndFClf__criterion': 'gini', 'RndFClf__max_depth': 30, 'RndFClf__min_samples_leaf': 1}\n",
      " NearCen, 0.6470455065344326, {'NearCen__metric': 'euclidean'}\n",
      "  MultNB, 0.7759111324779105, {'MultNB__alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# examine the obtaind scores and best_params\n",
    "for name, grid_s in grid_s_results.items():\n",
    "    print(f\"{name:>8}, {grid_s.best_score_}, {grid_s.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append the best_params and f1-scores from grid-search to the *models* dict and store it in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, grid_s in grid_s_results.items():\n",
    "    \n",
    "    models[name].append(grid_s.best_score_)\n",
    "    models[name].append(grid_s.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arXiv_shallow_gridscv5_bestparams_on_160000.joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib / pickle\n",
    "dump(models, f'shallow_gridscv5_bestparams_on_{len(text_train)}.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display macro F1 for all the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting to 160000 records. Testing on unseen 40000.\n",
      "Fitted LogReg in 7 min.\n",
      "Fitted LinSVC in 1 min.\n",
      "Fitted RndFClf in 7 min.\n",
      "Fitted NearCen in 1 min.\n",
      "Fitted MultNB in 1 min.\n"
     ]
    }
   ],
   "source": [
    "models = load('arXiv_shallow_gridscv5_bestparams_on_160000.joblib')\n",
    "\n",
    "# The grid_search did not do a final 'refit'\n",
    "# We do it by hand and store the scores obtained on the test data in a new dict\n",
    "# along with the refitted models\n",
    "\n",
    "small_test_ranking = {}\n",
    "\n",
    "print(f\"Fitting to {len(text_train)} records. Testing on unseen {len(text_test)}.\")\n",
    "\n",
    "for name, (model, original_grid, score, best_params_) in models.items():\n",
    "    \n",
    "    clf = build_clf(name, model)\n",
    "    clf.set_params(**best_params_)\n",
    "    tick = time.time()\n",
    "    clf.fit(text_train, y_train)\n",
    "    tock = time.time()\n",
    "    \n",
    "    small_test_ranking[name] = [f1_score(y_test, clf.predict(text_test), average='macro'), clf]\n",
    "    \n",
    "    print(f\"Fitted {name} in {(tock - tick)/60:.0f} min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogReg': 0.7888135808707667,\n",
       " 'LinSVC': 0.781761219382194,\n",
       " 'MultNB': 0.7641103960001768,\n",
       " 'RndFClf': 0.7181672596543689,\n",
       " 'NearCen': 0.6384163392173875}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the dict with final F1 scores\n",
    "\n",
    "scores_list = sorted(small_test_ranking.items(), key=lambda model: model[1][0], reverse = True)\n",
    "scores_sorted = {name: score for (name, [score, _] ) in scores_list}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM is basically as good as Logistic Regression but seven times faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f8ea4333c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = range(len(scores_sorted))\n",
    "plt.ylim(0.5, 1)\n",
    "plt.bar(count, list(scores_sorted.values()))\n",
    "plt.xticks(count, list(scores_sorted.keys()))\n",
    "plt.title(f\"Macro F1 scores on test data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point one sensible thing to do would be to take one or few models from the top of our list, perhaps make an ensemble model, and to finally tune it using larger datasample. But, since we still have deep-learning ahead of us, I'll do something much simpler but still interesting: Let's fit much more data to those exact same classifiers and see if they improve.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit more train data to the tuned classifiers.\n",
    "The classifiers were tuned on a small number of records. Now we fit them anew to a bigger chunk of data.\n",
    "It would of course be more desirable to do the grid-search on the bigger chunk to begin with. We are just imagining a scenario, where we've obtained more data after tuning, and we wish to refit the model without repeating the grid-search. On should bare in mind that in general the tuned parameters are functions of the volume of data, so this approach relies on the assumption that those functions are not varying very fast, and it probably makes sense only if the new chunk is not many orders of magnitude bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700000, 2), (138804, 2))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = load('arXiv_shallow_gridscv5_bestparams_on_160000.joblib')\n",
    "\n",
    "file = os.path.join(\"data\", \"notex_all.csv\")\n",
    "big_data_train = pd.read_csv(file, delimiter='\\t', nrows=big_number) \n",
    "big_data_test = pd.read_csv(file, delimiter='\\t', nrows=(total-big_number), skiprows=big_number, header=None, names=['text', 'label'])\n",
    "\n",
    "big_data_train.shape, big_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_text_train = big_data_train.text\n",
    "big_y_train = label_e.transform(big_data_train.label)\n",
    "\n",
    "big_text_test = big_data_test.text\n",
    "big_y_test = label_e.transform(big_data_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting to 700000 records. Testing on unseen 138804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LogReg in 45 min.\n",
      " LinSVC in 7 min.\n",
      " RndFClf in 29 min.\n",
      " NearCen in 4 min.\n",
      " MultNB in 3 min.\n"
     ]
    }
   ],
   "source": [
    "# the scores obtained on the test sample are stored in a new dict and the refitted models are appended in the 'models' dict\n",
    "\n",
    "big_test_ranking = {}\n",
    "\n",
    "print(f\"Fitting to {len(big_text_train)} records. Testing on unseen {len(big_text_test)}.\")\n",
    "\n",
    "for name, (model, original_grid, score, best_params_) in models.items():\n",
    "    \n",
    "    clf = build_clf(name, model)\n",
    "    clf.set_params(**best_params_)\n",
    "    tick = time.time()\n",
    "    clf.fit(big_text_train, big_y_train)\n",
    "    tock = time.time()\n",
    "    \n",
    "    big_test_ranking[name] = [f1_score(big_y_test, clf.predict(big_text_test), average='macro'), clf]\n",
    "    \n",
    "    print(f\" {name} in {(tock - tick)/60:.0f} min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display macro F1 for all the classifiers - after refitting on bigger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinSVC': 0.802025130989597,\n",
       " 'LogReg': 0.80040975529827,\n",
       " 'MultNB': 0.782374150372291,\n",
       " 'RndFClf': 0.684741838298042,\n",
       " 'NearCen': 0.6340358101991361}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the dict with final F1 scores\n",
    "# Save the the winning classifier\n",
    "\n",
    "ranking_list = sorted(big_test_ranking.items(), key=lambda item: item[1][0], reverse = True)\n",
    "\n",
    "winner = ranking_list[0][0]\n",
    "winner_clf = big_test_ranking[winner][1]\n",
    "\n",
    "scores_sorted = {name: score for (name, [score, _]) in ranking_list}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVClassifier took the lead\n",
    "Linear SVC and MultinomialNaiveBayes improved the most, by almost 2 %-points. LogisticRegression by about 1%-point. No change in the perfomance of NearestCentroidClassifier. And the Random Forest deteriorated by 3%-points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20626070a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = range(len(scores_sorted))\n",
    "plt.ylim(0.5, 1)\n",
    "plt.bar(count, list(scores_sorted.values()))\n",
    "plt.xticks(count, list(scores_sorted.keys()))\n",
    "plt.title(\"Macro F1 scores on test data after refitting\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_big_y_test = winner_clf.predict(big_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.87      0.89      0.88     18336\n",
      "        math       0.91      0.91      0.91     31597\n",
      "        phys       0.98      0.96      0.97     83929\n",
      "       q-bio       0.61      0.81      0.70      1796\n",
      "       q-fin       0.70      0.84      0.76       765\n",
      "        stat       0.51      0.70      0.59      2381\n",
      "\n",
      "   micro avg       0.93      0.93      0.93    138804\n",
      "   macro avg       0.76      0.85      0.80    138804\n",
      "weighted avg       0.94      0.93      0.93    138804\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[16302,   908,   275,   186,    54,   611],\n",
       "       [ 1063, 28864,   789,   136,   101,   644],\n",
       "       [  866,  1807, 80406,   527,    84,   239],\n",
       "       [   92,    31,   135,  1460,     4,    74],\n",
       "       [   36,    36,    12,     5,   642,    34],\n",
       "       [  456,   120,    34,    74,    30,  1667]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(big_y_test, predicted_big_y_test, target_names=label_e.classes_))\n",
    "conf_mtrx = confusion_matrix(big_y_test, predicted_big_y_test)\n",
    "conf_mtrx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The *Statistics* class appears to be escpecially ambigous\n",
    "Which is not that surprising seeing as many articles from other classes might also report in the abstract the statistical analysis employed in the study and the main findings in the language of statistics. At the same time, strictly statistical studies have little chance but to employ mathematics and computer science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how the articles have flown between classes in the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.6559201766503975e-12"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_nofuss_conf_mtrx = nofuss_conf_mtrx * len(big_y_test)/len(y_test)\n",
    "(conf_mtrx - rescaled_nofuss_conf_mtrx).sum() # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 320., -180., -130.,   20.,   10.,  130.],\n",
       "       [-290.,  160., -190.,   10.,  -20.,  140.],\n",
       "       [  20.,   20., -320.,  160.,   20.,   80.],\n",
       "       [ -80.,  -20.,  -20.,  330.,    0.,  -20.],\n",
       "       [ -40.,  -40.,  -20.,    0.,   20.,  -10.],\n",
       "       [-140., -110.,  -20.,   30.,    0.,  170.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(conf_mtrx - rescaled_nofuss_conf_mtrx, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the rarer classes had gained ground, wheras the most common one, *physics*, was depleted. Encouraging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the best model in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave='mask',\n",
       "    pattern='(\\\\${1,2}[\\\\s\\\\w\\\\d\\\\\\\\,\\\\.=\\\\(\\\\)*{}/\\\\[\\\\]^;:\\'`<>|%&@\\\\\"!\\\\?~#+-]*?\\\\${1,2})',\n",
       "    repl=' _LATEX_ ')), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LinSVC_fit-to-700000.joblib']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib / pickle\n",
    "dump(winner_clf, winner+f'_fit-to-{len(big_text_train)}.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('delatex', DeLaTeX(behave='mask',\n",
       "    pattern='(\\\\${1,2}[\\\\s\\\\w\\\\d\\\\\\\\,\\\\.=\\\\(\\\\)*{}/\\\\[\\\\]^;:\\'`<>|%&@\\\\\"!\\\\?~#+-]*?\\\\${1,2})',\n",
       "    repl=' _LATEX_ ')), ('tfidf_v', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_clf = load('LinSVC_fit-to-700000.joblib')\n",
    "some_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs', 'phys', 'q-bio', 'cs', 'math', 'q-fin', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_e.inverse_transform(some_clf.predict(random_abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
