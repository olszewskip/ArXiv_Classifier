{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a fixed-sized embeddings in the first layer\n",
    "\n",
    "# relies on outside variables: X_val, y_val, working_dir, n_classes, class_weights, CUSTOM_OBJECTS, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a wrapper class for creating the classification model with embedding, fitting, etc.\n",
    "It creates an useful object using a list of intermediate layers as the main argument.\n",
    "Makes it easier to consistently use the chosen metrics, loss function, class_weights, embedding etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the workhorse\n",
    "class BlackBox():\n",
    "    \n",
    "    def __init__(self, tag,\\\n",
    "                 layers, loss, batch_size, optimizer, epochs,\\\n",
    "                 metrics,\\\n",
    "                 mask_zeros=True,\\\n",
    "                 callbacks = None,\\\n",
    "                 embedd_file=None\n",
    "                ):\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "        self.loss_name = self.loss.__name__ if self.loss != 'categorical_crossentropy' else 'categorical_crossentropy'\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.tag = tag\n",
    "        self.epochs = epochs\n",
    "        self.metrics = metrics\n",
    "        self.mask_zeros = mask_zeros\n",
    "        self.callbacks = callbacks\n",
    "\n",
    "        if loss in ['categorical_crossentropy', cat_cross]:\n",
    "            self.class_weight = class_weights\n",
    "        else:\n",
    "            self.class_weight = None\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(input_dim=num_words,\n",
    "                                 output_dim=50,\n",
    "                                 input_length=padded_length,\n",
    "                                 mask_zero=self.mask_zeros))\n",
    "        \n",
    "        for layer in layers:\n",
    "            self.model.add(layer)\n",
    "        self.model.add(Dense(n_classes, activation='softmax'))\n",
    "        self.model.compile(loss=self.loss, optimizer=self.optimizer, metrics=self.metrics)\n",
    "\n",
    "        self.name = f\"{self.tag}_{self.loss_name}_batch{self.batch_size}_{self.optimizer}\"\n",
    "        self.history = None\n",
    "        self.val_macroF1 = None\n",
    "        self.eval_df = None\n",
    "    \n",
    "    def describe(self):\n",
    "        return f\"loss={self.loss_name}, batch_size={self.batch_size}, optimizer={self.optimizer}, explicit-class-weights: {type(self.class_weight)==np.ndarray}, embedd-trainable: {self.model.layers[0].trainable}\"\n",
    "    \n",
    "    def summary(self):\n",
    "        print(self.describe())\n",
    "        return self.model.summary()\n",
    "        \n",
    "    def save_embedd(self):\n",
    "        file = os.path.join(working_dir, f\"{self.name}_weights.p\")\n",
    "        with open(file, 'wb') as f:\n",
    "            pickle.dump(self.model.layers[0].get_weights(), f)\n",
    "\n",
    "    def load_embedd(self, embedd_file, trainable=False):\n",
    "        with open(embedd_file, \"rb\") as f:\n",
    "            weights = pickle.load(f)\n",
    "            self.model.layers[0].set_weights(weights)\n",
    "            self.model.layers[0].trainable = trainable\n",
    "            \n",
    "        self.model.compile(loss=self.loss, optimizer=self.optimizer, metrics=self.metrics)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _join_hist(hist_1, hist_2):\n",
    "        assert hist_1.keys() == hist_2.keys()\n",
    "        for key in hist_2:\n",
    "            hist_1[key] += hist_2[key]\n",
    "    \n",
    "    def fit(self, X_train, y_train, verbose=1, validate_on=None):        \n",
    "        print(self.describe())\n",
    "              \n",
    "        new_history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            class_weight = self.class_weight,\n",
    "            epochs=self.epochs,\n",
    "            batch_size = self.batch_size,\n",
    "            callbacks = self.callbacks,\n",
    "            validation_data = validate_on,\n",
    "            verbose = verbose        \n",
    "            ).history\n",
    "        if self.history:\n",
    "            self._join_hist(self.history, new_history)\n",
    "        else:\n",
    "            self.history = new_history\n",
    "        \n",
    "        try:\n",
    "            self.val_macroF1 = self.history['val_macroF1'][-1]\n",
    "            print(f\"Last val_macroF1: {self.val_macroF1}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    def save_hist(self):\n",
    "        file = os.path.join(working_dir, f\"{self.name}_history.p\")\n",
    "        \n",
    "        # numpy.float32-like values are not jsonifiable\n",
    "        for function in self.history.keys():\n",
    "            self.history[function] = [float(score) for score in model1.history[function]]\n",
    "        \n",
    "        with open(file, 'w') as f:\n",
    "            json.dump(self.history, f)\n",
    "    \n",
    "    def load_hist(self):\n",
    "        if self.history:\n",
    "            print(\"Overwriting the history.\")\n",
    "        self.history = json.load(open(os.path.join(working_dir, f\"{self.name}_history.p\"), \"r\"))\n",
    "        self.val_macroF1 = self.history['val_macroF1'][-1]\n",
    "\n",
    "    def Ksave(self):\n",
    "        file = os.path.join(working_dir, f\"{self.name}_Kmodel.h5\")\n",
    "        save_model(self.model, file)\n",
    "    \n",
    "    def Kload(self):\n",
    "        file = os.path.join(working_dir, f\"{self.name}_Kmodel.h5\")\n",
    "        print(\"Ovewriting the model.\")\n",
    "        self.model = load_model(file, custom_objects=CUSTOM_OBJECTS)\n",
    "        \n",
    "    def discard(self):\n",
    "        del self.history\n",
    "        self.history = None\n",
    "        del self.model\n",
    "        self.model = None\n",
    "    \n",
    "    def plot(self, with_loss=False, with_lr=False):\n",
    "        print(self.describe())\n",
    "        plot_history(self.history, with_loss=with_loss, with_lr=with_lr)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predict = {}\n",
    "        \n",
    "        # The model.evaluate method gives strangely bad results.\n",
    "        # I must be misunderstanding something.\n",
    "        # I've added evaluation using model.predict\n",
    "        \n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        Ky_test = K.variable(y_test)\n",
    "        Ky_pred = K.variable(y_pred)\n",
    "        \n",
    "        # categorical crossentropy (custom loss function)\n",
    "        predict['cat_cross'] = K.eval(cat_cross(Ky_test, Ky_pred))\n",
    "        # my_loss (custom loss function)\n",
    "        predict['my_loss'] = K.eval(my_loss(Ky_test, Ky_pred))\n",
    "        # categorical accuracy (custom metric)\n",
    "        predict['cat_acc'] = K.eval(cat_acc(Ky_test, Ky_pred))\n",
    "        # Macro precision (custom metric)\n",
    "        predict['macroPrec'] = K.eval(macroPrec(Ky_test, Ky_pred))\n",
    "        # Macro F1 (custom keras metric)\n",
    "        predict['macroF1'] = K.eval(macroF1(Ky_test, Ky_pred))\n",
    "#         # should match the above:\n",
    "#         # Macro F1 (computed by sklearn)\n",
    "#         predict['macroF1_sklearn'] = f1_score(np.round(y_pred).astype('int'), y_test.astype('int'), average='macro')\n",
    "        # Macro recall (custom metric)\n",
    "        predict['macroRecall'] = K.eval(macroRecall(Ky_test, Ky_pred))\n",
    "        \n",
    "        predict_df = pd.DataFrame(predict, index=[self.tag]).T\n",
    "        \n",
    "#         # the keras' build-in evaluate:\n",
    "#         print(f'Loss function: {self.loss_name}. Metrics: {[metric.__name__ if callable(metric) else metric for metric in self.metrics]}')\n",
    "#         columns = [self.loss_name] + [metric.__name__ if callable(metric) else metric for metric in self.metrics]\n",
    "#         evaluate_results = self.model.evaluate(X_test, y_test, verbose=1)\n",
    "#         evaluate_results_df = pd.DataFrame(np.asarray(evaluate_results).reshape(1,-1), columns=columns)\n",
    "        \n",
    "#         eval_df = pd.concat([predict_df, evaluate_results_df]).T      \n",
    "\n",
    "        \n",
    "        self.eval_df = predict_df\n",
    "        \n",
    "        return self.eval_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
