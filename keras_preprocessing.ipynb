{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the texts with masked LaTeX (see arXiv_shallow.ipynb)\n",
    "\n",
    "file = os.path.join(\"data\", \"notex_all.csv\")\n",
    "\n",
    "data = pd.read_csv(file, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838804"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_total = len(data)\n",
    "n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138804"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train-validate-test split\n",
    "# 500k - 200k - 138k\n",
    "\n",
    "n_train = 500_000\n",
    "data_train = data[:n_train]\n",
    "text_train = data_train.text\n",
    "label_train = data_train.label\n",
    "\n",
    "n_val = 200_000\n",
    "data_val = data[n_train:n_train+n_val]\n",
    "text_val = data_val.text\n",
    "label_val = data_val.label\n",
    "\n",
    "n_test = n_total - n_train - n_val\n",
    "data_test = data[n_train+n_val:]\n",
    "text_test = data_test.text\n",
    "label_test = data_test.label\n",
    "n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted 277303 unique words in the whole train dataset.\n",
      "Take numbers 1 to 'num_words'=277304 as numerical labels for the unique words, and 0 for 'silence'.\n",
      "A single record has at most 647 words.\n",
      "The text will be tokenized into sequences of numerical labels and put into arrays of length 'padded_length'=679 right-padded with zeros. The extra 5% of length is there in case a longer text would need to be tokenized and classified later (e.g. from a test dataset).\n"
     ]
    }
   ],
   "source": [
    "# see how many unique words are there globally in the train-set (unique_words)\n",
    "# and how many words are in the longest text (max_word_count)\n",
    "# save those annoyingly confusing integers to feed later into keras\n",
    "\n",
    "count_v = CountVectorizer(min_df = 1, strip_accents='unicode')\n",
    "word_counts_train = count_v.fit_transform(text_train)\n",
    "\n",
    "unique_words = word_counts_train.shape[1]\n",
    "num_words = unique_words + 1\n",
    "max_word_count = np.max(np.sum(word_counts_train, axis=1))\n",
    "padded_length = int(1.05*max_word_count)\n",
    "\n",
    "print(f\"Counted {unique_words} unique words in the whole train dataset.\")\n",
    "print(f\"Take numbers 1 to 'num_words'={num_words} as numerical labels for the unique words, and 0 for 'silence'.\")\n",
    "print(f\"A single record has at most {max_word_count} words.\")\n",
    "print(f\"The text will be tokenized into sequences of numerical labels and put into arrays of length \\\n",
    "'padded_length'={padded_length} right-padded with zeros. The extra 5% of length is there in case a longer text \\\n",
    "would need to be tokenized and classified later (e.g. from a test dataset).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unique_words': 277303, 'num_words': 277304, 'padded_length': 679}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_params = {'unique_words': unique_words, 'num_words': num_words, 'padded_length': padded_length}\n",
    "global_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=unique_words, lower=True)\n",
    "tokenizer.fit_on_texts(text_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_train)\n",
    "X_train = pad_sequences(sequences_train, maxlen=padded_length, padding='pre', truncating='post')\n",
    "\n",
    "sequences_val = tokenizer.texts_to_sequences(text_val)\n",
    "X_val = pad_sequences(sequences_val, maxlen=padded_length, padding='pre', truncating='post')\n",
    "\n",
    "sequences_test = tokenizer.texts_to_sequences(text_test)\n",
    "X_test = pad_sequences(sequences_test, maxlen=padded_length, padding='pre', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 679), (200000, 679), (138804, 679))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_e = LabelEncoder()\n",
    "num_label = label_e.fit_transform(label_train)\n",
    "y_train = to_categorical(num_label)\n",
    "y_val = to_categorical(label_e.transform(label_val))\n",
    "y_test = to_categorical(label_e.transform(label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 6), (200000, 6), (138804, 6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs' 'math' 'phys' 'q-bio' 'q-fin' 'stat']\n",
      "[0 1 2 3 4 5]\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# label/y translation\n",
    "\n",
    "print(label_e.inverse_transform(np.unique(num_label)))\n",
    "print(np.unique(num_label))\n",
    "print(to_categorical(np.unique(num_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute class weights for keras (obtained from the whole of train sample)\n",
    "\n",
    "n_classes = len(np.unique(num_label))\n",
    "global_params['n_classes'] = n_classes\n",
    "\n",
    "class_weights = compute_class_weight('balanced', np.unique(num_label), num_label)  # ~ 1 / np.unique(label, return_counts=True)[1]\n",
    "global_params['class_weights'] = class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unique_words': 277303,\n",
       " 'num_words': 277304,\n",
       " 'padded_length': 679,\n",
       " 'n_classes': 6,\n",
       " 'class_weights': array([ 1.26825655,  0.72736371,  0.27602776, 13.23801959, 30.29201502,\n",
       "         9.49559404])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.dump(global_params, open(\"global_params.p\", \"wb\"))\n",
    "global_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump all X's and y's to files\n",
    "\n",
    "# should've created a function for this...\n",
    "# and used compression...\n",
    "# the directories need to exist first, I think\n",
    "\n",
    "f_X_train = os.path.join(\"data\", \"Kdata\", \"X_train.npy\")\n",
    "np.save(f_X_train, X_train)\n",
    "f_y_train = os.path.join(\"data\", \"Kdata\", \"y_train.npy\")\n",
    "np.save(f_y_train, y_train)\n",
    "\n",
    "f_X_val = os.path.join(\"data\", \"Kdata\", \"X_val.npy\")\n",
    "np.save(f_X_val, X_val)\n",
    "f_y_val = os.path.join(\"data\", \"Kdata\", \"y_val.npy\")\n",
    "np.save(f_y_val, y_val)\n",
    "\n",
    "f_X_test = os.path.join(\"data\", \"Kdata\", \"X_test.npy\")\n",
    "np.save(f_X_test, X_test)\n",
    "f_y_test = os.path.join(\"data\", \"Kdata\", \"y_test.npy\")\n",
    "np.save(f_y_test, y_test)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   13,     1,  2082, ...,     0,     0,     0],\n",
       "       [ 6166,  2340,  6114, ...,     0,     0,     0],\n",
       "       [ 5375,    13,    79, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [    4,    56,  2290, ...,     0,     0,     0],\n",
       "       [ 2841,     2,     1, ...,     0,     0,     0],\n",
       "       [12727,     2,   283, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(os.path.join(\"data\", \"Kdata\", \"X_train.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
