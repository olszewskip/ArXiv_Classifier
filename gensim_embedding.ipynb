{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 500_000\n",
    "DATA_FILE = os.path.join(\"data\", \"notex_all.csv\")\n",
    "GENSIM_WORD_VEC_FILE = os.path.join(\"gensim\", f\"w2v_{n_train//1000}k_notex_records.kv\")\n",
    "EMBEDD_FILE = os.path.join(\"gensim\", \"embedd_weights.npy\")\n",
    "X_FILE = os.path.join(\"gensim\", \"gensim_embedd_X.txt\")\n",
    "LABELS_FILE = os.path.join(\"gensim\", \"labels.txt\")\n",
    "WORD_PATTERN = re.compile('\\w[\\w\\'`]+')\n",
    "EMBEDD_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A python iterator for gensim's Word2Vec class\n",
    "# It spits out elements that are lists of words\n",
    "# Each list corresponds to one arXiv article\n",
    "# e.g. next(texts_iter) = ['hello', 'world']\n",
    "\n",
    "class texts_iter():\n",
    "    \n",
    "    def __init__(self, filename, nrows=float('inf'), skiprows=1,\\\n",
    "                 put_labels_aside=False, labels_file=None):\n",
    "        \n",
    "        self.idx = 0\n",
    "        self.nrows = nrows\n",
    "        self.records = open(filename, \"r\")\n",
    "        self.put_labels_aside = put_labels_aside\n",
    "        if put_labels_aside:\n",
    "            self.labels_file = open(labels_file, \"w\")\n",
    "        \n",
    "        #skip rows, default = 1-line header\n",
    "        for _ in range(skiprows):\n",
    "            next(self.records)\n",
    "    \n",
    "    def finish(self):\n",
    "        self.records.close()\n",
    "        if self.put_labels_aside:\n",
    "            self.labels_file.close()\n",
    "\n",
    "\n",
    "    # the defining method, returns a list\n",
    "    def __next__(self):\n",
    "        \n",
    "        # dont read beyond 'nrows'\n",
    "        if self.idx < self.nrows:  \n",
    "            self.idx += 1\n",
    "            \n",
    "            try:\n",
    "                # record == text \\t label\n",
    "                record = next(self.records).split('\\t')\n",
    "            except:\n",
    "                self.finish()\n",
    "                raise StopIteration()\n",
    "            \n",
    "            if self.put_labels_aside:\n",
    "                label = record[1]\n",
    "                self.labels_file.write(label)\n",
    "                \n",
    "            text = record[0].lower()\n",
    "            words = WORD_PATTERN.findall(text)\n",
    "            return words\n",
    "        \n",
    "        else:\n",
    "            self.finish()\n",
    "            raise StopIteration()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(texts_iter(DATA_FILE, nrows=n_train),\\\n",
    "                    size=EMBEDD_DIM,\\\n",
    "                    min_count=1, sorted_vocab=1).wv\n",
    "\n",
    "# word2vec.save(GENSIM_WORD_VEC_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the gensim's \"wv\" object from the file\n",
    "# word2vecKV = KeyedVectors.load(WORD_VEC_TRAIN_FILE, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299304, 300)\n"
     ]
    }
   ],
   "source": [
    "# The resulting embedding and the mapping from words to indeces\n",
    "# are contained in this wod2vec object\n",
    "# Note that one needs the map along with the embedding to properly\n",
    "# tokenize the texts\n",
    "\n",
    "embedding = np.asarray(word2vec.vectors)\n",
    "print(embedding.shape)\n",
    "\n",
    "def word_to_idx(word):\n",
    "    try:\n",
    "        return word2vec.vocab[word].index + 1\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx('the'), word_to_idx('Å›wierszcz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embedding weights to file\n",
    "np.save(EMBEDD_FILE, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new files:\n",
    "# one with the texts converted to sequences of integer tokens\n",
    "# and the second with unprocessed labels,\n",
    "# both using the texts_iter class\n",
    "\n",
    "with open(X_FILE, 'w') as x_file:\n",
    "    \n",
    "    # generate word-lists using the same iterator as for\n",
    "    # creating the embedding\n",
    "    word_lists = texts_iter(DATA_FILE,\\\n",
    "                            put_labels_aside=True, labels_file=LABELS_FILE)\n",
    "    \n",
    "    for list_ in word_lists:\n",
    "        \n",
    "        sequence = [str(word_to_idx(word)) for word in list_]\n",
    "        x_file.write(\" \".join(sequence) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
